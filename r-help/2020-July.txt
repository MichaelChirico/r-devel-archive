From pd@|gd @end|ng |rom gm@||@com  Wed Jul  1 11:38:10 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 1 Jul 2020 11:38:10 +0200
Subject: [R] How to use mle2 function?
In-Reply-To: <CAMk+s2QwH=69HMQU6h_=ZOvS+RrxtgEvZjf1kEjBp9BQubtc=w@mail.gmail.com>
References: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
 <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>
 <CAMk+s2RaS1TzzTiKHKLc01mouLzieyB2bYWZgJfKk_O5F+0rmg@mail.gmail.com>
 <CAGgJW75k_6XnSW9bV9CPM4V57OsZtvvPwSsgvVBsH-mOEUwG_w@mail.gmail.com>
 <CAMk+s2QwH=69HMQU6h_=ZOvS+RrxtgEvZjf1kEjBp9BQubtc=w@mail.gmail.com>
Message-ID: <1844C46B-FBAF-4DAC-A30C-736487D8B3BA@gmail.com>

The basic problem is that holling() is not a (negative) loglikelihood function. nll() _is_ a negative loglikelihood, but it is not clear for what. You appear to be very confused as to what a likelihood even is (what is k? apparently your response variable? Then how can it be a scalar if X is a vector? etc.), so I think you need to read up a bit. 

-pd

> On 30 Jun 2020, at 14:22 , Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> No, I got the same. I reckon the problem is with X: this was I scalar,
> I was providing a vector with the actual values.
> Ho can mle2 optimize without knowing what are the actual data? and
> what values should I give for X?
> Thank you
> 
> On Tue, Jun 30, 2020 at 2:06 PM Eric Berger <ericjberger at gmail.com> wrote:
>> 
>> I have no problem with the following code:
>> 
>> library(bbmle)
>> holling <- function( a, b, x ) {
>> a*x^2 / (b^2 + x^2)
>> }
>> A=3261
>> B=10
>> X=30
>> foo <- mle2( minuslogl=holling, start=list(a=A,b=B,x=X) )
>> 
>> foo
>> 
>> # Call:
>> # mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
>> 
>> # Coefficients:
>> #            a             b             x
>> # 3.260044e+03  7.315124e+01 -2.332448e-14
>> 
>> # Log-likelihood: 0
>> 
>> 
>> Does this code create a problem for you?
>> 
>> On Tue, Jun 30, 2020 at 3:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>> 
>>> Sorry for the typo, but I have the same error if using b instead of h:
>>> ```
>>>> O = mle2(minuslogl = holling, start = list(a = A, b = B))
>>>> Error in minuslogl(a = 3261, b = 10) :
>>>  argument "x" is missing, with no default
>>> # let's add x
>>> X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
>>>      546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
>>>      1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
>>>      2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
>>>      3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
>>> O = mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
>>> Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
>>>  some named arguments in 'start' are not arguments to the specified
>>> log-likelihood function
>>> ```
>>> And even if I use the log-likelihood function:
>>> ```
>>> O = mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000, x = X))
>>>> Error in mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000,  :
>>>  some named arguments in 'start' are not arguments to the specified
>>> log-likelihood function
>>> ```
>>> 
>>> On Tue, Jun 30, 2020 at 12:03 PM Eric Berger <ericjberger at gmail.com> wrote:
>>>> 
>>>> Hi Luigi,
>>>> I took a quick look.
>>>> 
>>>> First error:
>>>> You wrote
>>>> O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
>>>> 
>>>> it should be b=B  (h is not an argument of holling())
>>>> The error message gave very precise information!
>>>> 
>>>> Second error:
>>>> You wrote
>>>> O = mle2(minuslogl = nll, start = list(a = A, h = B),   data = list(n
>>>> = 57200000, k = A))
>>>> but the arguments to nll() are p,n,k. Setting start to values for a
>>>> and h causes the function to complain.
>>>> 
>>>> HTH,
>>>> Eric
>>>> 
>>>> On Tue, Jun 30, 2020 at 12:45 PM Luigi Marongiu
>>>> <marongiu.luigi at gmail.com> wrote:
>>>>> 
>>>>> Hello,
>>>>> I would like to optimize the function:
>>>>> ```
>>>>> holling = function(a, b, x) {
>>>>>  y = (a * x^2) / (b^2 + x^2)
>>>>>  return(y)
>>>>> }
>>>>> ```
>>>>> I am trying to use the function mle2 from bbmle, but how do I need to
>>>>> feed the data?
>>>>> If I give `holling` as function to be optimized, passing the starting
>>>>> values for `a`, `b`, and `x`, I get:
>>>>> ```
>>>>> X = 1:60
>>>>> A = 3261
>>>>> B = 10
>>>>> O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
>>>>>> Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
>>>>>  some named arguments in 'start' are not arguments to the specified
>>>>> log-likelihood function
>>>>> ```
>>>>> If I pass the negative log-function (assuming a binomial distribution
>>>>> of the data, which I am not sure about)
>>>>> ```
>>>>> nll = function(p, n, k) {
>>>>>  # extract parms
>>>>>  a = p[1]
>>>>>  h = p[2]
>>>>>  # calculate probability of attack
>>>>>  pred = a/(1+a*h*n)
>>>>>  # calc NLL
>>>>>  -sum(dbinom(k, prob = pred, size = n, log = TRUE))
>>>>> }
>>>>> ```
>>>>> then I get the same error:
>>>>> ```
>>>>>> O = mle2(minuslogl = nll, start = list(a = A, h = B),
>>>>> +          data = list(n = 57200000, k = A))
>>>>> Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
>>>>> list(n = 57200000,  :
>>>>>  some named arguments in 'start' are not arguments to the specified
>>>>> log-likelihood function
>>>>> ```
>>>>> but with the disadvantage of working on an assumed function (nll).
>>>>> How can I optimize the function `holling` properly?
>>>>> Thank you
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jul  1 11:47:18 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 1 Jul 2020 09:47:18 +0000
Subject: [R] version plot problem
In-Reply-To: <24315.1861.131402.615115@stat.math.ethz.ch>
References: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>
 <20200624131236.GA24907@posteo.no>
 <251c1576907b443ab3bf3bdc55926b81@GBDCVPEXC08.corp.lgc-group.com>
 <b1bf757c9afd478688f7d95477cfe49f@SRVEXCHCM1302.precheza.cz>
 <24315.1861.131402.615115@stat.math.ethz.ch>
Message-ID: <ae1bfb7da1694e0fb8e9c2ea4b34df25@SRVEXCHCM1302.precheza.cz>

Hallo Martin

Yes I am aware of gradual improvement of R and also many new features of version 4.0.x. I have to be more aware of fact that some code could work in one version and give error in another, especially when using different major versions.

Probably best option is to persuade IT department to reinstall the newest R version on all affected PCs.

Thank you for explanation.

Best regards
Petr

> -----Original Message-----
> From: Martin Maechler <maechler at stat.math.ethz.ch>
> Sent: Tuesday, June 30, 2020 11:35 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Stephen Ellison <S.Ellison at LGCGroup.com>; Rasmus Liland
> <jral at posteo.no>; R-help <r-help at r-project.org>
> Subject: Re: [R] version plot problem
> 
> >>>>> PIKAL Petr
> >>>>>     on Thu, 25 Jun 2020 14:45:09 +0000 writes:
> 
>     > Thanks.
>     > I try to spread R to some other people and I use 4.0.0 - version.string R
>     > Under development (unstable) (2020-03-08 r77917) nickname
> Unsuffered
>     > Consequences  whereas they use R 3.6.3
>     > version.string R version 3.6.3 (2020-02-29) nickname       Holding the
>     > Windsock
> 
>     > With artificial data frame both behave with the same error
>     > dat <- data.frame(a=letters[1:5], b=1:5)
>     > dat$a <- as.character(dat$a)
>     > plot(dat)
>     > Error in plot.window(...) : need finite 'xlim' values
>     > In addition: Warning messages:
>     > 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
>     > 2: In min(x) : no non-missing arguments to min; returning Inf
>     > 3: In max(x) : no non-missing arguments to max; returning -Inf
> 
>     > So far so good.
> 
>     > But with original data with **character** columns
>     > dput(head(mok))
>     > mok <- structure(list(a = c("Kalcin?t A", "Kalcin?t A", "Kalcin?t A",
>     > "Kalcin?t A", "Kalcin?t A", "Kalcin?t A"), b = c("TB", "TB",
>     > "TB", "TB", "TB", "TB"), c = c("6101B", "6101B", "6101B", "6101B",
>     > "6101B", "6101B"), d = structure(c(1590624000, 1590624000, 1590537600,
>     > 1590537600, 1590537600, 1590537600), class = c("POSIXct", "POSIXt"
>     > ), tzone = "UTC"), e = structure(c(1590649200, 1590634800, 1590620400,
>     > 1590606000, 1590591600, 1590577200), class = c("POSIXct", "POSIXt"
>     > ), tzone = "UTC"), f = structure(c(1590649200, 1590634800, 1590620400,
>     > 1590606000, 1590591600, 1590577200), class = c("POSIXct", "POSIXt"
>     > ), tzone = "UTC"), g = c("BAROTOV?", "KR?TK?", "KR?TK?", "HOLASOV?",
>     > "HOLASOV?", "BAROTOV?"), h = c(239.4, 221, 190.3, 215.7, 241.4,
>     > 214.8), i = c(48.7, 55.6, 52.9, 50.1, 46.6, 54.4), j = c(94.2,
>     > 93, 92.4, 94.2, 96.3, 94.4), k = c(0.8, 1, 1, 0.8, 0.7, 0.8)), row.names =
>     > c(NA,
>     > 6L), class = "data.frame")
> 
>     > PLOT WORKS in R 400 but not in R 363??????
> 
>     > plot(mok)
> 
>     > Why it works in R400??? How should I explain it?
> 
> (it's  "R 4.0.0" , here spaces are relevant I think)
> 
> Well, new versions of R  are always better than previous ones (even though,
> yes, rarely sometimes bugs are introduced).
> 
> and you have heard that  R 4.0.0  came with *many* new features, right ?
> 
> In this case the long NEW FEATURES section in the NEWS | NEWS.pdf |
> NEWS.html files contained the entry
> 
>     ? data.matrix() now converts character columns to factors and from
>       this to integers.
> 
> and this contains the answer to your question, as
> 
>   plot(mok)  |->  plot.data.frame(mok)  |->  pairs(data.matrix(mok))
> 
> and  data.matrix(mok) in R 3.6.3 gives 4 warnings and ends in a character
> matrix.
> 
> --
> 
> And yes, the above new feature was related and made particularly sense with
> the important user-visible  stringsAsFactors  change in R 4.0.0; see also the
> corresponding R blog (by Kurt Hornik) :
> 
>   https://developer.r-project.org/Blog/public/2020/02/16/stringsasfactors/
> 
> 
> Martin Maechler
> R Core team  and  ETH Zurich

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jul  1 14:31:19 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 1 Jul 2020 14:31:19 +0200
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <20200630164100.3366d68b@Tarkus>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
 <20200630164100.3366d68b@Tarkus>
Message-ID: <CAMk+s2So-pOVSY0EHLqpfUgqKxnmDVcW1acgMXmR-LwsgBhLhg@mail.gmail.com>

Thank you,
I got this:
```
holly = function(p, x) {
  y = (p$a * x^2) / (p$b^2 + x^2)
  return(y)
}
A = 3261
B = 10
K = CH$Cum_Dead[1:60]
X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
      546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
      1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
      2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
      3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
O <- nls.lm(par = list(a = A, b = B), fn = holly, x = X)
> summary(O)

Parameters:
   Estimate Std. Error   t value Pr(>|t|)
a 3.090e-16  4.102e-17 7.533e+00 3.72e-10 ***
b 1.000e+01  1.525e-08 6.558e+08  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 3.107e-16 on 58 degrees of freedom
Number of iterations to termination: 2
Reason for termination: Relative error between `par' and the solution
is at most `ptol'.
```
Is this correct?
if yes, then the case is closed, thank you.
However, the optimization is worse the the eyeball estimate:
```
Addendum:
  the optimization actually got a worse outcome than the original
eyeball estimation:
  ```
actual <- c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,
            344,  408,  473,
            546,  619,  705,  794,  891,  999, 1096, 1242, 1363,
            1506, 1648, 1753,
            1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646,
            2698, 2727, 2771, 2818,
            2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
            3102, 3119, 3141, 3152,
            3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239,
            3246, 3252, 3261)
# a = 3261, b = 10
raw_estim <- c(32.28713,  125.42308,  269.25688,  449.79310,  652.20000,
               863.20588, 1072.40940, 1272.58537,
               1459.34254, 1630.50000, 1785.43439, 1924.52459, 2048.73234,
               2159.31081, 2257.61538, 2344.98876,
               2422.69666, 2491.89623, 2553.62473, 2608.80000, 2658.22736,
               2702.60959, 2742.55803, 2778.60355,
               2811.20690, 2840.76804, 2867.63450, 2892.10860, 2914.45377,
               2934.90000, 2953.64844, 2970.87544,
               2986.73591, 3001.36624, 3014.88679, 3027.40401, 3039.01225,
               3049.79534, 3059.82788, 3069.17647,
               3077.90062, 3086.05365, 3093.68343, 3100.83301, 3107.54118,
               3113.84296, 3119.77003, 3125.35108,
               3130.61216, 3135.57692, 3140.26694, 3144.70185, 3148.89962,
               3152.87666, 3156.64800, 3160.22744,
               3163.62765, 3166.86028, 3169.93605, 3172.86486)
# a = 3.090e-16, b = 1.000e+01
opt_estim <- c(3.059406e-18, 1.188462e-17, 2.551376e-17, 4.262069e-17,
6.180000e-17,
               8.179412e-17, 1.016174e-16,
1.205854e-16, 1.382818e-16, 1.545000e-16, 1.691810e-16, 1.823607e-16,
1.941301e-16, 2.046081e-16,
2.139231e-16, 2.222022e-16, 2.295656e-16, 2.361226e-16, 2.419718e-16,
2.472000e-16, 2.518835e-16,
2.560890e-16, 2.598744e-16, 2.632899e-16, 2.663793e-16, 2.691804e-16,
2.717262e-16, 2.740452e-16,
2.761626e-16, 2.781000e-16, 2.798765e-16, 2.815089e-16, 2.830118e-16,
2.843981e-16, 2.856792e-16,
2.868653e-16, 2.879653e-16, 2.889870e-16, 2.899377e-16, 2.908235e-16,
2.916502e-16, 2.924227e-16,
2.931457e-16, 2.938232e-16, 2.944588e-16, 2.950560e-16, 2.956176e-16,
2.961464e-16, 2.966449e-16,
2.971154e-16, 2.975598e-16, 2.979800e-16, 2.983778e-16, 2.987546e-16,
2.991120e-16, 2.994512e-16,
2.997734e-16, 3.000797e-16, 3.003711e-16, 3.006486e-16)
plot(1:60, actual, lty = 1 , type = "l", lwd = 2,
     xlab = "Index", ylab = "Values")
points(1:60, raw_estim, lty = 2, type = "l")
points(1:60, opt_estim, lty = 3, type = "l")
legend("right",
       legend = c("Actual values", "Raw estimate", "Optimized values"),
       lty = c(1, 2, 3), lwd = c(2, 1,1))
```
Is that normal?


On Tue, Jun 30, 2020 at 3:41 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> (Adding R-help back to Cc:)
>
> On Tue, 30 Jun 2020 14:44:29 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > Ok, I tried with:
> > ```
> > holly <- function(p) {
> >   y = (p$a * p$x^2) / (p$b^2 + p$x^2)
> >   return(y)
> > }
> > X = 1:60
> > A = 3261
> > B = 10
>
> > X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,
> > 408,  473, 546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506,
> > 1648, 1753, 1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698,
> > 2727, 2771, 2818, 2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
> > 3102, 3119, 3141, 3152, 3159, 3172, 3182, 3196, 3209, 3220, 3231,
> > 3239, 3246, 3252, 3261)
>
> You are correct in returning a vector of residuals to minimise a sum of
> squares of, but X seems to be an independent variable, not a parameter
> to optimize, so it shouldn't be passed as such. Instead you can either
> close over X:
>
> X <- c(...)
> holly <- function(p) (p$a * X^2) / (p:b^2 + X^2)
> # function holly now "contains" the vector X
>
> or pass X as an argument that nls.lm will pass to your function:
>
> holly <- function(p, X) (p$a * X^2) / (p$b^2 + X^2)
> # nls.lm will pass the X argument to function holly
> O <- nls.lm(par = list(a = 3261, b = 10), fn = holly, X = X)
> summary(O)
> # Parameters:
> #    Estimate Std. Error   t value Pr(>|t|)
> # a 3.090e-16  4.102e-17 7.533e+00 3.72e-10 ***
> # b 1.000e+01  1.525e-08 6.558e+08  < 2e-16 ***
> # ---
> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> #
> # Residual standard error: 3.107e-16 on 58 degrees of freedom
> # Number of iterations to termination: 2
> # Reason for termination: Relative error between `par' and the solution
> # is at most `ptol'.
>
> --
> Best regards,
> Ivan



--
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jul  1 15:15:10 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 1 Jul 2020 16:15:10 +0300
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <CAMk+s2So-pOVSY0EHLqpfUgqKxnmDVcW1acgMXmR-LwsgBhLhg@mail.gmail.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
 <20200630164100.3366d68b@Tarkus>
 <CAMk+s2So-pOVSY0EHLqpfUgqKxnmDVcW1acgMXmR-LwsgBhLhg@mail.gmail.com>
Message-ID: <20200701161510.2ff6ccf6@trisector>

On Wed, 1 Jul 2020 14:31:19 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

>  the optimization actually got a worse outcome than the original
>eyeball estimation

Could you elaborate on the function you are trying to fit to your data?
nls.lm takes a function returning a vector of residuals, that is,

fn <- function(parameters, input, actual.output) {
 calculate.output(parameters, input) - actual.output
}

...which means that you need a vector of input values and a vector of
output values of the same length. In your example,

> y = (p$a * x^2) / (p$b^2 + x^2)

a and b are parameters. x seems to be the dependent variable (i.e.
output of the process) and not the independent variable (i.e. input of
the model function) like I had initially assumed. What is the input of
your model function?

-- 
Best regards,
Ivan


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jul  1 15:18:12 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 1 Jul 2020 15:18:12 +0200
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <a643ad2f5d5b4ec5bb4c0ded775f36ea@GBDCVPEXC08.corp.lgc-group.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
 <20200630164100.3366d68b@Tarkus>
 <a643ad2f5d5b4ec5bb4c0ded775f36ea@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <CAMk+s2T7BXpxCxO=ix62rtD3k2ju43j6BxS7hBbjM2c5i0Pf9Q@mail.gmail.com>

Addendum.
I have found the function Gompertz even better than the Holling III
because it gives more pronounced S profile. However the optimization
is bad even in this case:
```
gomp = function(p, x) {
  y = p$a * exp(-p$b * exp(-p$c * x))
  return(y)
}
A = 3261
B = 10
C = 1
X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
      546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
      1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
      2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
      3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
W = nls.lm(par = list(a = A, b = B, c = C), fn = gomp, x = X)
W
> Nonlinear regression via the Levenberg-Marquardt algorithm
parameter estimates: 2.81739569520133e-17, 20.0000002056654, 0.100000000717244
residual sum-of-squares: 4.556e-32
reason terminated: Relative error between `par' and the solution is at
most `ptol'.
summary(W)

> Parameters:
   Estimate Std. Error   t value Pr(>|t|)
a 2.817e-17  3.764e-18 7.485e+00 4.94e-10 ***
b 2.000e+01  1.872e-08 1.068e+09  < 2e-16 ***
c 1.000e-01  2.924e-11 3.420e+09  < 2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 2.827e-17 on 57 degrees of freedom
Number of iterations to termination: 2
Reason for termination: Relative error between `par' and the solution
is at most `ptol'.
```
but eyeballing gives:
```
actual <- c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,
            344,  408,  473,
            546,  619,  705,  794,  891,  999, 1096, 1242, 1363,
            1506, 1648, 1753,
            1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646,
            2698, 2727, 2771, 2818,
            2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
            3102, 3119, 3141, 3152,
            3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239,
            3246, 3252, 3261)
# a = 3261, b = 20, c = 0.1
GOMP = c(4.508508e-05, 2.523166e-04, 1.198631e-03, 4.909360e-03, 1.758298e-02,
         5.577422e-02, 1.585133e-01,
         4.078768e-01, 9.592495e-01, 2.079652e+00, 4.188604e+00,
7.892437e+00, 1.400134e+01, 2.351997e+01,
         3.760684e+01, 5.750425e+01, 8.444654e+01, 1.195592e+02,
1.637624e+02, 2.176925e+02, 2.816487e+02,
         3.555714e+02, 4.390496e+02, 5.313549e+02, 6.314945e+02,
7.382759e+02, 8.503763e+02, 9.664098e+02,
         1.084989e+03, 1.204775e+03, 1.324520e+03, 1.443095e+03,
1.559508e+03, 1.672916e+03, 1.782624e+03,
         1.888078e+03, 1.988863e+03, 2.084686e+03, 2.175363e+03,
2.260805e+03, 2.341005e+03, 2.416022e+03,
         2.485969e+03, 2.551004e+03, 2.611315e+03, 2.667115e+03,
2.718631e+03, 2.766102e+03, 2.809769e+03,
         2.849874e+03, 2.886657e+03, 2.920347e+03, 2.951171e+03,
2.979341e+03, 3.005063e+03, 3.028528e+03,
         3.049918e+03, 3.069402e+03, 3.087140e+03, 3.103278e+03)
# a = 2.817e-17, b = 2.000e+01, c = 1.000e-01
GP = c(3.894654e-25, 2.179626e-24, 1.035432e-23, 4.240928e-23, 1.518898e-22,
         4.818030e-22, 1.369310e-21,
         3.523425e-21, 8.286434e-21, 1.796498e-20, 3.618306e-20,
6.817846e-20, 1.209500e-19, 2.031762e-19,
         3.248650e-19, 4.967478e-19, 7.294876e-19, 1.032806e-18,
1.414654e-18, 1.880527e-18, 2.433010e-18,
         3.071587e-18, 3.792710e-18, 4.590085e-18, 5.455136e-18,
6.377563e-18, 7.345937e-18, 8.348287e-18,
         9.372625e-18, 1.040739e-17, 1.144180e-17, 1.246611e-17,
1.347174e-17, 1.445141e-17, 1.539911e-17,
         1.631008e-17, 1.718071e-17, 1.800847e-17, 1.879178e-17,
1.952986e-17, 2.022267e-17, 2.087070e-17,
         2.147493e-17, 2.203673e-17, 2.255773e-17, 2.303975e-17,
2.348477e-17, 2.389484e-17, 2.427206e-17,
         2.461851e-17, 2.493625e-17, 2.522729e-17, 2.549356e-17,
2.573691e-17, 2.595910e-17, 2.616180e-17,
         2.634657e-17, 2.651489e-17, 2.666812e-17, 2.680752e-17)
plot(1:60, actual, lty = 1 , type = "l", lwd = 2,
     xlab = "Index", ylab = "Values")
points(1:60, GOMP, lty = 2, type = "l")
points(1:60, GP, lty = 3, type = "l")
legend("right",
       legend = c("Actual values", "Raw estimate", "Optimized values"),
       lty = c(1, 2, 3), lwd = c(2, 1,1))
```

On Tue, Jun 30, 2020 at 9:59 PM Stephen Ellison <S.Ellison at lgcgroup.com> wrote:
>
> Ivan Krylov [krylov.r00t at gmail.com] said:
> >  Instead you can either close over X:
> >
> > X <- c(...)
> > holly <- function(p) (p$a * X^2) / (p:b^2 + X^2)
> > # function holly now "contains" the vector X
>
> That would not be an accurate statement as written.
> The function only contains an unevaluated call referencing X; not the vector X.
> If X is not defined inside the function or its arguments, scoping rules take over and R goes looking in the function's environment, using the first thing called "X" that it finds.
>
> So
> X<-1:5
> h <- function(p=2) p*X
> h()
> # works, but
> X <- pi
> h()
> # Not the same answer. If the function 'contained' the vector, the result would be 2*(1:5) as above.
> # This is why it's not wise to rely on scoping rules in functions, unless you _completely_ control the environment.
>
> # and
> rm(X)
> h()
> # returns an error because X is no longer defined, in the function or out of it, even though X was defined at the time h() was defined.
>
> BUT
>
> X <- pi/2
> fh <- function(p=2) {
>         X <- 7
>         h(p)
> }
> fh()
> # returns pi and not 14 because h() was bound to the global environment on creation and still is when R finds it on evaluating h() in the fh() function body.
>
> Moral: if you want to be safe, pass it as an argument.
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:14}}


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jul  1 15:42:46 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 1 Jul 2020 16:42:46 +0300
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <CAMk+s2R6F3E-Ssxry_n7OBi_Xp2Gzj2tM-sXLA_Zgc6y-9=O-Q@mail.gmail.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
 <20200630164100.3366d68b@Tarkus>
 <CAMk+s2So-pOVSY0EHLqpfUgqKxnmDVcW1acgMXmR-LwsgBhLhg@mail.gmail.com>
 <20200701161510.2ff6ccf6@trisector>
 <CAMk+s2R6F3E-Ssxry_n7OBi_Xp2Gzj2tM-sXLA_Zgc6y-9=O-Q@mail.gmail.com>
Message-ID: <20200701164246.4dcd26f7@trisector>

On Wed, 1 Jul 2020 15:24:35 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

>You are right: The vector X is actually Y -- the response I would like
>to fit the curve upon. I understood I should fit nls.lm with a
>function that describes the data (Holling or Gomperz), initial
>parameters, and the actual values (Y). In return, I get the optimized
>values for the parameters. But when I re-run the function that
>describes the data with the optimized parameters, I get values close
>to zero.

The function to be minimized should have access to all three: the
parameters to optimize, the independent and dependent variable values.
Only then there is enough information to compute residuals and minimise
their sum of squares.

holly <- function(p, x, y) (p$a * x^2) / (p$b^2 + x^2) - y
#               residuals =      y.hat(x, params)      - y.actual
O <- nls.lm(par = list(a = 3261, b = 10), fn = holly, x = X, y = Y)
summary(O)
# Parameters:
#    Estimate Std. Error t value Pr(>|t|)
# a 4380.4979   106.8144   41.01   <2e-16 ***
# b   30.3779     0.9995   30.39   <2e-16 ***
# ---
# Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
# 
# Residual standard error: 157.5 on 58 degrees of freedom
# Number of iterations to termination: 7
# Reason for termination: Relative error in the sum of squares is at
# most `ftol'.

In our previous examples we ended up asking R to minimise y.hat(x)
calculated at wrong x values instead of minimising residuals.

-- 
Best regards,
Ivan


From d@cty|orh|z@ @end|ng |rom gm@||@com  Wed Jul  1 16:58:04 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Wed, 1 Jul 2020 23:58:04 +0900
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
 <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>
 <24170.28233.24528.535254@stat.math.ethz.ch>
 <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
Message-ID: <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>

Dear colleagues,

There is a new problem with dotchart(), and it is very simple to reproduce.

Just run example(dotchart).

On R versions < 4, group labels ("Urban Female" and so on) were
visible. Now they are not visible.

If in the dotchart() code, we replace the string

===

goffset <- (max(linch + offset, ginch, na.rm = TRUE) + 1/16)/lheight

===

with the string

===

goffset <- (max(linch + 0.2, ginch, na.rm = TRUE) + 1/16)/lheight

===

everything start to be OK. Probably, the reason that in the code,
there is another "offset" object and they clash. So if we replace this
part of code

===

offset <- cumsum(c(0, diff(as.numeric(groups)) != 0))
y <- seq_len(n) + 2 * offset

===

with

===

offset1 <- cumsum(c(0, diff(as.numeric(groups)) != 0))
y <- seq_len(n) + 2 * offset1

===

everything will be well again.

With best wishes,

Alexey Shipunov

??, 13 ???. 2020 ?. ? 18:56, Alexey Shipunov <dactylorhiza at gmail.com>:
>
> Dear Martin,
>
> Great news, thanks!
>
> If you wish, please also consider my initial note about help(hist),
> this is definitely worrying new R users.
>
> With best wishes,
>
> Alexey
>
> ??, 13 ???. 2020 ?. ? 02:16, Martin Maechler <maechler at stat.math.ethz.ch>:
> >
> > >>>>> Alexey Shipunov
> > >>>>>     on Tue, 18 Feb 2020 14:34:48 +0900 writes:
> >
> >     > Thank you for the detailed explanation. I tend to agree. However, this
> >     > behavior is relatively easy to remediate:
> >
> >     > This is the piece of the current code:
> >
> >     > ===
> >     > if (!(is.null(labels) && is.null(glabels))) {
> >     >    nmai <- par("mai")
> >     >    nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) + 0.1
> >     >    par(mai = nmai)
> >     > }
> >     > ===
> >
> >     > This is my proposal:
> >
> >     > ===
> >     > yinch <- if (!is.null(ylab)) 0.4 else 0
> >     > if (!(is.null(labels) && is.null(glabels))) {
> >     >    nmai <- par("mai")
> >     >    nm.2 <- nmai[4L] + max(if(is.null(ylab)) 0 else 0.4) + linch + goffset, ginch) + 0.1
> >     >    if (nmai[2L] < nm.2)
> >     >       nmai[2L] <- nm.2
> >     >    par(mai = nmai)
> >     > }
> >     > ===
> >
> >     > Then margins and y-axis labels start to work normally. I wonder if
> >     > this (or similar) is possible to introduce into the code?
> >
> >     > Alexey
> >
> > Well, I had looked at this back then (~Feb 18), and now had a
> > considerable longer look.
> >
> > Your suggestion makes sense,  but then it needs even more work
> > to ensure that the  'ylab'  y-axis label will be placed properly.
> >
> > Of course, Deepayan (author of grid-based 'lattice')  is right
> > that dotchart()s implementation is pretty hackish ... but then
> > still.
> >
> > I have (+-) fixed this in the sources of "R-devel" the
> > development version of R (which should become R 4.0.0  on April
> > 24 as was announced today).
> >
> > Now, things like this (extended) example work nicely :
> >
> > op <- par(xaxs = "i")  # 0 -- 100\%
> > dotchart(t(VADeaths), xlim = c(0,100), bg = "skyblue",
> >          main = "Death Rates in Virginia - 1940", xlab = "rate [ % ]",
> >          ylab = "Grouping:  Age  x   Urbanity . Gender")
> > par(op)
> >
> >
> > Thank you, Alexey, for your report and bug fix suggestion!
> >
> > Best regards,
> >
> > Martin Maechler
> > ETH Zurich and R Core team
> >
> >
> >
> >     > ........... 17:37, Deepayan Sarkar <deepayan.sarkar at gmail.com>:
> >     >>
> >     >> On Mon, Feb 17, 2020 at 10:24 AM Rui Barradas <ruipbarradas at sapo.pt> wrot=
> >     > e:
> >     >> >
> >     >> > Hello,
> >     >> >
> >     >> > Yes, this is definitely a bug.
> >     >>
> >     >> I would argue that the only bug here is that the documentation doesn't
> >     >> say that 'ylab' may not behave as expected.
> >     >>
> >     >> dotchart() is mainly designed for 2-way tables (see the VADeaths
> >     >> example), but it's implementation is really pretty hackish because it
> >     >> has to work within the limited traditional graphics framework. The
> >     >> main problem is that dot plots want to put horizontal y-axis labels
> >     >> (usually derived from factor levels), which are often longer than the
> >     >> default margins, so the margins are modified. Unfortunately they are
> >     >> only re-set on exit, and so the ylab that is plotted inside dotchart()
> >     >> may be clipped. Traditionally, Cleveland dot plots don't have a y-axis
> >     >> label; it's assumed that the factor levels are sufficient (and for
> >     >> 2-way tables, there would be two variables, so there is no sensible
> >     >> default).
> >     >>
> >     >> I doubt that dotchart() is worth fixing (except to maybe disallow
> >     >> ylab). If you want flexibility, use modern grid-based alternatives
> >     >> such as lattice::dotplot() or ggplot2.
> >     >>
> >     >> -Deepayan
> >     >>
> >     >> > Even the matrix plot is puzzling, with a "1" as top row sort-of-label
> >     >> > but no grid line. I'm trying to follow the source code of dotchart but
> >     >> > am yet to understand exactly what it does to decide the margins setting=
> >     > s.
> >     >> >
> >     >> >      if (!(is.null(labels) && is.null(glabels))) {
> >     >> >        nmai <- par("mai")
> >     >> >        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
> >     >> >          0.1
> >     >> >        par(mai = nmai)
> >     >> >      }
> >     >> >
> >     >> > This should be moved to r-devel?
> >     >> >
> >     >> > Rui Barradas
> >     >> >
> >     >> >  03:33 de 17/02/20, Alexey Shipunov escreveu:
> >     >> > > John and Rui, thanks!
> >     >> > >
> >     >> > > However, if we use the proper object, the problem still persists:
> >     >> > >
> >     >> > > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
> >     >> > > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
> >     >> > > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
> >     >> > >
> >     >> > > If the object is matrix, ylab is visible:
> >     >> > >
> >     >> > > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
> >     >> > >
> >     >> > > But the ?dotchart explicitly says that "x: either a vector or matrix
> >     >> > > of numeric values" and then "labels: a vector of labels for each
> >     >> > > point.  For vectors the default is to use  "names(x) = ...".
> >     >> > >
> >     >> > > So this is likely a bug. Do you agree?
> >     >> > >
> >     >> > > Alexey
> >     >> > >
> >     >> > > ..... 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
> >     >> > >>
> >     >> > >> Hello,
> >     >> > >>
> >     >> > >> I believe you are wrong, the error is not in dotchart, it's in your
> >     >> > >> code. You assume that to plot an object of class "table" is the same as
> >     >> > >> to plot an object of class "numeric".
> >     >> > >>
> >     >> > >> Inline.
> >     >> > >>
> >     >> > >> =C3=80s 12:21 de 16/02/20, Alexey Shipunov escreveu:
> >     >> > >>> Dear list,
> >     >> > >>>
> >     >> > >>> I have been advised to share these with R-help instead of filling the
> >     >> > >>> bug report:
> >     >> > >>>
> >     >> > >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
> >     >> > >>> cannot change the left margin (outer margin 2) of the plot
> >     >> > >>>
> >     >> > >>> The code:
> >     >> > >>>
> >     >> > >>> aa <- table(c(1, 1, 1, 2, 2, 3))
> >     >> > >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
> >     >> > >>
> >     >> > >> You are right, it does *not* show 'ylab' but the user is warned.
> >     >> > >>
> >     >> > >>
> >     >> > >> aa <- table(c(1, 1, 1, 2, 2, 3))
> >     >> > >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
> >     >> > >> #Warning message:
> >     >> > >> #In dotchart(aa, ylab = "Ylab") :
> >     >> > >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
> >     >> > >>
> >     >> > >>
> >     >> > >> My code:
> >     >> > >>
> >     >> > >>
> >     >> > >> (mar <- par("mar"))    # new R session
> >     >> > >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
> >     >> > >>
> >     >> > >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
> >     >> > >>
> >     >> > >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
> >     >> > >> old.par <- par(mar = mar + c(0, 5, 0, 0))
> >     >> > >> par("mar")
> >     >> > >> #[1] 5.1 9.1 4.1 2.1
> >     >> > >>
> >     >> > >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
> >     >> > >>
> >     >> > >> par(old.par)                 # It does change the left margin
> >     >> > >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
> >     >> > >>
> >     >> > >>
> >     >> > >>
> >     >> > >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
> >     >> > >>> par(old.par) # does not change left margin
> >     >> > >>>
> >     >> > >>> Possible solution:
> >     >> > >>>
> >     >> > >>> I researched the problem and think that the dotchart() code will need
> >     >> > >>> few corrections. If there is an interest, I can post it here; or you
> >     >> > >>> can look at the code of shipunov::Dotchart1() function.
> >     >> > >>>
> >     >> > >>> 2) example(hist) includes two "wrong" and "extreme" examples which
> >     >> > >>> slow down and even crash R on some systems; this make it unsuitable
> >     >> > >>> for demonstration in the class and strikes beginners in R who just
> >     >> > >>> want to understand how hist() works. Actually, I did it last week (I
> >     >> > >>> was not aware of these examples), and in the class two computers hang,
> >     >> > >>> and many others were extremely slow.
> >     >> > >>>
> >     >> > >>> The code:
> >     >> > >>>
> >     >> > >>> example(hist)
> >     >> > >>>
> >     >> > >>> Possible solution:
> >     >> > >>>
> >     >> > >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
> >     >> > >>> this will allow to see the code but in the same time will not strike
> >     >> > >>> beginners in R who just
> >     >> > >>> want to understand how hist() works. They will still be possible to
> >     >> > >>> run with example(..., run.dontrun=TRUE).
> >     >> > >>
> >     >> > >> Agree, it's annoying. Sometimes there's a Warning section after the
> >     >> > >> Details section. Maybe such a section could get users' attention to
> >     >> > >> those examples? At least it wouldn't hurt...
> >     >> > >>
> >     >> > >>
> >     >> > >> Hope this helps,
> >     >> > >>
> >     >> > >> Rui Barradas
> >     >> > >>
> >     >> > >>>
> >     >> > >>> With best wishes,
> >     >> > >>>
> >     >> > >>> Alexey Shipunov
> >     >> > >>> ______________________________________________


From |re|ey@ @end|ng |rom gm@||@com  Wed Jul  1 17:27:32 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 1 Jul 2020 17:27:32 +0200
Subject: [R] how to summarize results from studies?
Message-ID: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>

Hello everyone

I have some studies with results from the same outcome scale. I want to merge them into 1 summarised estimated result and its standard deviation. How do I do that in R?

Thank you very much for your help!
Frederik

From m@rc_@chw@rtz @end|ng |rom me@com  Wed Jul  1 17:40:33 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 1 Jul 2020 11:40:33 -0400
Subject: [R] how to summarize results from studies?
In-Reply-To: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>
References: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>
Message-ID: <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>

Hi,

It sounds like you will want to engage in a meta-analysis.

There is a CRAN task view here:

  https://cran.r-project.org/web/views/MetaAnalysis.html

that would be relevant in pointing you to tools in R that can support that approach.

That being said, the details of specific methodologies and conceptual assistance would be beyond the scope of this list. You should consider consulting a local statistician for assistance with that, if needed.

Regards,

Marc Schwartz

> On Jul 1, 2020, at 11:27 AM, Frederik Feys <frefeys at gmail.com> wrote:
> 
> Hello everyone
> 
> I have some studies with results from the same outcome scale. I want to merge them into 1 summarised estimated result and its standard deviation. How do I do that in R?
> 
> Thank you very much for your help!
> Frederik


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Jul  1 18:44:27 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 1 Jul 2020 11:44:27 -0500
Subject: [R] Creating and arranging multiply plots
References: <003201d64fc6$e2be9cb0$a83bd610$.ref@sbcglobal.net>
Message-ID: <003201d64fc6$e2be9cb0$a83bd610$@sbcglobal.net>

r-help forum

 
Need some guidance. I need to create 20 plots and then combine them into one
graphic. Normally this isn't a problem for me except this time I'm using the
holts function to perform a TS forecast. So I though I'd just write a
function which take the country name and then passes the name through the
function, then I'd take the name output and recombine the individual plots
into one. Well its not working like I though it would work. Any suggestions
of how I might tackle this quandary? The problem is I chose to make
individual plotly plots using the plot_forecast {TSstudio} function Here is
a sample dataset and code.

library(dplyr)
library(forecast)
library(ggplot2)
library(TSstudio)
library(xts)
library(zoo)

# data prep
sample_data <- read_excel("~/NGA Telework/USSOUTHCOM/Data/sample.xlsx")
sample_data$date <- as.Date(sample_data$date, format = c("%Y-%m-%d"))
sample_xts <- as.xts(samplef[ , -2], order.by = sample$date)
sample_zoo <- fortify(sample_xts)
sample_zoo$total_cases <- as.numeric(as.factor(sample_zoo$total_cases))

# plots function
plots <- function(i){
  cases <- filter(sample_data, location == i) %>% select(date, total_cases) 
  
  xts <- as.xts(cases[ , -1], order.by = cases$date)
  
  xts <- na.locf(xts)
  
  forecast <- holt(xts, damped = TRUE, h = 2, PI = 0.9)
  
  i <- plot_forecast(forecast,
                     title = i,
                     Xtitle = "Date",
                     Ytitle = "Cases")
  return(i)
}

# create individual plots
atg <- plots("Antigua and Barbuda")  # Antigua and Barbuda
arg <- plots("Argentina")            # Argentina
brb <- plots("Barbados")             # Barbados
blz <- plots("Belize")               # Belize

Sincerely

Jeff Reichman
(314) 457-1966


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul  1 19:06:03 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 1 Jul 2020 10:06:03 -0700
Subject: [R] Creating and arranging multiply plots
In-Reply-To: <003201d64fc6$e2be9cb0$a83bd610$@sbcglobal.net>
References: <003201d64fc6$e2be9cb0$a83bd610$.ref@sbcglobal.net>
 <003201d64fc6$e2be9cb0$a83bd610$@sbcglobal.net>
Message-ID: <CAGxFJbSpEaHXUGmTNKvfyYN4Jv9R-5Ji+FejRHcBtteK-xYV3w@mail.gmail.com>

I think you need to read about "faceting" in ggplot. This may necessitate
modifying your data structure.

?layout may be an alternative approach.

See also
https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html
for a fuller exegesis.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jul 1, 2020 at 9:44 AM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> r-help forum
>
>
> Need some guidance. I need to create 20 plots and then combine them into
> one
> graphic. Normally this isn't a problem for me except this time I'm using
> the
> holts function to perform a TS forecast. So I though I'd just write a
> function which take the country name and then passes the name through the
> function, then I'd take the name output and recombine the individual plots
> into one. Well its not working like I though it would work. Any suggestions
> of how I might tackle this quandary? The problem is I chose to make
> individual plotly plots using the plot_forecast {TSstudio} function Here is
> a sample dataset and code.
>
> library(dplyr)
> library(forecast)
> library(ggplot2)
> library(TSstudio)
> library(xts)
> library(zoo)
>
> # data prep
> sample_data <- read_excel("~/NGA Telework/USSOUTHCOM/Data/sample.xlsx")
> sample_data$date <- as.Date(sample_data$date, format = c("%Y-%m-%d"))
> sample_xts <- as.xts(samplef[ , -2], order.by = sample$date)
> sample_zoo <- fortify(sample_xts)
> sample_zoo$total_cases <- as.numeric(as.factor(sample_zoo$total_cases))
>
> # plots function
> plots <- function(i){
>   cases <- filter(sample_data, location == i) %>% select(date,
> total_cases)
>
>   xts <- as.xts(cases[ , -1], order.by = cases$date)
>
>   xts <- na.locf(xts)
>
>   forecast <- holt(xts, damped = TRUE, h = 2, PI = 0.9)
>
>   i <- plot_forecast(forecast,
>                      title = i,
>                      Xtitle = "Date",
>                      Ytitle = "Cases")
>   return(i)
> }
>
> # create individual plots
> atg <- plots("Antigua and Barbuda")  # Antigua and Barbuda
> arg <- plots("Argentina")            # Argentina
> brb <- plots("Barbados")             # Barbados
> blz <- plots("Belize")               # Belize
>
> Sincerely
>
> Jeff Reichman
> (314) 457-1966
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Wed Jul  1 19:07:13 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Wed, 1 Jul 2020 18:07:13 +0100
Subject: [R] how to summarize results from studies?
In-Reply-To: <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>
References: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>
 <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>
Message-ID: <56bc447b-f30f-865d-5d57-587d0b550591@dewey.myzen.co.uk>

Dear Frederik

There is also a mailing list dedicated to meta-analysis in R

https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis//

Michael


On 01/07/2020 16:40, Marc Schwartz via R-help wrote:
> Hi,
> 
> It sounds like you will want to engage in a meta-analysis.
> 
> There is a CRAN task view here:
> 
>    https://cran.r-project.org/web/views/MetaAnalysis.html
> 
> that would be relevant in pointing you to tools in R that can support that approach.
> 
> That being said, the details of specific methodologies and conceptual assistance would be beyond the scope of this list. You should consider consulting a local statistician for assistance with that, if needed.
> 
> Regards,
> 
> Marc Schwartz
> 
>> On Jul 1, 2020, at 11:27 AM, Frederik Feys <frefeys at gmail.com> wrote:
>>
>> Hello everyone
>>
>> I have some studies with results from the same outcome scale. I want to merge them into 1 summarised estimated result and its standard deviation. How do I do that in R?
>>
>> Thank you very much for your help!
>> Frederik
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From |re|ey@ @end|ng |rom gm@||@com  Wed Jul  1 19:16:35 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 1 Jul 2020 19:16:35 +0200
Subject: [R] how to summarize results from studies?
In-Reply-To: <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>
References: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>
 <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>
Message-ID: <BBF2930B-1AB9-42A4-9524-42BDF8D4C720@gmail.com>

Thank you Marc!

I ended up using metafor library:

res_UK <- escalc(mi=data_UK$GAD.7_mean, sdi=data_UK$weight_pred, ni=data_UK$GAD.7_mean_N, measure = "MN?)

rma(yi, vi, data=res_UK, method="REML?)



> Op 1 jul. 2020, om 17:40 heeft Marc Schwartz <marc_schwartz at me.com> het volgende geschreven:
> 
> Hi,
> 
> It sounds like you will want to engage in a meta-analysis.
> 
> There is a CRAN task view here:
> 
>  https://cran.r-project.org/web/views/MetaAnalysis.html
> 
> that would be relevant in pointing you to tools in R that can support that approach.
> 
> That being said, the details of specific methodologies and conceptual assistance would be beyond the scope of this list. You should consider consulting a local statistician for assistance with that, if needed.
> 
> Regards,
> 
> Marc Schwartz
> 
>> On Jul 1, 2020, at 11:27 AM, Frederik Feys <frefeys at gmail.com> wrote:
>> 
>> Hello everyone
>> 
>> I have some studies with results from the same outcome scale. I want to merge them into 1 summarised estimated result and its standard deviation. How do I do that in R?
>> 
>> Thank you very much for your help!
>> Frederik


From |re|ey@ @end|ng |rom gm@||@com  Wed Jul  1 19:17:37 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 1 Jul 2020 19:17:37 +0200
Subject: [R] how to summarize results from studies?
In-Reply-To: <56bc447b-f30f-865d-5d57-587d0b550591@dewey.myzen.co.uk>
References: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>
 <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>
 <56bc447b-f30f-865d-5d57-587d0b550591@dewey.myzen.co.uk>
Message-ID: <5B5D9406-DCDA-43A9-96C3-7D54871F0EFF@gmail.com>

Thank you Michael!

> Op 1 jul. 2020, om 19:07 heeft Michael Dewey <lists at dewey.myzen.co.uk> het volgende geschreven:
> 
> Dear Frederik
> 
> There is also a mailing list dedicated to meta-analysis in R
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis//
> 
> Michael
> 
> 
> On 01/07/2020 16:40, Marc Schwartz via R-help wrote:
>> Hi,
>> It sounds like you will want to engage in a meta-analysis.
>> There is a CRAN task view here:
>>   https://cran.r-project.org/web/views/MetaAnalysis.html
>> that would be relevant in pointing you to tools in R that can support that approach.
>> That being said, the details of specific methodologies and conceptual assistance would be beyond the scope of this list. You should consider consulting a local statistician for assistance with that, if needed.
>> Regards,
>> Marc Schwartz
>>> On Jul 1, 2020, at 11:27 AM, Frederik Feys <frefeys at gmail.com> wrote:
>>> 
>>> Hello everyone
>>> 
>>> I have some studies with results from the same outcome scale. I want to merge them into 1 summarised estimated result and its standard deviation. How do I do that in R?
>>> 
>>> Thank you very much for your help!
>>> Frederik
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


From m@rc_@chw@rtz @end|ng |rom me@com  Wed Jul  1 19:18:46 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 1 Jul 2020 13:18:46 -0400
Subject: [R] how to summarize results from studies?
In-Reply-To: <56bc447b-f30f-865d-5d57-587d0b550591@dewey.myzen.co.uk>
References: <102BF7BB-8E23-486A-ABC8-C2E6480CD37E@gmail.com>
 <A3E6755A-8D4A-4227-B277-91B4841A8269@me.com>
 <56bc447b-f30f-865d-5d57-587d0b550591@dewey.myzen.co.uk>
Message-ID: <01CEADD6-559E-4CE5-BC4D-3E440FE0C60E@me.com>

Michael,

Thanks for the reminder on that.

Frederik, sometimes, with an emphasis on sometimes, the r-sig-* lists are willing to go beyond narrow R programming assistance, and offer domain specific conceptual assistance, which would otherwise be off-topic for r-help.

You might look through the archives of that list to get a sense for the subject matter that has been covered there:

  https://stat.ethz.ch/pipermail/r-sig-meta-analysis/ <https://stat.ethz.ch/pipermail/r-sig-meta-analysis/>

I might also mention that a Google search using "meta analysis in R", comes up with a number of relevant hits, including various tutorials.

Regards,

Marc


> On Jul 1, 2020, at 1:07 PM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> Dear Frederik
> 
> There is also a mailing list dedicated to meta-analysis in R
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-meta-analysis//
> 
> Michael
> 
> 
> On 01/07/2020 16:40, Marc Schwartz via R-help wrote:
>> Hi,
>> It sounds like you will want to engage in a meta-analysis.
>> There is a CRAN task view here:
>>   https://cran.r-project.org/web/views/MetaAnalysis.html
>> that would be relevant in pointing you to tools in R that can support that approach.
>> That being said, the details of specific methodologies and conceptual assistance would be beyond the scope of this list. You should consider consulting a local statistician for assistance with that, if needed.
>> Regards,
>> Marc Schwartz
>>> On Jul 1, 2020, at 11:27 AM, Frederik Feys <frefeys at gmail.com> wrote:
>>> 
>>> Hello everyone
>>> 
>>> I have some studies with results from the same outcome scale. I want to merge them into 1 summarised estimated result and its standard deviation. How do I do that in R?
>>> 
>>> Thank you very much for your help!
>>> Frederik
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Jul  2 01:18:00 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Jul 2020 11:18:00 +1200
Subject: [R] [FORGED] Re:  Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
 <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>
 <24170.28233.24528.535254@stat.math.ethz.ch>
 <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
 <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
Message-ID: <6c107e7b-496f-0432-0847-16f8f2011c17@auckland.ac.nz>


On 2/07/20 2:58 am, Alexey Shipunov wrote:

> Dear colleagues,
> 
> There is a new problem with dotchart(), and it is very simple to reproduce.
> 
> Just run example(dotchart).
> 
> On R versions < 4, group labels ("Urban Female" and so on) were
> visible. Now they are not visible.

I just tried example(dotchart) and the results look fine to me.  In 
particular the group labels are definitely visible.  My session info 
follows.

>> sessionInfo()
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 18.04.4 LTS
> 
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3
> LAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3
> 
> Random number generation:
>  RNG:     Mersenne-Twister 
>  Normal:  Inversion 
>  Sample:  Rounding 
>  
> locale:
>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
>  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_GB.UTF-8    
>  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_GB.UTF-8   
>  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C                 
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
> [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C       
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> other attached packages:
> [1] brev_0.0-4
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.0.2 tools_4.0.2   

<SNIP>

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From d@cty|orh|z@ @end|ng |rom gm@||@com  Thu Jul  2 01:24:04 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Thu, 2 Jul 2020 08:24:04 +0900
Subject: [R] [FORGED] Re:  Unintended behaviour (possibly bugs)
In-Reply-To: <6c107e7b-496f-0432-0847-16f8f2011c17@auckland.ac.nz>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
 <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>
 <24170.28233.24528.535254@stat.math.ethz.ch>
 <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
 <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
 <6c107e7b-496f-0432-0847-16f8f2011c17@auckland.ac.nz>
Message-ID: <CAD-ePxbBcaDNrY768AVr2xjdvgvsAxqzmVie=uJ41Qj9RnjqcA@mail.gmail.com>

I need to clarify. This part of example(dotchart) does not show group
labels in my case:

===

dotchart(VADeaths, main = "Death Rates in Virginia - 1940")

===

My session is

===

> sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.6 LTS

Matrix products: default
BLAS:   /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] colorout_1.2-2

loaded via a namespace (and not attached):
[1] compiler_4.0.2 tools_4.0.2

===

Alexey Shipunov

??, 2 ???. 2020 ?. ? 08:18, Rolf Turner <r.turner at auckland.ac.nz>:

>
>
> On 2/07/20 2:58 am, Alexey Shipunov wrote:
>
> > Dear colleagues,
> >
> > There is a new problem with dotchart(), and it is very simple to reproduce.
> >
> > Just run example(dotchart).
> >
> > On R versions < 4, group labels ("Urban Female" and so on) were
> > visible. Now they are not visible.
>
> I just tried example(dotchart) and the results look fine to me.  In
> particular the group labels are definitely visible.  My session info
> follows.
>
> >> sessionInfo()
> > R version 4.0.2 (2020-06-22)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> > Running under: Ubuntu 18.04.4 LTS
> >
> > Matrix products: default
> > BLAS:   /usr/lib/x86_64-linux-gnu/atlas/libblas.so.3.10.3
> > LAPACK: /usr/lib/x86_64-linux-gnu/atlas/liblapack.so.3.10.3
> >
> > Random number generation:
> >  RNG:     Mersenne-Twister
> >  Normal:  Inversion
> >  Sample:  Rounding
> >
> > locale:
> >  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_GB.UTF-8
> >  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_GB.UTF-8
> >  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] brev_0.0-4
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_4.0.2 tools_4.0.2
>
> <SNIP>
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Jul  2 01:49:39 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Jul 2020 11:49:39 +1200
Subject: [R] [FORGED] Re:  Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxbBcaDNrY768AVr2xjdvgvsAxqzmVie=uJ41Qj9RnjqcA@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
 <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>
 <24170.28233.24528.535254@stat.math.ethz.ch>
 <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
 <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
 <6c107e7b-496f-0432-0847-16f8f2011c17@auckland.ac.nz>
 <CAD-ePxbBcaDNrY768AVr2xjdvgvsAxqzmVie=uJ41Qj9RnjqcA@mail.gmail.com>
Message-ID: <f214a565-8b6e-f348-49a5-e5a119d5f686@auckland.ac.nz>


On 2/07/20 11:24 am, Alexey Shipunov wrote:

> I need to clarify. This part of example(dotchart) does not show group
> labels in my case:
> 
> ===
> 
> dotchart(VADeaths, main = "Death Rates in Virginia - 1940")

<SNIP>

Ah!  I see.  I didn't know what I should be looking for in this 
instance.  Sorry for the noise.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dr@ke@go@@| @end|ng |rom gm@||@com  Thu Jul  2 00:47:42 2020
From: dr@ke@go@@| @end|ng |rom gm@||@com (Drake Gossi)
Date: Wed, 1 Jul 2020 17:47:42 -0500
Subject: [R] piping in only specific parts of a certain column
Message-ID: <CAPSTy5e8=LY=NODiOtOyTtd_C+uGa5-jH6b7qb-gyhPaQCqttQ@mail.gmail.com>

Hello!

Question. I'm dealing with a large excel sheet that I'm trying to tidy
and then visualize, and I'm wondering how I might specify the data I'm
visualizing.

Here's the data frame I'm working with:

> str(unclean_data)
Classes ?tbl_df?, ?tbl? and 'data.frame': 1909 obs. of  9 variables:
 $ unique identifier: num  1 1 1 1 1 1 1 1 1 1 ...
 $ question         : num  1 2 2 2 2 2 2 3 3 3 ...
 $ grid text        : chr  "******* and his family have lived and
worked in ******* for 6 years." "******* contributes to public safety
while also organizing community events. He said he hosts Trunk or
Treat, en"| __truncated__ "******* did not know the origin or history
of ******* PD, but he said it is integral to the safety of the area."
"The ******* PD ensures safety, he said, while also familiarizing
themselves with the town?s people. He said ev"| __truncated__ ...
>

The most important column is the $grid text one, and I know how to extract that:

> text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)

But my question is, what if I only wanted to extract stuff from the
$grid text column that was itself only correlated with the number 3 in
the $question column? So, instead of visualizing or rather tidying the
whole $grid text column, I want to only tidy a smaller portion of it,
only that which is indexed to the number 3 is the $question column.

Is there a way to do that in this line of code:

> text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)

Or do I have to FIRST shorten the $`grid text` column (shorten it to
only that which is indexed to 3 in the $question column) BEFORE I even
begin to tidy it?

I'm working with these libraries right now, if it helps:

library(tidytext)
library(dplyr)
library(stringr)

D


From drj|m|emon @end|ng |rom gm@||@com  Thu Jul  2 12:54:38 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 2 Jul 2020 20:54:38 +1000
Subject: [R] piping in only specific parts of a certain column
In-Reply-To: <CAPSTy5e8=LY=NODiOtOyTtd_C+uGa5-jH6b7qb-gyhPaQCqttQ@mail.gmail.com>
References: <CAPSTy5e8=LY=NODiOtOyTtd_C+uGa5-jH6b7qb-gyhPaQCqttQ@mail.gmail.com>
Message-ID: <CA+8X3fVe6rWH1dNL0kPcFcuR-TvJG-Zfjmazfavh3r6QZBNa+g@mail.gmail.com>

Hi Drake,
This is a guess on my part, but what about:
\
q3only<-unclean_data[unclean_data$question == 3,]

then perform your operations on q3only

Jim

On Thu, Jul 2, 2020 at 8:35 PM Drake Gossi <drake.gossi at gmail.com> wrote:
>
> Hello!
>
> Question. I'm dealing with a large excel sheet that I'm trying to tidy
> and then visualize, and I'm wondering how I might specify the data I'm
> visualizing.
>
> Here's the data frame I'm working with:
>
> > str(unclean_data)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 1909 obs. of  9 variables:
>  $ unique identifier: num  1 1 1 1 1 1 1 1 1 1 ...
>  $ question         : num  1 2 2 2 2 2 2 3 3 3 ...
>  $ grid text        : chr  "******* and his family have lived and
> worked in ******* for 6 years." "******* contributes to public safety
> while also organizing community events. He said he hosts Trunk or
> Treat, en"| __truncated__ "******* did not know the origin or history
> of ******* PD, but he said it is integral to the safety of the area."
> "The ******* PD ensures safety, he said, while also familiarizing
> themselves with the town?s people. He said ev"| __truncated__ ...
> >
>
> The most important column is the $grid text one, and I know how to extract that:
>
> > text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)
>
> But my question is, what if I only wanted to extract stuff from the
> $grid text column that was itself only correlated with the number 3 in
> the $question column? So, instead of visualizing or rather tidying the
> whole $grid text column, I want to only tidy a smaller portion of it,
> only that which is indexed to the number 3 is the $question column.
>
> Is there a way to do that in this line of code:
>
> > text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)
>
> Or do I have to FIRST shorten the $`grid text` column (shorten it to
> only that which is indexed to 3 in the $question column) BEFORE I even
> begin to tidy it?
>
> I'm working with these libraries right now, if it helps:
>
> library(tidytext)
> library(dplyr)
> library(stringr)
>
> D
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jul  2 13:46:57 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Jul 2020 13:46:57 +0200
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <20200701164246.4dcd26f7@trisector>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
 <20200630164100.3366d68b@Tarkus>
 <CAMk+s2So-pOVSY0EHLqpfUgqKxnmDVcW1acgMXmR-LwsgBhLhg@mail.gmail.com>
 <20200701161510.2ff6ccf6@trisector>
 <CAMk+s2R6F3E-Ssxry_n7OBi_Xp2Gzj2tM-sXLA_Zgc6y-9=O-Q@mail.gmail.com>
 <20200701164246.4dcd26f7@trisector>
Message-ID: <CAMk+s2Rv8qNyq7VtA3N6OO5DND3zZ5oxcUU-wo8Evx51emLOwQ@mail.gmail.com>

Got it, thanks!
Now I get:
```
actual <- c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,
            344,  408,  473,
            546,  619,  705,  794,  891,  999, 1096, 1242, 1363,
            1506, 1648, 1753,
            1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646,
            2698, 2727, 2771, 2818,
            2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
            3102, 3119, 3141, 3152,
            3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239,
            3246, 3252, 3261)
# a = 3261, b = 10
raw_estim <- c(32.28713,  125.42308,  269.25688,  449.79310,  652.20000,
               863.20588, 1072.40940, 1272.58537,
               1459.34254, 1630.50000, 1785.43439, 1924.52459, 2048.73234,
               2159.31081, 2257.61538, 2344.98876,
               2422.69666, 2491.89623, 2553.62473, 2608.80000, 2658.22736,
               2702.60959, 2742.55803, 2778.60355,
               2811.20690, 2840.76804, 2867.63450, 2892.10860, 2914.45377,
               2934.90000, 2953.64844, 2970.87544,
               2986.73591, 3001.36624, 3014.88679, 3027.40401, 3039.01225,
               3049.79534, 3059.82788, 3069.17647,
               3077.90062, 3086.05365, 3093.68343, 3100.83301, 3107.54118,
               3113.84296, 3119.77003, 3125.35108,
               3130.61216, 3135.57692, 3140.26694, 3144.70185, 3148.89962,
               3152.87666, 3156.64800, 3160.22744,
               3163.62765, 3166.86028, 3169.93605, 3172.86486)
# a = 3.090e-16, b = 1.000e+01
opt_estim_old <- c(3.059406e-18, 1.188462e-17, 2.551376e-17,
4.262069e-17, 6.180000e-17,
               8.179412e-17, 1.016174e-16,
1.205854e-16, 1.382818e-16, 1.545000e-16, 1.691810e-16, 1.823607e-16,
1.941301e-16, 2.046081e-16,
2.139231e-16, 2.222022e-16, 2.295656e-16, 2.361226e-16, 2.419718e-16,
2.472000e-16, 2.518835e-16,
2.560890e-16, 2.598744e-16, 2.632899e-16, 2.663793e-16, 2.691804e-16,
2.717262e-16, 2.740452e-16,
2.761626e-16, 2.781000e-16, 2.798765e-16, 2.815089e-16, 2.830118e-16,
2.843981e-16, 2.856792e-16,
2.868653e-16, 2.879653e-16, 2.889870e-16, 2.899377e-16, 2.908235e-16,
2.916502e-16, 2.924227e-16,
2.931457e-16, 2.938232e-16, 2.944588e-16, 2.950560e-16, 2.956176e-16,
2.961464e-16, 2.966449e-16,
2.971154e-16, 2.975598e-16, 2.979800e-16, 2.983778e-16, 2.987546e-16,
2.991120e-16, 2.994512e-16,
2.997734e-16, 3.000797e-16, 3.003711e-16, 3.006486e-16)
# a =  4380.4979, b = 30.3779
opt_estim <- c(4.741739,   18.905561,   42.309262,   74.655637,  115.541787,
               164.471381,  220.869196,
284.097173,  353.471198,  428.277856,  507.790487,  591.283989,
678.047947,  767.397828,
858.684086,  951.299179, 1044.682566, 1138.323858, 1231.764323,
1324.596988 , 1416.465585,
1507.062590, 1596.126574, 1683.439081, 1768.821202, 1852.130003,
1933.254918, 2012.114210,
2088.651563, 2162.832870, 2234.643232, 2304.084201, 2371.171268,
2435.931609, 2498.402055,
2558.627308, 2616.658366, 2672.551143, 2726.365284, 2778.163130,
2828.008847, 2875.967677,
2922.105311, 2966.487363, 3009.178936, 3050.244270, 3089.746448,
3127.747177, 3164.306598,
3199.483163, 3233.333529, 3265.912492, 3297.272946, 3327.465861,
3356.540283, 3384.543344,
3411.520287, 3437.514499, 3462.567553, 3486.719252)

plot(1:60, actual, lty = 1 , type = "l", lwd = 2,
     xlab = "Index", ylab = "Values")
points(1:60, raw_estim, lty = 2, type = "l")
points(1:60, opt_estim, lty = 3, type = "l")
legend("bottomright",
       legend = c("Actual values", "Raw estimate", "Optimized values"),
       lty = c(1, 2, 3), lwd = c(2, 1,1))
```

And it works even better with the function Gomperz:
```
gomp = function(p, x, y) (p$a * exp(-p$b * exp(-p$c * x))) - y
actual <- c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,
            344,  408,  473,
            546,  619,  705,  794,  891,  999, 1096, 1242, 1363,
            1506, 1648, 1753,
            1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646,
            2698, 2727, 2771, 2818,
            2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
            3102, 3119, 3141, 3152,
            3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239,
            3246, 3252, 3261)
# a = 3261, b = 20, c = 0.1
GOMP = c(4.508508e-05, 2.523166e-04, 1.198631e-03, 4.909360e-03, 1.758298e-02,
         5.577422e-02, 1.585133e-01,
         4.078768e-01, 9.592495e-01, 2.079652e+00, 4.188604e+00,
7.892437e+00, 1.400134e+01, 2.351997e+01,
         3.760684e+01, 5.750425e+01, 8.444654e+01, 1.195592e+02,
1.637624e+02, 2.176925e+02, 2.816487e+02,
         3.555714e+02, 4.390496e+02, 5.313549e+02, 6.314945e+02,
7.382759e+02, 8.503763e+02, 9.664098e+02,
         1.084989e+03, 1.204775e+03, 1.324520e+03, 1.443095e+03,
1.559508e+03, 1.672916e+03, 1.782624e+03,
         1.888078e+03, 1.988863e+03, 2.084686e+03, 2.175363e+03,
2.260805e+03, 2.341005e+03, 2.416022e+03,
         2.485969e+03, 2.551004e+03, 2.611315e+03, 2.667115e+03,
2.718631e+03, 2.766102e+03, 2.809769e+03,
         2.849874e+03, 2.886657e+03, 2.920347e+03, 2.951171e+03,
2.979341e+03, 3.005063e+03, 3.028528e+03,
         3.049918e+03, 3.069402e+03, 3.087140e+03, 3.103278e+03)
# a = 3.344e+03, b = 7.715e+00, c = 1.007e-01
GP = c(3.123603,    6.093680,   11.150677,   19.256792,   31.559926,
49.332695,
       73.883838,
106.453532,  148.107305,  199.643054,  261.522677,  333.835070,
416.291985,  508.253731,
608.778470,  716.687199,  830.636345,  949.190754, 1070.891363,
1194.313689, 1318.114912,
1441.068876, 1562.089431, 1680.243298, 1794.754104, 1904.999383,
2010.502340, 2110.919990,
2206.029092, 2295.711021, 2379.936466, 2458.750617, 2532.259301,
2600.616339, 2664.012281,
2722.664577, 2776.809146, 2826.693281, 2872.569775, 2914.692156,
2953.310891, 2988.670438,
3021.007015, 3050.546986, 3077.505743, 3102.087011, 3124.482483,
3144.871725, 3163.422286,
3180.289965, 3195.619209, 3209.543577, 3222.186275, 3233.660724,
3244.071144, 3253.513139,
3262.074288, 3269.834707, 3276.867604, 3283.239800)
plot(1:60, actual, lty = 1 , type = "l", lwd = 2,
     xlab = "Index", ylab = "Values")
points(1:60, GOMP, lty = 2, type = "l")
points(1:60, GP, lty = 3, type = "l")
legend("right",
       legend = c("Actual values", "Raw estimate", "Optimized values"),
       lty = c(1, 2, 3), lwd = c(2, 1,1))
```
Thank you

On Wed, Jul 1, 2020 at 3:42 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Wed, 1 Jul 2020 15:24:35 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> >You are right: The vector X is actually Y -- the response I would like
> >to fit the curve upon. I understood I should fit nls.lm with a
> >function that describes the data (Holling or Gomperz), initial
> >parameters, and the actual values (Y). In return, I get the optimized
> >values for the parameters. But when I re-run the function that
> >describes the data with the optimized parameters, I get values close
> >to zero.
>
> The function to be minimized should have access to all three: the
> parameters to optimize, the independent and dependent variable values.
> Only then there is enough information to compute residuals and minimise
> their sum of squares.
>
> holly <- function(p, x, y) (p$a * x^2) / (p$b^2 + x^2) - y
> #               residuals =      y.hat(x, params)      - y.actual
> O <- nls.lm(par = list(a = 3261, b = 10), fn = holly, x = X, y = Y)
> summary(O)
> # Parameters:
> #    Estimate Std. Error t value Pr(>|t|)
> # a 4380.4979   106.8144   41.01   <2e-16 ***
> # b   30.3779     0.9995   30.39   <2e-16 ***
> # ---
> # Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> #
> # Residual standard error: 157.5 on 58 degrees of freedom
> # Number of iterations to termination: 7
> # Reason for termination: Relative error in the sum of squares is at
> # most `ftol'.
>
> In our previous examples we ended up asking R to minimise y.hat(x)
> calculated at wrong x values instead of minimising residuals.
>
> --
> Best regards,
> Ivan



-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul  2 14:07:41 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Jul 2020 13:07:41 +0100
Subject: [R] piping in only specific parts of a certain column
In-Reply-To: <CAPSTy5e8=LY=NODiOtOyTtd_C+uGa5-jH6b7qb-gyhPaQCqttQ@mail.gmail.com>
References: <CAPSTy5e8=LY=NODiOtOyTtd_C+uGa5-jH6b7qb-gyhPaQCqttQ@mail.gmail.com>
Message-ID: <51d9a55f-5f37-4ca0-9dc8-04f714622e87@sapo.pt>

Hello,


Maybe the following is what you are looking for.


unclean_data %>%
   filter(question == 3) %>%
   mutate(line = row_number()) %>%
   select(line, `grid text`)


Hope this helps,

Rui Barradas
  

?s 23:47 de 01/07/2020, Drake Gossi escreveu:
> Hello!
>
> Question. I'm dealing with a large excel sheet that I'm trying to tidy
> and then visualize, and I'm wondering how I might specify the data I'm
> visualizing.
>
> Here's the data frame I'm working with:
>
>> str(unclean_data)
> Classes ?tbl_df?, ?tbl? and 'data.frame': 1909 obs. of  9 variables:
>   $ unique identifier: num  1 1 1 1 1 1 1 1 1 1 ...
>   $ question         : num  1 2 2 2 2 2 2 3 3 3 ...
>   $ grid text        : chr  "******* and his family have lived and
> worked in ******* for 6 years." "******* contributes to public safety
> while also organizing community events. He said he hosts Trunk or
> Treat, en"| __truncated__ "******* did not know the origin or history
> of ******* PD, but he said it is integral to the safety of the area."
> "The ******* PD ensures safety, he said, while also familiarizing
> themselves with the town?s people. He said ev"| __truncated__ ...
> The most important column is the $grid text one, and I know how to extract that:
>
>> text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)
> But my question is, what if I only wanted to extract stuff from the
> $grid text column that was itself only correlated with the number 3 in
> the $question column? So, instead of visualizing or rather tidying the
> whole $grid text column, I want to only tidy a smaller portion of it,
> only that which is indexed to the number 3 is the $question column.
>
> Is there a way to do that in this line of code:
>
>> text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)
> Or do I have to FIRST shorten the $`grid text` column (shorten it to
> only that which is indexed to 3 in the $question column) BEFORE I even
> begin to tidy it?
>
> I'm working with these libraries right now, if it helps:
>
> library(tidytext)
> library(dplyr)
> library(stringr)
>
> D
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From emm@@m@p@rr|@h @end|ng |rom gm@||@com  Wed Jul  1 21:15:58 2020
From: emm@@m@p@rr|@h @end|ng |rom gm@||@com (Emma Parrish)
Date: Wed, 1 Jul 2020 15:15:58 -0400
Subject: [R] Help with effectsize package
Message-ID: <CAPi=aqy0_zbB5FuhAR1c0F9AycY0AD9OHHhAkmfCQZF+SRTgDw@mail.gmail.com>

Hello all,
I am having some trouble with the effectsize package in R. I am trying to
convert Z scores to percentiles using the convert_z_to_percentile command.
This same code (below) has worked for 3 other variables, but not these 2
variables

However, when I use the function to convert other z scores to percentiles,
I get numbers that are exponential (e.g., 1.877030e+01) instead of a
percentile. Has this happened to anyone else, and if so, how were you able
to fix it?

Here is my code:

#generate z-scores for SSPA using the scale() function - this part of the
code is successful
dat$varA_z <- scale(dat$varA_tot, center = TRUE, scale = TRUE)
dat$varB_z <- scale(dat$varB_tot, center = TRUE, scale = TRUE)

#Convert z-scores to percentile for UPSA using effectsize package tool,
convert_z_to_percentile
#for some reason this isn't working
dat$varA_per <- (convert_z_to_percentile(dat$varA_z)*100)
dat$varB_per <- (convert_z_to_percentile(dat$varB_z)*100)

Thank you in advance for any help you may be able to offer!
Emma

-- 
Emma Parrish, B.S. | Graduate Student Researcher
SDSU/UC San Diego Joint Doctoral Program in Clinical Psychology
Cognitive Dynamics Lab
emma.m.parrish at gmail.com | (610) 428-6714

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Jul  2 15:22:19 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 2 Jul 2020 16:22:19 +0300
Subject: [R] Help with effectsize package
In-Reply-To: <CAPi=aqy0_zbB5FuhAR1c0F9AycY0AD9OHHhAkmfCQZF+SRTgDw@mail.gmail.com>
References: <CAPi=aqy0_zbB5FuhAR1c0F9AycY0AD9OHHhAkmfCQZF+SRTgDw@mail.gmail.com>
Message-ID: <CAGgJW76Nn4LgR=S+wBpAY50oNzt3tMq2GO6_rB_aBYCV1tAjiQ@mail.gmail.com>

Hi Emma,
You write
"I get numbers that are exponential (e.g., 1.877030e+01) "

1.877030e+01

is scientific notation. It means 1.877030 * 10 ( = 18.7703).

This seems like a perfectly good percentile.

HTH,
Eric


On Thu, Jul 2, 2020 at 4:12 PM Emma Parrish <emma.m.parrish at gmail.com>
wrote:

> Hello all,
> I am having some trouble with the effectsize package in R. I am trying to
> convert Z scores to percentiles using the convert_z_to_percentile command.
> This same code (below) has worked for 3 other variables, but not these 2
> variables
>
> However, when I use the function to convert other z scores to percentiles,
> I get numbers that are exponential (e.g., 1.877030e+01) instead of a
> percentile. Has this happened to anyone else, and if so, how were you able
> to fix it?
>
> Here is my code:
>
> #generate z-scores for SSPA using the scale() function - this part of the
> code is successful
> dat$varA_z <- scale(dat$varA_tot, center = TRUE, scale = TRUE)
> dat$varB_z <- scale(dat$varB_tot, center = TRUE, scale = TRUE)
>
> #Convert z-scores to percentile for UPSA using effectsize package tool,
> convert_z_to_percentile
> #for some reason this isn't working
> dat$varA_per <- (convert_z_to_percentile(dat$varA_z)*100)
> dat$varB_per <- (convert_z_to_percentile(dat$varB_z)*100)
>
> Thank you in advance for any help you may be able to offer!
> Emma
>
> --
> Emma Parrish, B.S. | Graduate Student Researcher
> SDSU/UC San Diego Joint Doctoral Program in Clinical Psychology
> Cognitive Dynamics Lab
> emma.m.parrish at gmail.com | (610) 428-6714
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jul  2 15:30:05 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 2 Jul 2020 15:30:05 +0200
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
 <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>
 <24170.28233.24528.535254@stat.math.ethz.ch>
 <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
 <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
Message-ID: <24317.57693.817671.488741@stat.math.ethz.ch>

>>>>> Alexey Shipunov 
>>>>>     on Wed, 1 Jul 2020 23:58:04 +0900 writes:

    > Dear colleagues,
    > There is a new problem with dotchart(), and it is very simple to reproduce.

    > Just run example(dotchart).

    > On R versions < 4, group labels ("Urban Female" and so on) were
    > visible. Now they are not visible.

    > If in the dotchart() code, we replace the string

    > ===

    > goffset <- (max(linch + offset, ginch, na.rm = TRUE) + 1/16)/lheight

    > ===

    > with the string

    > ===

    > goffset <- (max(linch + 0.2, ginch, na.rm = TRUE) + 1/16)/lheight

    > ===

 > everything start to be OK. Probably, the reason that in the code,
 > there is another "offset" object and they clash. So if we replace this
 > part of code

    > ===

    > offset <- cumsum(c(0, diff(as.numeric(groups)) != 0))
    > y <- seq_len(n) + 2 * offset

    > ===

    > with

    > ===

    > offset1 <- cumsum(c(0, diff(as.numeric(groups)) != 0))
    > y <- seq_len(n) + 2 * offset1

    > ===

    > everything will be well again.

Thank you.

I'll have a look *again*, and cautiously consider the above.
Indeed your second patch seems the correct one, distinguishing the
two different offsets that where conflated.
I will commit to R-devel and also to "R 4.0.2 patched" (but note
that no quick R 4.0.3 has been planned).

Note (Alexey knows, almost everbody else probably not):
This has come from another dotchart(* , ylab=.) glitch which
Alexey had reported in February and I had fixed early
March... evidently not fixed quite correctly... and yes, I'm
embarrased.
However I did mention here to have fixed it, on March 12
(--> https://stat.ethz.ch/pipermail/r-help/2020-March/465921.html )

It would have been really great if people would test such
changes, as they were in all pre-releases (R 4.0.0 alpha, beta,
RC), easily available ...  and we could have fixed this even
before R 4.0.0 was released more than a month later than my
e-mail above...

Martin


    > With best wishes,
    > Alexey Shipunov

    > ??, 13 ???. 2020 ?. ? 18:56, Alexey Shipunov <dactylorhiza at gmail.com>:
    >> 
    >> Dear Martin,
    >> 
    >> Great news, thanks!
    >> 
    >> If you wish, please also consider my initial note about help(hist),
    >> this is definitely worrying new R users.
    >> 
    >> With best wishes,
    >> 
    >> Alexey
    >> 
    >> ??, 13 ???. 2020 ?. ? 02:16, Martin Maechler <maechler at stat.math.ethz.ch>:
    >> >
    >> > >>>>> Alexey Shipunov
    >> > >>>>>     on Tue, 18 Feb 2020 14:34:48 +0900 writes:
    >> >
    >> >     > Thank you for the detailed explanation. I tend to agree. However, this
    >> >     > behavior is relatively easy to remediate:
    >> >
    >> >     > This is the piece of the current code:
    >> >
    >> >     > ===
    >> >     > if (!(is.null(labels) && is.null(glabels))) {
    >> >     >    nmai <- par("mai")
    >> >     >    nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) + 0.1
    >> >     >    par(mai = nmai)
    >> >     > }
    >> >     > ===
    >> >
    >> >     > This is my proposal:
    >> >
    >> >     > ===
    >> >     > yinch <- if (!is.null(ylab)) 0.4 else 0
    >> >     > if (!(is.null(labels) && is.null(glabels))) {
    >> >     >    nmai <- par("mai")
    >> >     >    nm.2 <- nmai[4L] + max(if(is.null(ylab)) 0 else 0.4) + linch + goffset, ginch) + 0.1
    >> >     >    if (nmai[2L] < nm.2)
    >> >     >       nmai[2L] <- nm.2
    >> >     >    par(mai = nmai)
    >> >     > }
    >> >     > ===
    >> >
    >> >     > Then margins and y-axis labels start to work normally. I wonder if
    >> >     > this (or similar) is possible to introduce into the code?
    >> >
    >> >     > Alexey
    >> >
    >> > Well, I had looked at this back then (~Feb 18), and now had a
    >> > considerable longer look.
    >> >
    >> > Your suggestion makes sense,  but then it needs even more work
    >> > to ensure that the  'ylab'  y-axis label will be placed properly.
    >> >
    >> > Of course, Deepayan (author of grid-based 'lattice')  is right
    >> > that dotchart()s implementation is pretty hackish ... but then
    >> > still.
    >> >
    >> > I have (+-) fixed this in the sources of "R-devel" the
    >> > development version of R (which should become R 4.0.0  on April
    >> > 24 as was announced today).
    >> >
    >> > Now, things like this (extended) example work nicely :
    >> >
    >> > op <- par(xaxs = "i")  # 0 -- 100\%
    >> > dotchart(t(VADeaths), xlim = c(0,100), bg = "skyblue",
    >> >          main = "Death Rates in Virginia - 1940", xlab = "rate [ % ]",
    >> >          ylab = "Grouping:  Age  x   Urbanity . Gender")
    >> > par(op)
    >> >
    >> >
    >> > Thank you, Alexey, for your report and bug fix suggestion!
    >> >
    >> > Best regards,
    >> >
    >> > Martin Maechler
    >> > ETH Zurich and R Core team
    >> >
    >> >
    >> >
    >> >     > ........... 17:37, Deepayan Sarkar <deepayan.sarkar at gmail.com>:
    >> >     >>
    >> >     >> On Mon, Feb 17, 2020 at 10:24 AM Rui Barradas <ruipbarradas at sapo.pt> wrot=
    >> >     > e:
    >> >     >> >
    >> >     >> > Hello,
    >> >     >> >
    >> >     >> > Yes, this is definitely a bug.
    >> >     >>
    >> >     >> I would argue that the only bug here is that the documentation doesn't
    >> >     >> say that 'ylab' may not behave as expected.
    >> >     >>
    >> >     >> dotchart() is mainly designed for 2-way tables (see the VADeaths
    >> >     >> example), but it's implementation is really pretty hackish because it
    >> >     >> has to work within the limited traditional graphics framework. The
    >> >     >> main problem is that dot plots want to put horizontal y-axis labels
    >> >     >> (usually derived from factor levels), which are often longer than the
    >> >     >> default margins, so the margins are modified. Unfortunately they are
    >> >     >> only re-set on exit, and so the ylab that is plotted inside dotchart()
    >> >     >> may be clipped. Traditionally, Cleveland dot plots don't have a y-axis
    >> >     >> label; it's assumed that the factor levels are sufficient (and for
    >> >     >> 2-way tables, there would be two variables, so there is no sensible
    >> >     >> default).
    >> >     >>
    >> >     >> I doubt that dotchart() is worth fixing (except to maybe disallow
    >> >     >> ylab). If you want flexibility, use modern grid-based alternatives
    >> >     >> such as lattice::dotplot() or ggplot2.
    >> >     >>
    >> >     >> -Deepayan
    >> >     >>
    >> >     >> > Even the matrix plot is puzzling, with a "1" as top row sort-of-label
    >> >     >> > but no grid line. I'm trying to follow the source code of dotchart but
    >> >     >> > am yet to understand exactly what it does to decide the margins setting=
    >> >     > s.
    >> >     >> >
    >> >     >> >      if (!(is.null(labels) && is.null(glabels))) {
    >> >     >> >        nmai <- par("mai")
    >> >     >> >        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
    >> >     >> >          0.1
    >> >     >> >        par(mai = nmai)
    >> >     >> >      }
    >> >     >> >
    >> >     >> > This should be moved to r-devel?
    >> >     >> >
    >> >     >> > Rui Barradas
    >> >     >> >
    >> >     >> >  03:33 de 17/02/20, Alexey Shipunov escreveu:
    >> >     >> > > John and Rui, thanks!
    >> >     >> > >
    >> >     >> > > However, if we use the proper object, the problem still persists:
    >> >     >> > >
    >> >     >> > > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
    >> >     >> > > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
    >> >     >> > > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
    >> >     >> > >
    >> >     >> > > If the object is matrix, ylab is visible:
    >> >     >> > >
    >> >     >> > > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
    >> >     >> > >
    >> >     >> > > But the ?dotchart explicitly says that "x: either a vector or matrix
    >> >     >> > > of numeric values" and then "labels: a vector of labels for each
    >> >     >> > > point.  For vectors the default is to use  "names(x) = ...".
    >> >     >> > >
    >> >     >> > > So this is likely a bug. Do you agree?
    >> >     >> > >
    >> >     >> > > Alexey
    >> >     >> > >
    >> >     >> > > ..... 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
    >> >     >> > >>
    >> >     >> > >> Hello,
    >> >     >> > >>
    >> >     >> > >> I believe you are wrong, the error is not in dotchart, it's in your
    >> >     >> > >> code. You assume that to plot an object of class "table" is the same as
    >> >     >> > >> to plot an object of class "numeric".
    >> >     >> > >>
    >> >     >> > >> Inline.
    >> >     >> > >>
    >> >     >> > >> =C3=80s 12:21 de 16/02/20, Alexey Shipunov escreveu:
    >> >     >> > >>> Dear list,
    >> >     >> > >>>
    >> >     >> > >>> I have been advised to share these with R-help instead of filling the
    >> >     >> > >>> bug report:
    >> >     >> > >>>
    >> >     >> > >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
    >> >     >> > >>> cannot change the left margin (outer margin 2) of the plot
    >> >     >> > >>>
    >> >     >> > >>> The code:
    >> >     >> > >>>
    >> >     >> > >>> aa <- table(c(1, 1, 1, 2, 2, 3))
    >> >     >> > >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
    >> >     >> > >>
    >> >     >> > >> You are right, it does *not* show 'ylab' but the user is warned.
    >> >     >> > >>
    >> >     >> > >>
    >> >     >> > >> aa <- table(c(1, 1, 1, 2, 2, 3))
    >> >     >> > >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
    >> >     >> > >> #Warning message:
    >> >     >> > >> #In dotchart(aa, ylab = "Ylab") :
    >> >     >> > >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
    >> >     >> > >>
    >> >     >> > >>
    >> >     >> > >> My code:
    >> >     >> > >>
    >> >     >> > >>
    >> >     >> > >> (mar <- par("mar"))    # new R session
    >> >     >> > >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
    >> >     >> > >>
    >> >     >> > >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
    >> >     >> > >>
    >> >     >> > >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
    >> >     >> > >> old.par <- par(mar = mar + c(0, 5, 0, 0))
    >> >     >> > >> par("mar")
    >> >     >> > >> #[1] 5.1 9.1 4.1 2.1
    >> >     >> > >>
    >> >     >> > >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
    >> >     >> > >>
    >> >     >> > >> par(old.par)                 # It does change the left margin
    >> >     >> > >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
    >> >     >> > >>
    >> >     >> > >>
    >> >     >> > >>
    >> >     >> > >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
    >> >     >> > >>> par(old.par) # does not change left margin
    >> >     >> > >>>
    >> >     >> > >>> Possible solution:
    >> >     >> > >>>
    >> >     >> > >>> I researched the problem and think that the dotchart() code will need
    >> >     >> > >>> few corrections. If there is an interest, I can post it here; or you
    >> >     >> > >>> can look at the code of shipunov::Dotchart1() function.
    >> >     >> > >>>
    >> >     >> > >>> 2) example(hist) includes two "wrong" and "extreme" examples which
    >> >     >> > >>> slow down and even crash R on some systems; this make it unsuitable
    >> >     >> > >>> for demonstration in the class and strikes beginners in R who just
    >> >     >> > >>> want to understand how hist() works. Actually, I did it last week (I
    >> >     >> > >>> was not aware of these examples), and in the class two computers hang,
    >> >     >> > >>> and many others were extremely slow.
    >> >     >> > >>>
    >> >     >> > >>> The code:
    >> >     >> > >>>
    >> >     >> > >>> example(hist)
    >> >     >> > >>>
    >> >     >> > >>> Possible solution:
    >> >     >> > >>>
    >> >     >> > >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
    >> >     >> > >>> this will allow to see the code but in the same time will not strike
    >> >     >> > >>> beginners in R who just
    >> >     >> > >>> want to understand how hist() works. They will still be possible to
    >> >     >> > >>> run with example(..., run.dontrun=TRUE).
    >> >     >> > >>
    >> >     >> > >> Agree, it's annoying. Sometimes there's a Warning section after the
    >> >     >> > >> Details section. Maybe such a section could get users' attention to
    >> >     >> > >> those examples? At least it wouldn't hurt...
    >> >     >> > >>
    >> >     >> > >>
    >> >     >> > >> Hope this helps,
    >> >     >> > >>
    >> >     >> > >> Rui Barradas
    >> >     >> > >>
    >> >     >> > >>>
    >> >     >> > >>> With best wishes,
    >> >     >> > >>>
    >> >     >> > >>> Alexey Shipunov
    >> >     >> > >>> ______________________________________________


From dr@ke@go@@| @end|ng |rom gm@||@com  Thu Jul  2 21:26:54 2020
From: dr@ke@go@@| @end|ng |rom gm@||@com (Drake Gossi)
Date: Thu, 2 Jul 2020 12:26:54 -0700
Subject: [R] piping in only specific parts of a certain column
In-Reply-To: <51d9a55f-5f37-4ca0-9dc8-04f714622e87@sapo.pt>
References: <CAPSTy5e8=LY=NODiOtOyTtd_C+uGa5-jH6b7qb-gyhPaQCqttQ@mail.gmail.com>
 <51d9a55f-5f37-4ca0-9dc8-04f714622e87@sapo.pt>
Message-ID: <CAPSTy5c36sPW6huqqJ0bqhyu6VDsP0pJANu2U6Oa-f0mc+u6XA@mail.gmail.com>

Thank you very much, Jim and Rui.

The line that ended up working for me was this:

> ed_exp3 <- unclean_data[which(unclean_data$question == 3) %in% c("`grid text`")]

However, as I read and study Jim's and Rui's code, I see how those
would work too. Thank you all again!

On Thu, Jul 2, 2020 at 5:07 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
>
> Maybe the following is what you are looking for.
>
>
> unclean_data %>%
>   filter(question == 3) %>%
>   mutate(line = row_number()) %>%
>   select(line, `grid text`)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 23:47 de 01/07/2020, Drake Gossi escreveu:
>
> Hello!
>
> Question. I'm dealing with a large excel sheet that I'm trying to tidy
> and then visualize, and I'm wondering how I might specify the data I'm
> visualizing.
>
> Here's the data frame I'm working with:
>
> str(unclean_data)
>
> Classes ?tbl_df?, ?tbl? and 'data.frame': 1909 obs. of  9 variables:
>  $ unique identifier: num  1 1 1 1 1 1 1 1 1 1 ...
>  $ question         : num  1 2 2 2 2 2 2 3 3 3 ...
>  $ grid text        : chr  "******* and his family have lived and
> worked in ******* for 6 years." "******* contributes to public safety
> while also organizing community events. He said he hosts Trunk or
> Treat, en"| __truncated__ "******* did not know the origin or history
> of ******* PD, but he said it is integral to the safety of the area."
> "The ******* PD ensures safety, he said, while also familiarizing
> themselves with the town?s people. He said ev"| __truncated__ ...
>
> The most important column is the $grid text one, and I know how to extract that:
>
> text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)
>
> But my question is, what if I only wanted to extract stuff from the
> $grid text column that was itself only correlated with the number 3 in
> the $question column? So, instead of visualizing or rather tidying the
> whole $grid text column, I want to only tidy a smaller portion of it,
> only that which is indexed to the number 3 is the $question column.
>
> Is there a way to do that in this line of code:
>
> text_df_APPLIED <- tibble(line = 1:1909, text = unclean_data$`grid text`)
>
> Or do I have to FIRST shorten the $`grid text` column (shorten it to
> only that which is indexed to 3 in the $question column) BEFORE I even
> begin to tidy it?
>
> I'm working with these libraries right now, if it helps:
>
> library(tidytext)
> library(dplyr)
> library(stringr)
>
> D
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Sem v?rus. www.avast.com



-- 
Drake Gossi
Phd Student
University of Texas at Austin


From herd_dog @end|ng |rom cox@net  Fri Jul  3 00:04:10 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Thu, 2 Jul 2020 15:04:10 -0700
Subject: [R] National Weather Service Data
Message-ID: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>

Is anyone out there familiar with rNOMADS?  It is a package to get into National Weather Service forecasting data with R?

I'm not sure the Weather Service software named wgrib2 loaded correctly because some of the stuff won't run and I can't make much sense out of some of the output.

Thanks.
	[[alternative HTML version deleted]]


From @@e||ck @end|ng |rom gm@||@com  Fri Jul  3 00:20:04 2020
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Thu, 2 Jul 2020 18:20:04 -0400
Subject: [R] National Weather Service Data
In-Reply-To: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
Message-ID: <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>

I am unfamiliar with Rnomads. Could you provide a minimal reproducable
example? You are more likely to receive help this way.

On Thu, Jul 2, 2020, 18:06 Philip <herd_dog at cox.net> wrote:

> Is anyone out there familiar with rNOMADS?  It is a package to get into
> National Weather Service forecasting data with R?
>
> I'm not sure the Weather Service software named wgrib2 loaded correctly
> because some of the stuff won't run and I can't make much sense out of some
> of the output.
>
> Thanks.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@cty|orh|z@ @end|ng |rom gm@||@com  Fri Jul  3 05:40:13 2020
From: d@cty|orh|z@ @end|ng |rom gm@||@com (Alexey Shipunov)
Date: Fri, 3 Jul 2020 12:40:13 +0900
Subject: [R] Unintended behaviour (possibly bugs)
In-Reply-To: <24317.57693.817671.488741@stat.math.ethz.ch>
References: <CAD-ePxY3WOumNjaED5OwHtGWnzGecom+5MLGNgeEWS4sbBxGiw@mail.gmail.com>
 <bd143039-d302-fee9-7350-ec01a61c17e1@sapo.pt>
 <CAD-ePxZ-MytqqfQUiEE9+4e_T8kyfj4kiYcRTj4GsYcupGLj8A@mail.gmail.com>
 <cd83233c-5794-d741-cf9d-32d4435cf590@sapo.pt>
 <CADfFDC6HGT0X0d5xnrCfRKybp9SRehU10c3C5hGAm0USNtndWQ@mail.gmail.com>
 <CAD-ePxZELLi+zvkT8AmF6R9vffB+_K3vi6PMLONi2RViuSBFng@mail.gmail.com>
 <24170.28233.24528.535254@stat.math.ethz.ch>
 <CAD-ePxZtLg-fhgeNMQSKhLfzXt-ZC4_V8N--rh-OV9XZ-2B3CA@mail.gmail.com>
 <CAD-ePxb1YhEqM_Xss_tXG4L4zq5RmPyRh0yBp25Q0tvb2DqYSA@mail.gmail.com>
 <24317.57693.817671.488741@stat.math.ethz.ch>
Message-ID: <CAD-ePxY45w4t71bZ-XThkmvWwZP9xJt6ykejfOhxicTDNOXGew@mail.gmail.com>

Martin,

Yes, I should have test it earlier. Thank you for the response!

With best wishes,

Alexey

??, 2 ???. 2020 ?. ? 22:30, Martin Maechler <maechler at stat.math.ethz.ch>:
>
> >>>>> Alexey Shipunov
> >>>>>     on Wed, 1 Jul 2020 23:58:04 +0900 writes:
>
>     > Dear colleagues,
>     > There is a new problem with dotchart(), and it is very simple to reproduce.
>
>     > Just run example(dotchart).
>
>     > On R versions < 4, group labels ("Urban Female" and so on) were
>     > visible. Now they are not visible.
>
>     > If in the dotchart() code, we replace the string
>
>     > ===
>
>     > goffset <- (max(linch + offset, ginch, na.rm = TRUE) + 1/16)/lheight
>
>     > ===
>
>     > with the string
>
>     > ===
>
>     > goffset <- (max(linch + 0.2, ginch, na.rm = TRUE) + 1/16)/lheight
>
>     > ===
>
>  > everything start to be OK. Probably, the reason that in the code,
>  > there is another "offset" object and they clash. So if we replace this
>  > part of code
>
>     > ===
>
>     > offset <- cumsum(c(0, diff(as.numeric(groups)) != 0))
>     > y <- seq_len(n) + 2 * offset
>
>     > ===
>
>     > with
>
>     > ===
>
>     > offset1 <- cumsum(c(0, diff(as.numeric(groups)) != 0))
>     > y <- seq_len(n) + 2 * offset1
>
>     > ===
>
>     > everything will be well again.
>
> Thank you.
>
> I'll have a look *again*, and cautiously consider the above.
> Indeed your second patch seems the correct one, distinguishing the
> two different offsets that where conflated.
> I will commit to R-devel and also to "R 4.0.2 patched" (but note
> that no quick R 4.0.3 has been planned).
>
> Note (Alexey knows, almost everbody else probably not):
> This has come from another dotchart(* , ylab=.) glitch which
> Alexey had reported in February and I had fixed early
> March... evidently not fixed quite correctly... and yes, I'm
> embarrased.
> However I did mention here to have fixed it, on March 12
> (--> https://stat.ethz.ch/pipermail/r-help/2020-March/465921.html )
>
> It would have been really great if people would test such
> changes, as they were in all pre-releases (R 4.0.0 alpha, beta,
> RC), easily available ...  and we could have fixed this even
> before R 4.0.0 was released more than a month later than my
> e-mail above...
>
> Martin
>
>
>     > With best wishes,
>     > Alexey Shipunov
>
>     > ??, 13 ???. 2020 ?. ? 18:56, Alexey Shipunov <dactylorhiza at gmail.com>:
>     >>
>     >> Dear Martin,
>     >>
>     >> Great news, thanks!
>     >>
>     >> If you wish, please also consider my initial note about help(hist),
>     >> this is definitely worrying new R users.
>     >>
>     >> With best wishes,
>     >>
>     >> Alexey
>     >>
>     >> ??, 13 ???. 2020 ?. ? 02:16, Martin Maechler <maechler at stat.math.ethz.ch>:
>     >> >
>     >> > >>>>> Alexey Shipunov
>     >> > >>>>>     on Tue, 18 Feb 2020 14:34:48 +0900 writes:
>     >> >
>     >> >     > Thank you for the detailed explanation. I tend to agree. However, this
>     >> >     > behavior is relatively easy to remediate:
>     >> >
>     >> >     > This is the piece of the current code:
>     >> >
>     >> >     > ===
>     >> >     > if (!(is.null(labels) && is.null(glabels))) {
>     >> >     >    nmai <- par("mai")
>     >> >     >    nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) + 0.1
>     >> >     >    par(mai = nmai)
>     >> >     > }
>     >> >     > ===
>     >> >
>     >> >     > This is my proposal:
>     >> >
>     >> >     > ===
>     >> >     > yinch <- if (!is.null(ylab)) 0.4 else 0
>     >> >     > if (!(is.null(labels) && is.null(glabels))) {
>     >> >     >    nmai <- par("mai")
>     >> >     >    nm.2 <- nmai[4L] + max(if(is.null(ylab)) 0 else 0.4) + linch + goffset, ginch) + 0.1
>     >> >     >    if (nmai[2L] < nm.2)
>     >> >     >       nmai[2L] <- nm.2
>     >> >     >    par(mai = nmai)
>     >> >     > }
>     >> >     > ===
>     >> >
>     >> >     > Then margins and y-axis labels start to work normally. I wonder if
>     >> >     > this (or similar) is possible to introduce into the code?
>     >> >
>     >> >     > Alexey
>     >> >
>     >> > Well, I had looked at this back then (~Feb 18), and now had a
>     >> > considerable longer look.
>     >> >
>     >> > Your suggestion makes sense,  but then it needs even more work
>     >> > to ensure that the  'ylab'  y-axis label will be placed properly.
>     >> >
>     >> > Of course, Deepayan (author of grid-based 'lattice')  is right
>     >> > that dotchart()s implementation is pretty hackish ... but then
>     >> > still.
>     >> >
>     >> > I have (+-) fixed this in the sources of "R-devel" the
>     >> > development version of R (which should become R 4.0.0  on April
>     >> > 24 as was announced today).
>     >> >
>     >> > Now, things like this (extended) example work nicely :
>     >> >
>     >> > op <- par(xaxs = "i")  # 0 -- 100\%
>     >> > dotchart(t(VADeaths), xlim = c(0,100), bg = "skyblue",
>     >> >          main = "Death Rates in Virginia - 1940", xlab = "rate [ % ]",
>     >> >          ylab = "Grouping:  Age  x   Urbanity . Gender")
>     >> > par(op)
>     >> >
>     >> >
>     >> > Thank you, Alexey, for your report and bug fix suggestion!
>     >> >
>     >> > Best regards,
>     >> >
>     >> > Martin Maechler
>     >> > ETH Zurich and R Core team
>     >> >
>     >> >
>     >> >
>     >> >     > ........... 17:37, Deepayan Sarkar <deepayan.sarkar at gmail.com>:
>     >> >     >>
>     >> >     >> On Mon, Feb 17, 2020 at 10:24 AM Rui Barradas <ruipbarradas at sapo.pt> wrot=
>     >> >     > e:
>     >> >     >> >
>     >> >     >> > Hello,
>     >> >     >> >
>     >> >     >> > Yes, this is definitely a bug.
>     >> >     >>
>     >> >     >> I would argue that the only bug here is that the documentation doesn't
>     >> >     >> say that 'ylab' may not behave as expected.
>     >> >     >>
>     >> >     >> dotchart() is mainly designed for 2-way tables (see the VADeaths
>     >> >     >> example), but it's implementation is really pretty hackish because it
>     >> >     >> has to work within the limited traditional graphics framework. The
>     >> >     >> main problem is that dot plots want to put horizontal y-axis labels
>     >> >     >> (usually derived from factor levels), which are often longer than the
>     >> >     >> default margins, so the margins are modified. Unfortunately they are
>     >> >     >> only re-set on exit, and so the ylab that is plotted inside dotchart()
>     >> >     >> may be clipped. Traditionally, Cleveland dot plots don't have a y-axis
>     >> >     >> label; it's assumed that the factor levels are sufficient (and for
>     >> >     >> 2-way tables, there would be two variables, so there is no sensible
>     >> >     >> default).
>     >> >     >>
>     >> >     >> I doubt that dotchart() is worth fixing (except to maybe disallow
>     >> >     >> ylab). If you want flexibility, use modern grid-based alternatives
>     >> >     >> such as lattice::dotplot() or ggplot2.
>     >> >     >>
>     >> >     >> -Deepayan
>     >> >     >>
>     >> >     >> > Even the matrix plot is puzzling, with a "1" as top row sort-of-label
>     >> >     >> > but no grid line. I'm trying to follow the source code of dotchart but
>     >> >     >> > am yet to understand exactly what it does to decide the margins setting=
>     >> >     > s.
>     >> >     >> >
>     >> >     >> >      if (!(is.null(labels) && is.null(glabels))) {
>     >> >     >> >        nmai <- par("mai")
>     >> >     >> >        nmai[2L] <- nmai[4L] + max(linch + goffset, ginch) +
>     >> >     >> >          0.1
>     >> >     >> >        par(mai = nmai)
>     >> >     >> >      }
>     >> >     >> >
>     >> >     >> > This should be moved to r-devel?
>     >> >     >> >
>     >> >     >> > Rui Barradas
>     >> >     >> >
>     >> >     >> >  03:33 de 17/02/20, Alexey Shipunov escreveu:
>     >> >     >> > > John and Rui, thanks!
>     >> >     >> > >
>     >> >     >> > > However, if we use the proper object, the problem still persists:
>     >> >     >> > >
>     >> >     >> > > dotchart(c("3"=1, "2"=2, "1"=3), ylab="Ylab") # ylab is invisible
>     >> >     >> > > dotchart(c("aa"=1, "b"=2, "cc"=3), ylab="Ylab") # ylab is partly visible (!!!)
>     >> >     >> > > dotchart(c("aaa"=1, "bbb"=2, "ccc"=3), ylab="Ylab") # ylab is well visible
>     >> >     >> > >
>     >> >     >> > > If the object is matrix, ylab is visible:
>     >> >     >> > >
>     >> >     >> > > dotchart(matrix(1:3, dimnames=list(c("aa","bb","cc"), NULL)), ylab="Ylab")
>     >> >     >> > >
>     >> >     >> > > But the ?dotchart explicitly says that "x: either a vector or matrix
>     >> >     >> > > of numeric values" and then "labels: a vector of labels for each
>     >> >     >> > > point.  For vectors the default is to use  "names(x) = ...".
>     >> >     >> > >
>     >> >     >> > > So this is likely a bug. Do you agree?
>     >> >     >> > >
>     >> >     >> > > Alexey
>     >> >     >> > >
>     >> >     >> > > ..... 01:55, Rui Barradas <ruipbarradas at sapo.pt>:
>     >> >     >> > >>
>     >> >     >> > >> Hello,
>     >> >     >> > >>
>     >> >     >> > >> I believe you are wrong, the error is not in dotchart, it's in your
>     >> >     >> > >> code. You assume that to plot an object of class "table" is the same as
>     >> >     >> > >> to plot an object of class "numeric".
>     >> >     >> > >>
>     >> >     >> > >> Inline.
>     >> >     >> > >>
>     >> >     >> > >> =C3=80s 12:21 de 16/02/20, Alexey Shipunov escreveu:
>     >> >     >> > >>> Dear list,
>     >> >     >> > >>>
>     >> >     >> > >>> I have been advised to share these with R-help instead of filling the
>     >> >     >> > >>> bug report:
>     >> >     >> > >>>
>     >> >     >> > >>> 1) dotchart() does not allow to see the left axis title ('ylab') and
>     >> >     >> > >>> cannot change the left margin (outer margin 2) of the plot
>     >> >     >> > >>>
>     >> >     >> > >>> The code:
>     >> >     >> > >>>
>     >> >     >> > >>> aa <- table(c(1, 1, 1, 2, 2, 3))
>     >> >     >> > >>> dotchart(aa, ylab="Ylab") # does not show 'ylab'
>     >> >     >> > >>
>     >> >     >> > >> You are right, it does *not* show 'ylab' but the user is warned.
>     >> >     >> > >>
>     >> >     >> > >>
>     >> >     >> > >> aa <- table(c(1, 1, 1, 2, 2, 3))
>     >> >     >> > >> dotchart(aa, ylab = "Ylab") # does show 'ylab'
>     >> >     >> > >> #Warning message:
>     >> >     >> > >> #In dotchart(aa, ylab = "Ylab") :
>     >> >     >> > >> #  'x' is neither a vector nor a matrix: using as.numeric(x)
>     >> >     >> > >>
>     >> >     >> > >>
>     >> >     >> > >> My code:
>     >> >     >> > >>
>     >> >     >> > >>
>     >> >     >> > >> (mar <- par("mar"))    # new R session
>     >> >     >> > >> #[1] 5.1 4.1 4.1 2.1   # the left margin is 4.1
>     >> >     >> > >>
>     >> >     >> > >> aa <- as.numeric(table(c(1, 1, 1, 2, 2, 3)))
>     >> >     >> > >>
>     >> >     >> > >> dotchart(aa, ylab = "Ylab") # It does show 'ylab'
>     >> >     >> > >> old.par <- par(mar = mar + c(0, 5, 0, 0))
>     >> >     >> > >> par("mar")
>     >> >     >> > >> #[1] 5.1 9.1 4.1 2.1
>     >> >     >> > >>
>     >> >     >> > >> dotchart(aa, ylab = "Ylab")  # The left margin is now 9.1, much bigger
>     >> >     >> > >>
>     >> >     >> > >> par(old.par)                 # It does change the left margin
>     >> >     >> > >> dotchart(aa, ylab = "Ylab")  #  but only when a new graph is plotted.
>     >> >     >> > >>
>     >> >     >> > >>
>     >> >     >> > >>
>     >> >     >> > >>> old.par <- par(mar=c(1, 10, 1, 1)) ; dotchart(aa, ylab="Ylab") ;
>     >> >     >> > >>> par(old.par) # does not change left margin
>     >> >     >> > >>>
>     >> >     >> > >>> Possible solution:
>     >> >     >> > >>>
>     >> >     >> > >>> I researched the problem and think that the dotchart() code will need
>     >> >     >> > >>> few corrections. If there is an interest, I can post it here; or you
>     >> >     >> > >>> can look at the code of shipunov::Dotchart1() function.
>     >> >     >> > >>>
>     >> >     >> > >>> 2) example(hist) includes two "wrong" and "extreme" examples which
>     >> >     >> > >>> slow down and even crash R on some systems; this make it unsuitable
>     >> >     >> > >>> for demonstration in the class and strikes beginners in R who just
>     >> >     >> > >>> want to understand how hist() works. Actually, I did it last week (I
>     >> >     >> > >>> was not aware of these examples), and in the class two computers hang,
>     >> >     >> > >>> and many others were extremely slow.
>     >> >     >> > >>>
>     >> >     >> > >>> The code:
>     >> >     >> > >>>
>     >> >     >> > >>> example(hist)
>     >> >     >> > >>>
>     >> >     >> > >>> Possible solution:
>     >> >     >> > >>>
>     >> >     >> > >>> If R maintainers will enclose parts of "hist" example in \dontrun{},
>     >> >     >> > >>> this will allow to see the code but in the same time will not strike
>     >> >     >> > >>> beginners in R who just
>     >> >     >> > >>> want to understand how hist() works. They will still be possible to
>     >> >     >> > >>> run with example(..., run.dontrun=TRUE).
>     >> >     >> > >>
>     >> >     >> > >> Agree, it's annoying. Sometimes there's a Warning section after the
>     >> >     >> > >> Details section. Maybe such a section could get users' attention to
>     >> >     >> > >> those examples? At least it wouldn't hurt...
>     >> >     >> > >>
>     >> >     >> > >>
>     >> >     >> > >> Hope this helps,
>     >> >     >> > >>
>     >> >     >> > >> Rui Barradas
>     >> >     >> > >>
>     >> >     >> > >>>
>     >> >     >> > >>> With best wishes,
>     >> >     >> > >>>
>     >> >     >> > >>> Alexey Shipunov
>     >> >     >> > >>> ______________________________________________


From te@3rd @end|ng |rom gm@||@com  Fri Jul  3 11:15:58 2020
From: te@3rd @end|ng |rom gm@||@com (Thomas Adams)
Date: Fri, 3 Jul 2020 05:15:58 -0400
Subject: [R] National Weather Service Data
In-Reply-To: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
Message-ID: <CAGxgkWg6pFuKB8hvqiVyn3ui-ErVqciuVcXymqnSCeX=vKmiwQ@mail.gmail.com>

Hi Philip!

I'm a little familiar with rNOMADS... I tried following the example for
'ArchiveGribGrab' using a more recent date

#An example for the Global Forecast System
#Get data for January 1 2014
#Temperature at 2 m above ground
#3 hour prediction
# using GRIB
abbrev <- "gfsanl"
model.date <- 20200601
model.run <- 00
preds <- 3

I got this result...
URL 'https://nomads.ncdc.noaa.gov/data/gfsanl/202006/20200601/': status was
'Couldn't resolve host name'

Even this part of the URL was not found: https://nomads.ncdc.noaa.gov -- so
there is documentation problems.

I did get the first example, using contour to work fine. You probably
should contact Daniel C. Bowman <danny.c.bowman at gmail.com> directly with
issues, because the problems you are seeing may be resolvable only by him...

Best,
Tom

On Thu, Jul 2, 2020 at 6:06 PM Philip <herd_dog at cox.net> wrote:

> Is anyone out there familiar with rNOMADS?  It is a package to get into
> National Weather Service forecasting data with R?
>
> I'm not sure the Weather Service software named wgrib2 loaded correctly
> because some of the stuff won't run and I can't make much sense out of some
> of the output.
>
> Thanks.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Thomas E Adams, III
1724 Sage Lane
Blacksburg, VA 24060
tea3rd at gmail.com (personal)
tea at terrapredictions.org (work)

1 (513) 739-9512 (cell)

	[[alternative HTML version deleted]]


From kde@@|1 @end|ng |rom @he|||e|d@@c@uk  Fri Jul  3 22:56:32 2020
From: kde@@|1 @end|ng |rom @he|||e|d@@c@uk (Kathan Desai)
Date: Fri, 3 Jul 2020 21:56:32 +0100
Subject: [R] Help with looping a function over a list of dataframes:
Message-ID: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>

I have been trying to run a forloop for a function that compares dataframe n
with dataframe n-1, across a list of dataframes. It does this by checking
each midpoint of dataframe n with each midpoint of dataframe n-1. This is
done to make up for an disparity in row length. The idea of this code is to
identify any objects that are stationary, and assign them an id of 1, and
the dynamic objects are assigned an id of 0 (examples can be found below).


*This is what i have so far:*
for(i in seq_along(list_df)){
   list_df$position_tab_[[i]]$ID <-
     unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
                 ifelse(any(abs(x - list_df$position_tab_[[i-1]]$midpoint)
<= 1),1,0)
            ))
}

There is no error message being produced so theres nothing to debug, i am
quite new to R programming in general so excuse any silly mistakes i may
have made. The function doesnt seem to be adding the ID columns and
comparing the data as it should.

my list of dataframes contain dataframes named: position_tab_1,
position_tab_2 .... position_tab_121. Each position_tab represents a
timepoints, so in total there are 121 timepoints (frames). I need the loop
to run so that pos_tab_2 compares to pos_tab_1 and this continues all the
way to pos_tab_121 comparing to pos_tab_120.

The function adds a column named "id" to each of these dataframes as it
compares to the dataframe before it, so all dataframes apart from
position_tab_1 (as it has nothing to compare to) should have this added.


*Some of my data (first 10 dataframes in list):*
> dput(list_df[1:10])
list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names = c(NA,
-21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
structure(list(
    Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
    2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
    2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
    147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
    907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
    ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
    702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
    1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
    233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
    1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names = c(NA,
-21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
structure(list(
    Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
    2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
    2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
    149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
    907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
    ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
    700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
    1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
    232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
    1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)), row.names =
c(NA,
-21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
structure(list(
    Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
    2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
    2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
    142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
    908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
    ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
    701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
    1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
    232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
    1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names = c(NA,
-21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
structure(list(
    Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
    2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
    2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum = c(3L,
    43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
    861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
    1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
    629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
    1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
    midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
    818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
    1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
structure(list(
    Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
    2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
    2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum = c(4L,
    45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
    804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
    1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
    419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
    1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
    midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
    618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
    1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
-23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
structure(list(
    Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
    2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
    2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum = c(3L,
    45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
    837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
    1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
    415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
    1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
    midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
    684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
    1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
-23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
structure(list(
    Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
    2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
    2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum = c(5L,
    44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
    841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
    1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
    409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
    1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
    midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
    683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
    1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
-23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
structure(list(
    Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
    2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
    2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
    44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
    840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
    1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
    589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
    1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
    62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
    916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
    1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
"data.frame")), position_tab_10 = structure(list(Object = c(2469L,
2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
), class = c("tbl_df", "tbl", "data.frame")))

*What is produced when running the base code without any loops:*

This is the base code without me trying to loop it in anyway, below is what
it produces when its used with dataframe 4 and 5:

#the code:
list_df$position_tab_5$ID <- unlist(lapply(list_df$position_tab_5$midpoint,
function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <= 1),1,0)))

##position_tab_5 after manipulations have occured:
structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
-23L), class = c("tbl_df", "tbl", "data.frame"))

#position_tab_4 (the DF pos_tab_5 is being compared to)
structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
    maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
    701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
    1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
    232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
    1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names = c(NA,
-21L), class = c("tbl_df", "tbl", "data.frame"))

*Appreciate any help, anyone can provide!*

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Jul  4 12:14:40 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 4 Jul 2020 20:14:40 +1000
Subject: [R] Help with looping a function over a list of dataframes:
In-Reply-To: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
References: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
Message-ID: <CA+8X3fVb5aAXQUVLkTrE7qCxRZjCEqb5XDc6s=MurFrebUSj8A@mail.gmail.com>

Hi Kathan,
This is a very lazy answer as I haven't tested it. I think you will
need to wrap your loop in a function and return the modified list_df
to assign it like this:

add_IDs<-function(xdf) {
 for(i in seq_along(xdf)) {
  xdf$position_tab_[[i]]$ID <-
   unlist(lapply(xdf$position_tab_[[i]]$midpoint, function(x)
    ifelse(any(abs(x - xdf$position_tab_[[i-1]]$midpoint)<= 1),1,0)))
 }
 return(xdf)
}
list_df<-add_IDs(list_df)

Jim

On Sat, Jul 4, 2020 at 4:48 PM Kathan Desai <kdesai1 at sheffield.ac.uk> wrote:
>
> I have been trying to run a forloop for a function that compares dataframe n
> with dataframe n-1, across a list of dataframes. It does this by checking
> each midpoint of dataframe n with each midpoint of dataframe n-1. This is
> done to make up for an disparity in row length. The idea of this code is to
> identify any objects that are stationary, and assign them an id of 1, and
> the dynamic objects are assigned an id of 0 (examples can be found below).
>
>
> *This is what i have so far:*
> for(i in seq_along(list_df)){
>    list_df$position_tab_[[i]]$ID <-
>      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
>                  ifelse(any(abs(x - list_df$position_tab_[[i-1]]$midpoint)
> <= 1),1,0)
>             ))
> }
>
> There is no error message being produced so theres nothing to debug, i am
> quite new to R programming in general so excuse any silly mistakes i may
> have made. The function doesnt seem to be adding the ID columns and
> comparing the data as it should.
>
> my list of dataframes contain dataframes named: position_tab_1,
> position_tab_2 .... position_tab_121. Each position_tab represents a
> timepoints, so in total there are 121 timepoints (frames). I need the loop
> to run so that pos_tab_2 compares to pos_tab_1 and this continues all the
> way to pos_tab_121 comparing to pos_tab_120.
>
> The function adds a column named "id" to each of these dataframes as it
> compares to the dataframe before it, so all dataframes apart from
> position_tab_1 (as it has nothing to compare to) should have this added.
>
>
> *Some of my data (first 10 dataframes in list):*
> > dput(list_df[1:10])
> list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
> 2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
> 2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
> 2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
> 669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
> 1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
> 587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
> 1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
> 160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
> 1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names = c(NA,
> -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
> structure(list(
>     Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
>     2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
>     2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
>     147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
>     907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
>     ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
>     702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
>     1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
>     233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
>     1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names = c(NA,
> -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
> structure(list(
>     Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
>     2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
>     2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
>     149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
>     907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
>     ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
>     700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
>     1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
>     232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
>     1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)), row.names =
> c(NA,
> -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
> structure(list(
>     Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
>     2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
>     2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
>     142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
>     908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
>     ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
>     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
>     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
>     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
>     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names = c(NA,
> -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
> structure(list(
>     Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
>     2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
>     2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum = c(3L,
>     43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
>     861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
>     1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
>     629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
>     1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
>     midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
>     818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
>     1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
> ), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
> structure(list(
>     Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
>     2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
>     2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum = c(4L,
>     45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
>     804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
>     1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
>     419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
>     1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
>     midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
>     618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
>     1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
> -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
> structure(list(
>     Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
>     2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
>     2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum = c(3L,
>     45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
>     837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
>     1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
>     415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
>     1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
>     midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
>     684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
>     1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
> -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
> structure(list(
>     Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
>     2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
>     2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum = c(5L,
>     44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
>     841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
>     1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
>     409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
>     1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
>     midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
>     683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
>     1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
> -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
> structure(list(
>     Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
>     2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
>     2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
>     44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
>     840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
>     1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
>     589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
>     1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
>     62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
>     916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
>     1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
> "data.frame")), position_tab_10 = structure(list(Object = c(2469L,
> 2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
> 2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
> 2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
> 363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
> 1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
> 76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
> 924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
> 1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
> 626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
> 1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
> ), class = c("tbl_df", "tbl", "data.frame")))
>
> *What is produced when running the base code without any loops:*
>
> This is the base code without me trying to loop it in anyway, below is what
> it produces when its used with dataframe 4 and 5:
>
> #the code:
> list_df$position_tab_5$ID <- unlist(lapply(list_df$position_tab_5$midpoint,
> function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <= 1),1,0)))
>
> ##position_tab_5 after manipulations have occured:
> structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
> 2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
> 2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
> ), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
> 808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
> 1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
> 419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
> 1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
> ), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> 818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
> 1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
> 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
> -23L), class = c("tbl_df", "tbl", "data.frame"))
>
> #position_tab_4 (the DF pos_tab_5 is being compared to)
> structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
> 2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
> 2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
> 42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> 908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
>     maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
>     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
>     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
>     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
>     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names = c(NA,
> -21L), class = c("tbl_df", "tbl", "data.frame"))
>
> *Appreciate any help, anyone can provide!*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kde@@|1 @end|ng |rom @he|||e|d@@c@uk  Sat Jul  4 15:33:07 2020
From: kde@@|1 @end|ng |rom @he|||e|d@@c@uk (Kathan Desai)
Date: Sat, 4 Jul 2020 14:33:07 +0100
Subject: [R] Fwd:  Help with looping a function over a list of dataframes:
In-Reply-To: <CAH05x1FBaqFynVU_8BQWC=s+4mehS-6pF9NcVKMQ3px9u1HH3g@mail.gmail.com>
References: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
 <CA+8X3fVb5aAXQUVLkTrE7qCxRZjCEqb5XDc6s=MurFrebUSj8A@mail.gmail.com>
 <CAH05x1FBaqFynVU_8BQWC=s+4mehS-6pF9NcVKMQ3px9u1HH3g@mail.gmail.com>
Message-ID: <CAH05x1G668Hs9cvXaJAqCNjcHUwWppjq91qDnZwMALUVX88rfA@mail.gmail.com>

---------- Forwarded message ---------
From: Kathan Desai <kdesai1 at sheffield.ac.uk>
Date: Sat, 4 Jul 2020 at 14:31
Subject: Re: [R] Help with looping a function over a list of dataframes:
To: Jim Lemon <drjimlemon at gmail.com>


Hi Jim,

Thankyou for your reply, I tried the function you suggested and it
doesn't seem to work. There are again no error messages produced, however
the transformation to each position_tab_n table isn't being applied.

Cheers,
Kathan


On Sat, 4 Jul 2020 at 11:14, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kathan,
> This is a very lazy answer as I haven't tested it. I think you will
> need to wrap your loop in a function and return the modified list_df
> to assign it like this:
>
> add_IDs<-function(xdf) {
>  for(i in seq_along(xdf)) {
>   xdf$position_tab_[[i]]$ID <-
>    unlist(lapply(xdf$position_tab_[[i]]$midpoint, function(x)
>     ifelse(any(abs(x - xdf$position_tab_[[i-1]]$midpoint)<= 1),1,0)))
>  }
>  return(xdf)
> }
> list_df<-add_IDs(list_df)
>
> Jim
>
> On Sat, Jul 4, 2020 at 4:48 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
> wrote:
> >
> > I have been trying to run a forloop for a function that compares
> dataframe n
> > with dataframe n-1, across a list of dataframes. It does this by checking
> > each midpoint of dataframe n with each midpoint of dataframe n-1. This is
> > done to make up for an disparity in row length. The idea of this code is
> to
> > identify any objects that are stationary, and assign them an id of 1, and
> > the dynamic objects are assigned an id of 0 (examples can be found
> below).
> >
> >
> > *This is what i have so far:*
> > for(i in seq_along(list_df)){
> >    list_df$position_tab_[[i]]$ID <-
> >      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
> >                  ifelse(any(abs(x -
> list_df$position_tab_[[i-1]]$midpoint)
> > <= 1),1,0)
> >             ))
> > }
> >
> > There is no error message being produced so theres nothing to debug, i am
> > quite new to R programming in general so excuse any silly mistakes i may
> > have made. The function doesnt seem to be adding the ID columns and
> > comparing the data as it should.
> >
> > my list of dataframes contain dataframes named: position_tab_1,
> > position_tab_2 .... position_tab_121. Each position_tab represents a
> > timepoints, so in total there are 121 timepoints (frames). I need the
> loop
> > to run so that pos_tab_2 compares to pos_tab_1 and this continues all the
> > way to pos_tab_121 comparing to pos_tab_120.
> >
> > The function adds a column named "id" to each of these dataframes as it
> > compares to the dataframe before it, so all dataframes apart from
> > position_tab_1 (as it has nothing to compare to) should have this added.
> >
> >
> > *Some of my data (first 10 dataframes in list):*
> > > dput(list_df[1:10])
> > list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
> > 2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
> > 2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
> > 2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
> > 669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
> > 1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
> > 587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
> > 1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
> > 160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
> > 1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names = c(NA,
> > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
> > structure(list(
> >     Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
> >     2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
> >     2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
> >     147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
> >     907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
> >     ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
> >     702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
> >     1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
> >     233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
> >     1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names = c(NA,
> > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
> > structure(list(
> >     Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
> >     2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
> >     2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
> >     149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
> >     907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
> >     ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
> >     700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
> >     1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
> >     232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
> >     1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)), row.names =
> > c(NA,
> > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
> > structure(list(
> >     Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
> >     2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
> >     2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
> >     142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> >     908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
> >     ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
> >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
> >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
> >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
> >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names = c(NA,
> > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
> > structure(list(
> >     Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
> >     2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
> >     2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum = c(3L,
> >     43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
> >     861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
> >     1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
> >     629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
> >     1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
> >     midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> >     818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
> >     1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
> > ), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
> > structure(list(
> >     Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
> >     2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
> >     2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum = c(4L,
> >     45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
> >     804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
> >     1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
> >     419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
> >     1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
> >     midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
> >     618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
> >     1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
> > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
> > structure(list(
> >     Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
> >     2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
> >     2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum = c(3L,
> >     45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
> >     837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
> >     1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
> >     415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
> >     1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
> >     midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
> >     684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
> >     1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
> > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
> > structure(list(
> >     Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
> >     2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
> >     2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum = c(5L,
> >     44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
> >     841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
> >     1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
> >     409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
> >     1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
> >     midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
> >     683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
> >     1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
> > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
> > structure(list(
> >     Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
> >     2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
> >     2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
> >     44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
> >     840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
> >     1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
> >     589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
> >     1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
> >     62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
> >     916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
> >     1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
> > "data.frame")), position_tab_10 = structure(list(Object = c(2469L,
> > 2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
> > 2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
> > 2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
> > 363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
> > 1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
> > 76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
> > 924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
> > 1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
> > 626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
> > 1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
> > ), class = c("tbl_df", "tbl", "data.frame")))
> >
> > *What is produced when running the base code without any loops:*
> >
> > This is the base code without me trying to loop it in anyway, below is
> what
> > it produces when its used with dataframe 4 and 5:
> >
> > #the code:
> > list_df$position_tab_5$ID <-
> unlist(lapply(list_df$position_tab_5$midpoint,
> > function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
> 1),1,0)))
> >
> > ##position_tab_5 after manipulations have occured:
> > structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
> > 2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
> > 2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
> > ), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
> > 808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
> > 1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
> > 419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
> > 1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
> > ), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> > 818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
> > 1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
> > 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
> > -23L), class = c("tbl_df", "tbl", "data.frame"))
> >
> > #position_tab_4 (the DF pos_tab_5 is being compared to)
> > structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
> > 2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
> > 2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
> > 42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> > 908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
> >     maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
> >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
> >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
> >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
> >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names = c(NA,
> > -21L), class = c("tbl_df", "tbl", "data.frame"))
> >
> > *Appreciate any help, anyone can provide!*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sat Jul  4 15:43:38 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 4 Jul 2020 16:43:38 +0300
Subject: [R] 
 Fwd: Help with looping a function over a list of dataframes:
In-Reply-To: <CAH05x1G668Hs9cvXaJAqCNjcHUwWppjq91qDnZwMALUVX88rfA@mail.gmail.com>
References: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
 <CA+8X3fVb5aAXQUVLkTrE7qCxRZjCEqb5XDc6s=MurFrebUSj8A@mail.gmail.com>
 <CAH05x1FBaqFynVU_8BQWC=s+4mehS-6pF9NcVKMQ3px9u1HH3g@mail.gmail.com>
 <CAH05x1G668Hs9cvXaJAqCNjcHUwWppjq91qDnZwMALUVX88rfA@mail.gmail.com>
Message-ID: <CAGgJW74aNnekWtvfSS50ss+E9pGnzA3rm-_WWxb=w7cWU7+5bw@mail.gmail.com>

Hi Kathan,
How about trying to create a *minimal* reproducible example, e.g. with a
list of two data frames, where each data frame has 5 rows,?
My guess is that there is a good chance that when you try to create such an
example, you will discover the problem yourself.
In the event that you create the example but still cannot solve your issue,
you will find more people on this list willing to look into your question,
as it will be much faster for them to do that (compared to the original
formulation.)

Eric


On Sat, Jul 4, 2020 at 4:33 PM Kathan Desai <kdesai1 at sheffield.ac.uk> wrote:

> ---------- Forwarded message ---------
> From: Kathan Desai <kdesai1 at sheffield.ac.uk>
> Date: Sat, 4 Jul 2020 at 14:31
> Subject: Re: [R] Help with looping a function over a list of dataframes:
> To: Jim Lemon <drjimlemon at gmail.com>
>
>
> Hi Jim,
>
> Thankyou for your reply, I tried the function you suggested and it
> doesn't seem to work. There are again no error messages produced, however
> the transformation to each position_tab_n table isn't being applied.
>
> Cheers,
> Kathan
>
>
> On Sat, 4 Jul 2020 at 11:14, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Kathan,
> > This is a very lazy answer as I haven't tested it. I think you will
> > need to wrap your loop in a function and return the modified list_df
> > to assign it like this:
> >
> > add_IDs<-function(xdf) {
> >  for(i in seq_along(xdf)) {
> >   xdf$position_tab_[[i]]$ID <-
> >    unlist(lapply(xdf$position_tab_[[i]]$midpoint, function(x)
> >     ifelse(any(abs(x - xdf$position_tab_[[i-1]]$midpoint)<= 1),1,0)))
> >  }
> >  return(xdf)
> > }
> > list_df<-add_IDs(list_df)
> >
> > Jim
> >
> > On Sat, Jul 4, 2020 at 4:48 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
> > wrote:
> > >
> > > I have been trying to run a forloop for a function that compares
> > dataframe n
> > > with dataframe n-1, across a list of dataframes. It does this by
> checking
> > > each midpoint of dataframe n with each midpoint of dataframe n-1. This
> is
> > > done to make up for an disparity in row length. The idea of this code
> is
> > to
> > > identify any objects that are stationary, and assign them an id of 1,
> and
> > > the dynamic objects are assigned an id of 0 (examples can be found
> > below).
> > >
> > >
> > > *This is what i have so far:*
> > > for(i in seq_along(list_df)){
> > >    list_df$position_tab_[[i]]$ID <-
> > >      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
> > >                  ifelse(any(abs(x -
> > list_df$position_tab_[[i-1]]$midpoint)
> > > <= 1),1,0)
> > >             ))
> > > }
> > >
> > > There is no error message being produced so theres nothing to debug, i
> am
> > > quite new to R programming in general so excuse any silly mistakes i
> may
> > > have made. The function doesnt seem to be adding the ID columns and
> > > comparing the data as it should.
> > >
> > > my list of dataframes contain dataframes named: position_tab_1,
> > > position_tab_2 .... position_tab_121. Each position_tab represents a
> > > timepoints, so in total there are 121 timepoints (frames). I need the
> > loop
> > > to run so that pos_tab_2 compares to pos_tab_1 and this continues all
> the
> > > way to pos_tab_121 comparing to pos_tab_120.
> > >
> > > The function adds a column named "id" to each of these dataframes as it
> > > compares to the dataframe before it, so all dataframes apart from
> > > position_tab_1 (as it has nothing to compare to) should have this
> added.
> > >
> > >
> > > *Some of my data (first 10 dataframes in list):*
> > > > dput(list_df[1:10])
> > > list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
> > > 2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
> > > 2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
> > > 2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
> > > 669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
> > > 1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
> > > 587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
> > > 1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
> > > 160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
> > > 1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names = c(NA,
> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
> > > structure(list(
> > >     Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
> > >     2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
> > >     2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
> > >     147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
> > >     907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
> > >     ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
> > >     702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
> > >     1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
> > >     233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
> > >     1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names =
> c(NA,
> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
> > > structure(list(
> > >     Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
> > >     2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
> > >     2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
> > >     149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
> > >     907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
> > >     ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
> > >     700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
> > >     1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
> > >     232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
> > >     1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)), row.names =
> > > c(NA,
> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
> > > structure(list(
> > >     Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
> > >     2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
> > >     2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
> > >     142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> > >     908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
> > >     ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
> c(NA,
> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
> > > structure(list(
> > >     Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
> > >     2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
> > >     2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum = c(3L,
> > >     43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
> > >     861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
> > >     1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
> > >     629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
> > >     1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
> > >     midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> > >     818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
> > >     1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
> > > ), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
> > > structure(list(
> > >     Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
> > >     2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
> > >     2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum = c(4L,
> > >     45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
> > >     804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
> > >     1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
> > >     419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
> > >     1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
> > >     midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
> > >     618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
> > >     1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
> > > structure(list(
> > >     Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
> > >     2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
> > >     2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum = c(3L,
> > >     45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
> > >     837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
> > >     1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
> > >     415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
> > >     1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
> > >     midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
> > >     684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
> > >     1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
> > > structure(list(
> > >     Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
> > >     2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
> > >     2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum = c(5L,
> > >     44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
> > >     841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
> > >     1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
> > >     409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
> > >     1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
> > >     midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
> > >     683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
> > >     1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
> > > structure(list(
> > >     Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
> > >     2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
> > >     2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
> > >     44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
> > >     840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
> > >     1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
> > >     589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
> > >     1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
> > >     62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
> > >     916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
> > >     1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
> > > "data.frame")), position_tab_10 = structure(list(Object = c(2469L,
> > > 2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
> > > 2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
> > > 2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
> > > 363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
> > > 1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
> > > 76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
> > > 924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
> > > 1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
> > > 626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
> > > 1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
> > > ), class = c("tbl_df", "tbl", "data.frame")))
> > >
> > > *What is produced when running the base code without any loops:*
> > >
> > > This is the base code without me trying to loop it in anyway, below is
> > what
> > > it produces when its used with dataframe 4 and 5:
> > >
> > > #the code:
> > > list_df$position_tab_5$ID <-
> > unlist(lapply(list_df$position_tab_5$midpoint,
> > > function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
> > 1),1,0)))
> > >
> > > ##position_tab_5 after manipulations have occured:
> > > structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
> > > 2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
> > > 2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
> > > ), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
> > > 808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
> > > 1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
> > > 419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
> > > 1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
> > > ), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> > > 818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
> > > 1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
> > > 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
> > > -23L), class = c("tbl_df", "tbl", "data.frame"))
> > >
> > > #position_tab_4 (the DF pos_tab_5 is being compared to)
> > > structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
> > > 2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
> > > 2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
> > > 42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> > > 908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
> > >     maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
> c(NA,
> > > -21L), class = c("tbl_df", "tbl", "data.frame"))
> > >
> > > *Appreciate any help, anyone can provide!*
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gr@h@m_|e@@k @end|ng |rom y@hoo@com  Sat Jul  4 16:34:26 2020
From: gr@h@m_|e@@k @end|ng |rom y@hoo@com (Graham Leask)
Date: Sat, 4 Jul 2020 15:34:26 +0100
Subject: [R] Mapping Geographical Coordinate Data
References: <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA.ref@yahoo.com>
Message-ID: <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA@yahoo.com>

Dear List,

I have a postcode file containing geographical coordinates but this is not in the
format of a standard shape file. I list the first 5 observations below;

Postcode Postcode_geometry                                             
  <chr>    <chr>                                                         
1 101      [[[[15.066294,54.986481],[15.08849170010846,54.98916685060565]?
2 102      [[[[12.529952999999999,55.631105],[12.525127622017353,55.62519?
3 103      [[[[12.545395,55.684824],[12.564698,55.684824],[12.568558,55.6?
4 104      [[[[12.510651,55.635403],[12.526093,55.635403],[12.52995299999?
5 105      [[[[12.50293,55.641849],[12.511615913774403,55.65205570659488]?


The length of the second variable precludes showing all of each line.


tibble [62 ? 2] (S3: tbl_df/tbl/data.frame)
 $ Postcode         : chr [1:62] "101" "102" "103" "104" ...
  ..- attr(*, "label")= chr "Brick code"
  ..- attr(*, "format.stata")= chr "%9s"
 $ Postcode_geometry: chr [1:62] "[[[[15.066294,54.986481],[15.08849170010846,54.98916685060565],[15.109724384490239,55.009579959623146],[15.1203"| __truncated__ "[[[[12.529952999999999,55.631105],[12.525127622017353,55.62519635262449],[12.507755425704989,55.61552698519515]"| __truncated__ "[[[[12.545395,55.684824],[12.564698,55.684824],[12.568558,55.689122],[12.552151038503252,55.70792316285329],[12"| __truncated__ "[[[[12.510651,55.635403],[12.526093,55.635403],[12.529952999999999,55.631105],[12.552151038503252,55.6445350874"| __truncated__ ?

How can I map this file using R? I?ve tried using the sf package with st_multipolygon and st_multilinestring without success. 

Any help as to which package and appropriate commands to successfully map this data using R will be appreciated.

Kind regards


Graham


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul  4 16:41:28 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 4 Jul 2020 07:41:28 -0700
Subject: [R] Mapping Geographical Coordinate Data
In-Reply-To: <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA@yahoo.com>
References: <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA.ref@yahoo.com>
 <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA@yahoo.com>
Message-ID: <CAGxFJbSnXrOvB8DBZjiLrSE2hkwB1_1-kR7q3BcL9XAr2tnOvQ@mail.gmail.com>

You should post on r-sig-geo, not here. You are much more likely to find
the interest and expertise you seek there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jul 4, 2020 at 7:34 AM Graham Leask via R-help <r-help at r-project.org>
wrote:

> Dear List,
>
> I have a postcode file containing geographical coordinates but this is not
> in the
> format of a standard shape file. I list the first 5 observations below;
>
> Postcode Postcode_geometry
>   <chr>    <chr>
> 1 101      [[[[15.066294,54.986481],[15.08849170010846,54.98916685060565]?
> 2 102      [[[[12.529952999999999,55.631105],[12.525127622017353,55.62519?
> 3 103      [[[[12.545395,55.684824],[12.564698,55.684824],[12.568558,55.6?
> 4 104      [[[[12.510651,55.635403],[12.526093,55.635403],[12.52995299999?
> 5 105      [[[[12.50293,55.641849],[12.511615913774403,55.65205570659488]?
>
>
> The length of the second variable precludes showing all of each line.
>
>
> tibble [62 ? 2] (S3: tbl_df/tbl/data.frame)
>  $ Postcode         : chr [1:62] "101" "102" "103" "104" ...
>   ..- attr(*, "label")= chr "Brick code"
>   ..- attr(*, "format.stata")= chr "%9s"
>  $ Postcode_geometry: chr [1:62]
> "[[[[15.066294,54.986481],[15.08849170010846,54.98916685060565],[15.109724384490239,55.009579959623146],[15.1203"|
> __truncated__
> "[[[[12.529952999999999,55.631105],[12.525127622017353,55.62519635262449],[12.507755425704989,55.61552698519515]"|
> __truncated__
> "[[[[12.545395,55.684824],[12.564698,55.684824],[12.568558,55.689122],[12.552151038503252,55.70792316285329],[12"|
> __truncated__
> "[[[[12.510651,55.635403],[12.526093,55.635403],[12.529952999999999,55.631105],[12.552151038503252,55.6445350874"|
> __truncated__ ?
>
> How can I map this file using R? I?ve tried using the sf package with
> st_multipolygon and st_multilinestring without success.
>
> Any help as to which package and appropriate commands to successfully map
> this data using R will be appreciated.
>
> Kind regards
>
>
> Graham
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jul  4 16:54:09 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 04 Jul 2020 07:54:09 -0700
Subject: [R] Mapping Geographical Coordinate Data
In-Reply-To: <CAGxFJbSnXrOvB8DBZjiLrSE2hkwB1_1-kR7q3BcL9XAr2tnOvQ@mail.gmail.com>
References: <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA.ref@yahoo.com>
 <84E351F3-0FF2-4C04-BB8C-4BF3E5EEEAEA@yahoo.com>
 <CAGxFJbSnXrOvB8DBZjiLrSE2hkwB1_1-kR7q3BcL9XAr2tnOvQ@mail.gmail.com>
Message-ID: <20E38B37-674C-48B0-A0A4-D41DC08EE902@dcn.davis.ca.us>

And post a minimal reproducible example (perhaps using dput(head(dta))).

On July 4, 2020 7:41:28 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>You should post on r-sig-geo, not here. You are much more likely to
>find
>the interest and expertise you seek there.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sat, Jul 4, 2020 at 7:34 AM Graham Leask via R-help
><r-help at r-project.org>
>wrote:
>
>> Dear List,
>>
>> I have a postcode file containing geographical coordinates but this
>is not
>> in the
>> format of a standard shape file. I list the first 5 observations
>below;
>>
>> Postcode Postcode_geometry
>>   <chr>    <chr>
>> 1 101     
>[[[[15.066294,54.986481],[15.08849170010846,54.98916685060565]?
>> 2 102     
>[[[[12.529952999999999,55.631105],[12.525127622017353,55.62519?
>> 3 103     
>[[[[12.545395,55.684824],[12.564698,55.684824],[12.568558,55.6?
>> 4 104     
>[[[[12.510651,55.635403],[12.526093,55.635403],[12.52995299999?
>> 5 105     
>[[[[12.50293,55.641849],[12.511615913774403,55.65205570659488]?
>>
>>
>> The length of the second variable precludes showing all of each line.
>>
>>
>> tibble [62 ? 2] (S3: tbl_df/tbl/data.frame)
>>  $ Postcode         : chr [1:62] "101" "102" "103" "104" ...
>>   ..- attr(*, "label")= chr "Brick code"
>>   ..- attr(*, "format.stata")= chr "%9s"
>>  $ Postcode_geometry: chr [1:62]
>>
>"[[[[15.066294,54.986481],[15.08849170010846,54.98916685060565],[15.109724384490239,55.009579959623146],[15.1203"|
>> __truncated__
>>
>"[[[[12.529952999999999,55.631105],[12.525127622017353,55.62519635262449],[12.507755425704989,55.61552698519515]"|
>> __truncated__
>>
>"[[[[12.545395,55.684824],[12.564698,55.684824],[12.568558,55.689122],[12.552151038503252,55.70792316285329],[12"|
>> __truncated__
>>
>"[[[[12.510651,55.635403],[12.526093,55.635403],[12.529952999999999,55.631105],[12.552151038503252,55.6445350874"|
>> __truncated__ ?
>>
>> How can I map this file using R? I?ve tried using the sf package with
>> st_multipolygon and st_multilinestring without success.
>>
>> Any help as to which package and appropriate commands to successfully
>map
>> this data using R will be appreciated.
>>
>> Kind regards
>>
>>
>> Graham
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From kde@@|1 @end|ng |rom @he|||e|d@@c@uk  Sat Jul  4 16:54:32 2020
From: kde@@|1 @end|ng |rom @he|||e|d@@c@uk (Kathan Desai)
Date: Sat, 4 Jul 2020 15:54:32 +0100
Subject: [R] 
 Fwd: Help with looping a function over a list of dataframes:
In-Reply-To: <CAGgJW74aNnekWtvfSS50ss+E9pGnzA3rm-_WWxb=w7cWU7+5bw@mail.gmail.com>
References: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
 <CA+8X3fVb5aAXQUVLkTrE7qCxRZjCEqb5XDc6s=MurFrebUSj8A@mail.gmail.com>
 <CAH05x1FBaqFynVU_8BQWC=s+4mehS-6pF9NcVKMQ3px9u1HH3g@mail.gmail.com>
 <CAH05x1G668Hs9cvXaJAqCNjcHUwWppjq91qDnZwMALUVX88rfA@mail.gmail.com>
 <CAGgJW74aNnekWtvfSS50ss+E9pGnzA3rm-_WWxb=w7cWU7+5bw@mail.gmail.com>
Message-ID: <CAH05x1GJC5gLh13WCpPHrrQLvfKwKDqqVrMVwXjPcmoP___o4g@mail.gmail.com>

*I hope this is more succinct.*

*I have the following code: *
list_df$position_tab_5$ID <- unlist(lapply(list_df$position_tab_5$midpoint,
function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <= 1),1,0)))


It compares every observation from the midpoint column from dataframe 2 to
every observation from the midpoint column from dataframe 1. It does this
in order to find any values within +/- 1 of the value, and if it satisfies
this criteria then it assigns it a unique id of 1. If not then a value of
0.

In the example below, pos_tab_5 is being compared to pos_tab_4:

Pos tab 4:
Object minimum maximum midpoint
2600    4             22             13
2604    42           85             63.5
2606    142         172           157
2609    223         241           232
2611    393         421           407

Pos tab 5:
Object minimum maximum midpoint ID
2580    3             21             12           1
2581    43           85             64           1
2585    132         168           150         0
2586    223         241           232         1
2589    391         419           405         0

The reason it compares every observation from pos_tab_(n) to pos_tab_(n-1)
is because some of the dataframes are of different row length, and so by
comparing every observation from one DF to another, it can find any values
that are within +/- 1 of each other. (which is the main thing i'm looking
for)

I need help looping this function over a list of dataframes. The list of
dataframes called: list_df contains 121 different dataframes all
representing a different time point of the object.

This is what i have so far:
for(i in seq_along(list_df)){
   list_df$position_tab_[[i]]$ID <-
     unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
                 ifelse(any(abs(x - list_df$position_tab_[[i-1]]$midpoint)
<= 1),1,0)
            ))
}

On Sat, 4 Jul 2020 at 14:44, Eric Berger <ericjberger at gmail.com> wrote:

> Hi Kathan,
> How about trying to create a *minimal* reproducible example, e.g. with a
> list of two data frames, where each data frame has 5 rows,?
> My guess is that there is a good chance that when you try to create such
> an example, you will discover the problem yourself.
> In the event that you create the example but still cannot solve your
> issue, you will find more people on this list willing to look into your
> question, as it will be much faster for them to do that (compared to the
> original formulation.)
>
> Eric
>
>
> On Sat, Jul 4, 2020 at 4:33 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
> wrote:
>
>> ---------- Forwarded message ---------
>> From: Kathan Desai <kdesai1 at sheffield.ac.uk>
>> Date: Sat, 4 Jul 2020 at 14:31
>> Subject: Re: [R] Help with looping a function over a list of dataframes:
>> To: Jim Lemon <drjimlemon at gmail.com>
>>
>>
>> Hi Jim,
>>
>> Thankyou for your reply, I tried the function you suggested and it
>> doesn't seem to work. There are again no error messages produced, however
>> the transformation to each position_tab_n table isn't being applied.
>>
>> Cheers,
>> Kathan
>>
>>
>> On Sat, 4 Jul 2020 at 11:14, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> > Hi Kathan,
>> > This is a very lazy answer as I haven't tested it. I think you will
>> > need to wrap your loop in a function and return the modified list_df
>> > to assign it like this:
>> >
>> > add_IDs<-function(xdf) {
>> >  for(i in seq_along(xdf)) {
>> >   xdf$position_tab_[[i]]$ID <-
>> >    unlist(lapply(xdf$position_tab_[[i]]$midpoint, function(x)
>> >     ifelse(any(abs(x - xdf$position_tab_[[i-1]]$midpoint)<= 1),1,0)))
>> >  }
>> >  return(xdf)
>> > }
>> > list_df<-add_IDs(list_df)
>> >
>> > Jim
>> >
>> > On Sat, Jul 4, 2020 at 4:48 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
>> > wrote:
>> > >
>> > > I have been trying to run a forloop for a function that compares
>> > dataframe n
>> > > with dataframe n-1, across a list of dataframes. It does this by
>> checking
>> > > each midpoint of dataframe n with each midpoint of dataframe n-1.
>> This is
>> > > done to make up for an disparity in row length. The idea of this code
>> is
>> > to
>> > > identify any objects that are stationary, and assign them an id of 1,
>> and
>> > > the dynamic objects are assigned an id of 0 (examples can be found
>> > below).
>> > >
>> > >
>> > > *This is what i have so far:*
>> > > for(i in seq_along(list_df)){
>> > >    list_df$position_tab_[[i]]$ID <-
>> > >      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
>> > >                  ifelse(any(abs(x -
>> > list_df$position_tab_[[i-1]]$midpoint)
>> > > <= 1),1,0)
>> > >             ))
>> > > }
>> > >
>> > > There is no error message being produced so theres nothing to debug,
>> i am
>> > > quite new to R programming in general so excuse any silly mistakes i
>> may
>> > > have made. The function doesnt seem to be adding the ID columns and
>> > > comparing the data as it should.
>> > >
>> > > my list of dataframes contain dataframes named: position_tab_1,
>> > > position_tab_2 .... position_tab_121. Each position_tab represents a
>> > > timepoints, so in total there are 121 timepoints (frames). I need the
>> > loop
>> > > to run so that pos_tab_2 compares to pos_tab_1 and this continues all
>> the
>> > > way to pos_tab_121 comparing to pos_tab_120.
>> > >
>> > > The function adds a column named "id" to each of these dataframes as
>> it
>> > > compares to the dataframe before it, so all dataframes apart from
>> > > position_tab_1 (as it has nothing to compare to) should have this
>> added.
>> > >
>> > >
>> > > *Some of my data (first 10 dataframes in list):*
>> > > > dput(list_df[1:10])
>> > > list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
>> > > 2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
>> > > 2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
>> > > 2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
>> > > 669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
>> > > 1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
>> > > 587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
>> > > 1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
>> > > 160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
>> > > 1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names =
>> c(NA,
>> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
>> > > structure(list(
>> > >     Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
>> > >     2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
>> > >     2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
>> > >     147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
>> > >     907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
>> > >     ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
>> > >     702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
>> > >     1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
>> > >     233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
>> > >     1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names =
>> c(NA,
>> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
>> > > structure(list(
>> > >     Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
>> > >     2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
>> > >     2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
>> > >     149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
>> > >     907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
>> > >     ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
>> > >     700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
>> > >     1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
>> > >     232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
>> > >     1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)), row.names
>> =
>> > > c(NA,
>> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
>> > > structure(list(
>> > >     Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
>> > >     2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
>> > >     2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
>> > >     142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
>> > >     908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
>> > >     ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
>> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
>> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
>> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
>> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
>> c(NA,
>> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
>> > > structure(list(
>> > >     Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
>> > >     2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
>> > >     2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum = c(3L,
>> > >     43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
>> > >     861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
>> > >     1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
>> > >     629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
>> > >     1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
>> > >     midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
>> > >     818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
>> > >     1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
>> > > ), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
>> > > structure(list(
>> > >     Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
>> > >     2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
>> > >     2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum = c(4L,
>> > >     45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
>> > >     804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
>> > >     1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
>> > >     419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
>> > >     1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
>> > >     midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
>> > >     618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
>> > >     1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
>> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
>> > > structure(list(
>> > >     Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
>> > >     2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
>> > >     2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum = c(3L,
>> > >     45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
>> > >     837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
>> > >     1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
>> > >     415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
>> > >     1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
>> > >     midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
>> > >     684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
>> > >     1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
>> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
>> > > structure(list(
>> > >     Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
>> > >     2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
>> > >     2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum = c(5L,
>> > >     44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
>> > >     841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
>> > >     1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
>> > >     409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
>> > >     1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
>> > >     midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
>> > >     683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
>> > >     1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
>> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
>> > > structure(list(
>> > >     Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
>> > >     2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
>> > >     2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
>> > >     44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
>> > >     840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
>> > >     1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
>> > >     589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
>> > >     1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
>> > >     62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
>> > >     916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
>> > >     1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
>> > > "data.frame")), position_tab_10 = structure(list(Object = c(2469L,
>> > > 2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
>> > > 2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
>> > > 2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
>> > > 363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
>> > > 1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
>> > > 76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
>> > > 924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
>> > > 1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
>> > > 626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
>> > > 1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
>> > > ), class = c("tbl_df", "tbl", "data.frame")))
>> > >
>> > > *What is produced when running the base code without any loops:*
>> > >
>> > > This is the base code without me trying to loop it in anyway, below is
>> > what
>> > > it produces when its used with dataframe 4 and 5:
>> > >
>> > > #the code:
>> > > list_df$position_tab_5$ID <-
>> > unlist(lapply(list_df$position_tab_5$midpoint,
>> > > function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
>> > 1),1,0)))
>> > >
>> > > ##position_tab_5 after manipulations have occured:
>> > > structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
>> > > 2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
>> > > 2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
>> > > ), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
>> > > 808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
>> > > 1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
>> > > 419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
>> > > 1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
>> > > ), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
>> > > 818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
>> > > 1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
>> > > 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
>> > > -23L), class = c("tbl_df", "tbl", "data.frame"))
>> > >
>> > > #position_tab_4 (the DF pos_tab_5 is being compared to)
>> > > structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
>> > > 2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
>> > > 2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
>> > > 42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
>> > > 908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
>> > >     maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
>> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
>> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
>> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
>> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
>> c(NA,
>> > > -21L), class = c("tbl_df", "tbl", "data.frame"))
>> > >
>> > > *Appreciate any help, anyone can provide!*
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul  4 17:25:07 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 4 Jul 2020 08:25:07 -0700
Subject: [R] 
 Fwd: Help with looping a function over a list of dataframes:
In-Reply-To: <CAH05x1GJC5gLh13WCpPHrrQLvfKwKDqqVrMVwXjPcmoP___o4g@mail.gmail.com>
References: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
 <CA+8X3fVb5aAXQUVLkTrE7qCxRZjCEqb5XDc6s=MurFrebUSj8A@mail.gmail.com>
 <CAH05x1FBaqFynVU_8BQWC=s+4mehS-6pF9NcVKMQ3px9u1HH3g@mail.gmail.com>
 <CAH05x1G668Hs9cvXaJAqCNjcHUwWppjq91qDnZwMALUVX88rfA@mail.gmail.com>
 <CAGgJW74aNnekWtvfSS50ss+E9pGnzA3rm-_WWxb=w7cWU7+5bw@mail.gmail.com>
 <CAH05x1GJC5gLh13WCpPHrrQLvfKwKDqqVrMVwXjPcmoP___o4g@mail.gmail.com>
Message-ID: <CAGxFJbS-bF2TunCyyA7fvJwN9=NY0BQ5jAQF_4XwG-54m6y5Ug@mail.gmail.com>

Perhaps the following will be helpful (you can ignore the warning message
here):

> set.seed(1001)
> x <- sample(1:5,10, rep = TRUE)
> y <- sample(1:5,12, rep = TRUE)
> n <- seq_len(min(length(x), length(y)))
> flag <- as.numeric(abs(x-y)[n] <= 1)
Warning message:
In x - y : longer object length is not a multiple of shorter object length
> cbind(x[n], y[n], flag)
          flag
 [1,] 3 2    1
 [2,] 3 2    1
 [3,] 4 4    1
 [4,] 4 3    1
 [5,] 4 4    1
 [6,] 4 1    0
 [7,] 4 2    0
 [8,] 5 3    0
 [9,] 5 5    1
[10,] 3 1    0

Do note that all columns in a data frame must have the same length, so
maybe you'll need to pad with NA's -- I do not entirely get what you are
trying to do.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jul 4, 2020 at 8:04 AM Kathan Desai <kdesai1 at sheffield.ac.uk> wrote:

> *I hope this is more succinct.*
>
> *I have the following code: *
> list_df$position_tab_5$ID <- unlist(lapply(list_df$position_tab_5$midpoint,
> function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
> 1),1,0)))
>
>
> It compares every observation from the midpoint column from dataframe 2 to
> every observation from the midpoint column from dataframe 1. It does this
> in order to find any values within +/- 1 of the value, and if it satisfies
> this criteria then it assigns it a unique id of 1. If not then a value of
> 0.
>
> In the example below, pos_tab_5 is being compared to pos_tab_4:
>
> Pos tab 4:
> Object minimum maximum midpoint
> 2600    4             22             13
> 2604    42           85             63.5
> 2606    142         172           157
> 2609    223         241           232
> 2611    393         421           407
>
> Pos tab 5:
> Object minimum maximum midpoint ID
> 2580    3             21             12           1
> 2581    43           85             64           1
> 2585    132         168           150         0
> 2586    223         241           232         1
> 2589    391         419           405         0
>
> The reason it compares every observation from pos_tab_(n) to pos_tab_(n-1)
> is because some of the dataframes are of different row length, and so by
> comparing every observation from one DF to another, it can find any values
> that are within +/- 1 of each other. (which is the main thing i'm looking
> for)
>
> I need help looping this function over a list of dataframes. The list of
> dataframes called: list_df contains 121 different dataframes all
> representing a different time point of the object.
>
> This is what i have so far:
> for(i in seq_along(list_df)){
>    list_df$position_tab_[[i]]$ID <-
>      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
>                  ifelse(any(abs(x - list_df$position_tab_[[i-1]]$midpoint)
> <= 1),1,0)
>             ))
> }
>
> On Sat, 4 Jul 2020 at 14:44, Eric Berger <ericjberger at gmail.com> wrote:
>
> > Hi Kathan,
> > How about trying to create a *minimal* reproducible example, e.g. with a
> > list of two data frames, where each data frame has 5 rows,?
> > My guess is that there is a good chance that when you try to create such
> > an example, you will discover the problem yourself.
> > In the event that you create the example but still cannot solve your
> > issue, you will find more people on this list willing to look into your
> > question, as it will be much faster for them to do that (compared to the
> > original formulation.)
> >
> > Eric
> >
> >
> > On Sat, Jul 4, 2020 at 4:33 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
> > wrote:
> >
> >> ---------- Forwarded message ---------
> >> From: Kathan Desai <kdesai1 at sheffield.ac.uk>
> >> Date: Sat, 4 Jul 2020 at 14:31
> >> Subject: Re: [R] Help with looping a function over a list of dataframes:
> >> To: Jim Lemon <drjimlemon at gmail.com>
> >>
> >>
> >> Hi Jim,
> >>
> >> Thankyou for your reply, I tried the function you suggested and it
> >> doesn't seem to work. There are again no error messages produced,
> however
> >> the transformation to each position_tab_n table isn't being applied.
> >>
> >> Cheers,
> >> Kathan
> >>
> >>
> >> On Sat, 4 Jul 2020 at 11:14, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> > Hi Kathan,
> >> > This is a very lazy answer as I haven't tested it. I think you will
> >> > need to wrap your loop in a function and return the modified list_df
> >> > to assign it like this:
> >> >
> >> > add_IDs<-function(xdf) {
> >> >  for(i in seq_along(xdf)) {
> >> >   xdf$position_tab_[[i]]$ID <-
> >> >    unlist(lapply(xdf$position_tab_[[i]]$midpoint, function(x)
> >> >     ifelse(any(abs(x - xdf$position_tab_[[i-1]]$midpoint)<= 1),1,0)))
> >> >  }
> >> >  return(xdf)
> >> > }
> >> > list_df<-add_IDs(list_df)
> >> >
> >> > Jim
> >> >
> >> > On Sat, Jul 4, 2020 at 4:48 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
> >> > wrote:
> >> > >
> >> > > I have been trying to run a forloop for a function that compares
> >> > dataframe n
> >> > > with dataframe n-1, across a list of dataframes. It does this by
> >> checking
> >> > > each midpoint of dataframe n with each midpoint of dataframe n-1.
> >> This is
> >> > > done to make up for an disparity in row length. The idea of this
> code
> >> is
> >> > to
> >> > > identify any objects that are stationary, and assign them an id of
> 1,
> >> and
> >> > > the dynamic objects are assigned an id of 0 (examples can be found
> >> > below).
> >> > >
> >> > >
> >> > > *This is what i have so far:*
> >> > > for(i in seq_along(list_df)){
> >> > >    list_df$position_tab_[[i]]$ID <-
> >> > >      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
> >> > >                  ifelse(any(abs(x -
> >> > list_df$position_tab_[[i-1]]$midpoint)
> >> > > <= 1),1,0)
> >> > >             ))
> >> > > }
> >> > >
> >> > > There is no error message being produced so theres nothing to debug,
> >> i am
> >> > > quite new to R programming in general so excuse any silly mistakes i
> >> may
> >> > > have made. The function doesnt seem to be adding the ID columns and
> >> > > comparing the data as it should.
> >> > >
> >> > > my list of dataframes contain dataframes named: position_tab_1,
> >> > > position_tab_2 .... position_tab_121. Each position_tab represents a
> >> > > timepoints, so in total there are 121 timepoints (frames). I need
> the
> >> > loop
> >> > > to run so that pos_tab_2 compares to pos_tab_1 and this continues
> all
> >> the
> >> > > way to pos_tab_121 comparing to pos_tab_120.
> >> > >
> >> > > The function adds a column named "id" to each of these dataframes as
> >> it
> >> > > compares to the dataframe before it, so all dataframes apart from
> >> > > position_tab_1 (as it has nothing to compare to) should have this
> >> added.
> >> > >
> >> > >
> >> > > *Some of my data (first 10 dataframes in list):*
> >> > > > dput(list_df[1:10])
> >> > > list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
> >> > > 2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
> >> > > 2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
> >> > > 2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
> >> > > 669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
> >> > > 1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
> >> > > 587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
> >> > > 1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
> >> > > 160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
> >> > > 1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names =
> >> c(NA,
> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
> >> > > structure(list(
> >> > >     Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
> >> > >     2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
> >> > >     2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
> >> > >     147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
> >> > >     907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
> >> > >     ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
> >> > >     702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
> >> > >     1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
> >> > >     233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
> >> > >     1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names =
> >> c(NA,
> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
> >> > > structure(list(
> >> > >     Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
> >> > >     2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
> >> > >     2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
> >> > >     149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
> >> > >     907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
> >> > >     ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
> >> > >     700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
> >> > >     1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
> >> > >     232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
> >> > >     1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)),
> row.names
> >> =
> >> > > c(NA,
> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
> >> > > structure(list(
> >> > >     Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
> >> > >     2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
> >> > >     2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
> >> > >     142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> >> > >     908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
> >> > >     ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
> >> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
> >> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
> >> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
> >> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
> >> c(NA,
> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
> >> > > structure(list(
> >> > >     Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
> >> > >     2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
> >> > >     2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum =
> c(3L,
> >> > >     43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
> >> > >     861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
> >> > >     1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
> >> > >     629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
> >> > >     1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
> >> > >     midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> >> > >     818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
> >> > >     1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
> >> > > ), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
> >> > > structure(list(
> >> > >     Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
> >> > >     2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
> >> > >     2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum =
> c(4L,
> >> > >     45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
> >> > >     804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
> >> > >     1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
> >> > >     419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
> >> > >     1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
> >> > >     midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
> >> > >     618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
> >> > >     1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
> >> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
> >> > > structure(list(
> >> > >     Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
> >> > >     2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
> >> > >     2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum =
> c(3L,
> >> > >     45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
> >> > >     837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
> >> > >     1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
> >> > >     415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
> >> > >     1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
> >> > >     midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
> >> > >     684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
> >> > >     1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
> >> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
> >> > > structure(list(
> >> > >     Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
> >> > >     2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
> >> > >     2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum =
> c(5L,
> >> > >     44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
> >> > >     841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
> >> > >     1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
> >> > >     409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
> >> > >     1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
> >> > >     midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
> >> > >     683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
> >> > >     1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
> >> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
> >> > > structure(list(
> >> > >     Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
> >> > >     2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
> >> > >     2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
> >> > >     44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
> >> > >     840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
> >> > >     1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
> >> > >     589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
> >> > >     1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
> >> > >     62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
> >> > >     916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
> >> > >     1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
> >> > > "data.frame")), position_tab_10 = structure(list(Object = c(2469L,
> >> > > 2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
> >> > > 2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
> >> > > 2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
> >> > > 363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
> >> > > 1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
> >> > > 76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
> >> > > 924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
> >> > > 1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
> >> > > 626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
> >> > > 1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
> >> > > ), class = c("tbl_df", "tbl", "data.frame")))
> >> > >
> >> > > *What is produced when running the base code without any loops:*
> >> > >
> >> > > This is the base code without me trying to loop it in anyway, below
> is
> >> > what
> >> > > it produces when its used with dataframe 4 and 5:
> >> > >
> >> > > #the code:
> >> > > list_df$position_tab_5$ID <-
> >> > unlist(lapply(list_df$position_tab_5$midpoint,
> >> > > function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
> >> > 1),1,0)))
> >> > >
> >> > > ##position_tab_5 after manipulations have occured:
> >> > > structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
> >> > > 2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
> >> > > 2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
> >> > > ), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
> >> > > 808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
> >> > > 1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
> >> > > 419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
> >> > > 1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
> >> > > ), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
> >> > > 818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
> >> > > 1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
> >> > > 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
> >> > > -23L), class = c("tbl_df", "tbl", "data.frame"))
> >> > >
> >> > > #position_tab_4 (the DF pos_tab_5 is being compared to)
> >> > > structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
> >> > > 2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
> >> > > 2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
> >> > > 42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
> >> > > 908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
> >> > >     maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
> >> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
> >> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
> >> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
> >> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
> >> c(NA,
> >> > > -21L), class = c("tbl_df", "tbl", "data.frame"))
> >> > >
> >> > > *Appreciate any help, anyone can provide!*
> >> > >
> >> > >         [[alternative HTML version deleted]]
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kde@@|1 @end|ng |rom @he|||e|d@@c@uk  Sat Jul  4 17:39:18 2020
From: kde@@|1 @end|ng |rom @he|||e|d@@c@uk (Kathan Desai)
Date: Sat, 4 Jul 2020 16:39:18 +0100
Subject: [R] 
 Fwd: Help with looping a function over a list of dataframes:
In-Reply-To: <CAGxFJbS-bF2TunCyyA7fvJwN9=NY0BQ5jAQF_4XwG-54m6y5Ug@mail.gmail.com>
References: <CAH05x1G34LOV5BM=y61ZDumxg2+p4Mq8iEo8xLk=E5HVhNw7GQ@mail.gmail.com>
 <CA+8X3fVb5aAXQUVLkTrE7qCxRZjCEqb5XDc6s=MurFrebUSj8A@mail.gmail.com>
 <CAH05x1FBaqFynVU_8BQWC=s+4mehS-6pF9NcVKMQ3px9u1HH3g@mail.gmail.com>
 <CAH05x1G668Hs9cvXaJAqCNjcHUwWppjq91qDnZwMALUVX88rfA@mail.gmail.com>
 <CAGgJW74aNnekWtvfSS50ss+E9pGnzA3rm-_WWxb=w7cWU7+5bw@mail.gmail.com>
 <CAH05x1GJC5gLh13WCpPHrrQLvfKwKDqqVrMVwXjPcmoP___o4g@mail.gmail.com>
 <CAGxFJbS-bF2TunCyyA7fvJwN9=NY0BQ5jAQF_4XwG-54m6y5Ug@mail.gmail.com>
Message-ID: <CAH05x1Fh9T_aj2-oB12-KTnj_FHj_DJPfQhsgw-B0F2ZFkvuQw@mail.gmail.com>

Hello thanks everyone for your help i managed to get a working function as
followed:

for(i in 2:length(list_df)){
list_df[[paste0("position_tab_",i)]][['ID']] <-
 unlist(lapply(list_df[[paste0("position_tab_",i)]][['midpoint']],
function(x)
  ifelse(any(abs(x - list_df[[paste0("position_tab_",i-1)]][['midpoint']])
                       <= 1),1,0)         )) }

The idea with this was to detect stationary mitochondria from each frame.
So i needed to link objects from frame to frame (pos_tab = one frame) and
find any of them that didnt move more than 2 pixels hence the +/- one
requirement.

On Sat, 4 Jul 2020 at 16:25, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Perhaps the following will be helpful (you can ignore the warning message
> here):
>
> > set.seed(1001)
> > x <- sample(1:5,10, rep = TRUE)
> > y <- sample(1:5,12, rep = TRUE)
> > n <- seq_len(min(length(x), length(y)))
> > flag <- as.numeric(abs(x-y)[n] <= 1)
> Warning message:
> In x - y : longer object length is not a multiple of shorter object length
> > cbind(x[n], y[n], flag)
>           flag
>  [1,] 3 2    1
>  [2,] 3 2    1
>  [3,] 4 4    1
>  [4,] 4 3    1
>  [5,] 4 4    1
>  [6,] 4 1    0
>  [7,] 4 2    0
>  [8,] 5 3    0
>  [9,] 5 5    1
> [10,] 3 1    0
>
> Do note that all columns in a data frame must have the same length, so
> maybe you'll need to pad with NA's -- I do not entirely get what you are
> trying to do.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Jul 4, 2020 at 8:04 AM Kathan Desai <kdesai1 at sheffield.ac.uk>
> wrote:
>
>> *I hope this is more succinct.*
>>
>> *I have the following code: *
>> list_df$position_tab_5$ID <-
>> unlist(lapply(list_df$position_tab_5$midpoint,
>> function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
>> 1),1,0)))
>>
>>
>> It compares every observation from the midpoint column from dataframe 2 to
>> every observation from the midpoint column from dataframe 1. It does this
>> in order to find any values within +/- 1 of the value, and if it satisfies
>> this criteria then it assigns it a unique id of 1. If not then a value of
>> 0.
>>
>> In the example below, pos_tab_5 is being compared to pos_tab_4:
>>
>> Pos tab 4:
>> Object minimum maximum midpoint
>> 2600    4             22             13
>> 2604    42           85             63.5
>> 2606    142         172           157
>> 2609    223         241           232
>> 2611    393         421           407
>>
>> Pos tab 5:
>> Object minimum maximum midpoint ID
>> 2580    3             21             12           1
>> 2581    43           85             64           1
>> 2585    132         168           150         0
>> 2586    223         241           232         1
>> 2589    391         419           405         0
>>
>> The reason it compares every observation from pos_tab_(n) to pos_tab_(n-1)
>> is because some of the dataframes are of different row length, and so by
>> comparing every observation from one DF to another, it can find any values
>> that are within +/- 1 of each other. (which is the main thing i'm looking
>> for)
>>
>> I need help looping this function over a list of dataframes. The list of
>> dataframes called: list_df contains 121 different dataframes all
>> representing a different time point of the object.
>>
>> This is what i have so far:
>> for(i in seq_along(list_df)){
>>    list_df$position_tab_[[i]]$ID <-
>>      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
>>                  ifelse(any(abs(x - list_df$position_tab_[[i-1]]$midpoint)
>> <= 1),1,0)
>>             ))
>> }
>>
>> On Sat, 4 Jul 2020 at 14:44, Eric Berger <ericjberger at gmail.com> wrote:
>>
>> > Hi Kathan,
>> > How about trying to create a *minimal* reproducible example, e.g. with a
>> > list of two data frames, where each data frame has 5 rows,?
>> > My guess is that there is a good chance that when you try to create such
>> > an example, you will discover the problem yourself.
>> > In the event that you create the example but still cannot solve your
>> > issue, you will find more people on this list willing to look into your
>> > question, as it will be much faster for them to do that (compared to the
>> > original formulation.)
>> >
>> > Eric
>> >
>> >
>> > On Sat, Jul 4, 2020 at 4:33 PM Kathan Desai <kdesai1 at sheffield.ac.uk>
>> > wrote:
>> >
>> >> ---------- Forwarded message ---------
>> >> From: Kathan Desai <kdesai1 at sheffield.ac.uk>
>> >> Date: Sat, 4 Jul 2020 at 14:31
>> >> Subject: Re: [R] Help with looping a function over a list of
>> dataframes:
>> >> To: Jim Lemon <drjimlemon at gmail.com>
>> >>
>> >>
>> >> Hi Jim,
>> >>
>> >> Thankyou for your reply, I tried the function you suggested and it
>> >> doesn't seem to work. There are again no error messages produced,
>> however
>> >> the transformation to each position_tab_n table isn't being applied.
>> >>
>> >> Cheers,
>> >> Kathan
>> >>
>> >>
>> >> On Sat, 4 Jul 2020 at 11:14, Jim Lemon <drjimlemon at gmail.com> wrote:
>> >>
>> >> > Hi Kathan,
>> >> > This is a very lazy answer as I haven't tested it. I think you will
>> >> > need to wrap your loop in a function and return the modified list_df
>> >> > to assign it like this:
>> >> >
>> >> > add_IDs<-function(xdf) {
>> >> >  for(i in seq_along(xdf)) {
>> >> >   xdf$position_tab_[[i]]$ID <-
>> >> >    unlist(lapply(xdf$position_tab_[[i]]$midpoint, function(x)
>> >> >     ifelse(any(abs(x - xdf$position_tab_[[i-1]]$midpoint)<= 1),1,0)))
>> >> >  }
>> >> >  return(xdf)
>> >> > }
>> >> > list_df<-add_IDs(list_df)
>> >> >
>> >> > Jim
>> >> >
>> >> > On Sat, Jul 4, 2020 at 4:48 PM Kathan Desai <kdesai1 at sheffield.ac.uk
>> >
>> >> > wrote:
>> >> > >
>> >> > > I have been trying to run a forloop for a function that compares
>> >> > dataframe n
>> >> > > with dataframe n-1, across a list of dataframes. It does this by
>> >> checking
>> >> > > each midpoint of dataframe n with each midpoint of dataframe n-1.
>> >> This is
>> >> > > done to make up for an disparity in row length. The idea of this
>> code
>> >> is
>> >> > to
>> >> > > identify any objects that are stationary, and assign them an id of
>> 1,
>> >> and
>> >> > > the dynamic objects are assigned an id of 0 (examples can be found
>> >> > below).
>> >> > >
>> >> > >
>> >> > > *This is what i have so far:*
>> >> > > for(i in seq_along(list_df)){
>> >> > >    list_df$position_tab_[[i]]$ID <-
>> >> > >      unlist(lapply(list_df$position_tab_[[i]]$midpoint, function(x)
>> >> > >                  ifelse(any(abs(x -
>> >> > list_df$position_tab_[[i-1]]$midpoint)
>> >> > > <= 1),1,0)
>> >> > >             ))
>> >> > > }
>> >> > >
>> >> > > There is no error message being produced so theres nothing to
>> debug,
>> >> i am
>> >> > > quite new to R programming in general so excuse any silly mistakes
>> i
>> >> may
>> >> > > have made. The function doesnt seem to be adding the ID columns and
>> >> > > comparing the data as it should.
>> >> > >
>> >> > > my list of dataframes contain dataframes named: position_tab_1,
>> >> > > position_tab_2 .... position_tab_121. Each position_tab represents
>> a
>> >> > > timepoints, so in total there are 121 timepoints (frames). I need
>> the
>> >> > loop
>> >> > > to run so that pos_tab_2 compares to pos_tab_1 and this continues
>> all
>> >> the
>> >> > > way to pos_tab_121 comparing to pos_tab_120.
>> >> > >
>> >> > > The function adds a column named "id" to each of these dataframes
>> as
>> >> it
>> >> > > compares to the dataframe before it, so all dataframes apart from
>> >> > > position_tab_1 (as it has nothing to compare to) should have this
>> >> added.
>> >> > >
>> >> > >
>> >> > > *Some of my data (first 10 dataframes in list):*
>> >> > > > dput(list_df[1:10])
>> >> > > list(position_tab_1 = structure(list(Object = c(2666L, 2668L,
>> >> > > 2671L, 2674L, 2676L, 2677L, 2678L, 2679L, 2680L, 2682L, 2683L,
>> >> > > 2684L, 2685L, 2686L, 2687L, 2689L, 2692L, 2693L, 2694L, 2695L,
>> >> > > 2696L), minimum = c(4L, 39L, 147L, 224L, 419L, 531L, 595L, 641L,
>> >> > > 669L, 723L, 810L, 836L, 907L, 978L, 1061L, 1129L, 1290L, 1519L,
>> >> > > 1749L, 1843L, 1897L), maximum = c(22L, 85L, 173L, 242L, 449L,
>> >> > > 587L, 627L, 655L, 702L, 740L, 828L, 890L, 923L, 1024L, 1086L,
>> >> > > 1144L, 1302L, 1544L, 1780L, 1870L, 1925L), midpoint = c(13, 62,
>> >> > > 160, 233, 434, 559, 611, 648, 685.5, 731.5, 819, 863, 915, 1001,
>> >> > > 1073.5, 1136.5, 1296, 1531.5, 1764.5, 1856.5, 1911)), row.names =
>> >> c(NA,
>> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_2 =
>> >> > > structure(list(
>> >> > >     Object = c(2645L, 2646L, 2650L, 2652L, 2655L, 2656L, 2657L,
>> >> > >     2658L, 2659L, 2661L, 2662L, 2663L, 2664L, 2665L, 2667L, 2670L,
>> >> > >     2675L, 2681L, 2688L, 2690L, 2691L), minimum = c(4L, 40L,
>> >> > >     147L, 224L, 415L, 532L, 595L, 641L, 670L, 722L, 811L, 835L,
>> >> > >     907L, 978L, 1061L, 1128L, 1289L, 1520L, 1748L, 1843L, 1897L
>> >> > >     ), maximum = c(22L, 85L, 173L, 242L, 445L, 588L, 627L, 655L,
>> >> > >     702L, 739L, 828L, 891L, 923L, 1022L, 1085L, 1143L, 1302L,
>> >> > >     1544L, 1779L, 1870L, 1925L), midpoint = c(13, 62.5, 160,
>> >> > >     233, 430, 560, 611, 648, 686, 730.5, 819.5, 863, 915, 1000,
>> >> > >     1073, 1135.5, 1295.5, 1532, 1763.5, 1856.5, 1911)), row.names =
>> >> c(NA,
>> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_3 =
>> >> > > structure(list(
>> >> > >     Object = c(2623L, 2624L, 2627L, 2631L, 2633L, 2635L, 2636L,
>> >> > >     2637L, 2638L, 2640L, 2641L, 2642L, 2643L, 2644L, 2647L, 2649L,
>> >> > >     2654L, 2660L, 2669L, 2672L, 2673L), minimum = c(3L, 39L,
>> >> > >     149L, 223L, 402L, 539L, 594L, 639L, 669L, 722L, 811L, 834L,
>> >> > >     907L, 979L, 1060L, 1129L, 1289L, 1520L, 1749L, 1842L, 1897L
>> >> > >     ), maximum = c(22L, 86L, 175L, 241L, 431L, 587L, 627L, 653L,
>> >> > >     700L, 738L, 828L, 894L, 925L, 1021L, 1084L, 1144L, 1302L,
>> >> > >     1544L, 1779L, 1869L, 1925L), midpoint = c(12.5, 62.5, 162,
>> >> > >     232, 416.5, 563, 610.5, 646, 684.5, 730, 819.5, 864, 916,
>> >> > >     1000, 1072, 1136.5, 1295.5, 1532, 1764, 1855.5, 1911)),
>> row.names
>> >> =
>> >> > > c(NA,
>> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_4 =
>> >> > > structure(list(
>> >> > >     Object = c(2600L, 2604L, 2606L, 2609L, 2611L, 2613L, 2614L,
>> >> > >     2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L, 2626L, 2628L,
>> >> > >     2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L, 42L,
>> >> > >     142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
>> >> > >     908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L
>> >> > >     ), maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
>> >> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
>> >> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
>> >> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
>> >> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
>> >> c(NA,
>> >> > > -21L), class = c("tbl_df", "tbl", "data.frame")), position_tab_5 =
>> >> > > structure(list(
>> >> > >     Object = c(2580L, 2581L, 2585L, 2586L, 2589L, 2590L, 2592L,
>> >> > >     2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L, 2601L, 2603L,
>> >> > >     2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L), minimum =
>> c(3L,
>> >> > >     43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L, 808L, 836L,
>> >> > >     861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L, 1748L,
>> >> > >     1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L, 419L,
>> >> > >     629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L, 1050L,
>> >> > >     1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L),
>> >> > >     midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
>> >> > >     818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5,
>> >> > >     1531.5, 1764, 1855.5, 1909, 2148)), row.names = c(NA, -23L
>> >> > > ), class = c("tbl_df", "tbl", "data.frame")), position_tab_6 =
>> >> > > structure(list(
>> >> > >     Object = c(2555L, 2559L, 2562L, 2563L, 2564L, 2567L, 2569L,
>> >> > >     2570L, 2571L, 2572L, 2573L, 2574L, 2575L, 2576L, 2577L, 2579L,
>> >> > >     2583L, 2587L, 2591L, 2602L, 2607L, 2608L, 2612L), minimum =
>> c(4L,
>> >> > >     45L, 123L, 154L, 224L, 390L, 546L, 600L, 643L, 669L, 720L,
>> >> > >     804L, 836L, 908L, 967L, 1058L, 1129L, 1289L, 1519L, 1748L,
>> >> > >     1843L, 1893L, 2147L), maximum = c(23L, 86L, 150L, 171L, 241L,
>> >> > >     419L, 589L, 636L, 657L, 701L, 738L, 827L, 879L, 925L, 1011L,
>> >> > >     1084L, 1144L, 1301L, 1543L, 1780L, 1871L, 1924L, 2148L),
>> >> > >     midpoint = c(13.5, 65.5, 136.5, 162.5, 232.5, 404.5, 567.5,
>> >> > >     618, 650, 685, 729, 815.5, 857.5, 916.5, 989, 1071, 1136.5,
>> >> > >     1295, 1531, 1764, 1857, 1908.5, 2147.5)), row.names = c(NA,
>> >> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_7 =
>> >> > > structure(list(
>> >> > >     Object = c(2537L, 2539L, 2540L, 2541L, 2542L, 2544L, 2546L,
>> >> > >     2547L, 2548L, 2549L, 2550L, 2551L, 2552L, 2554L, 2556L, 2558L,
>> >> > >     2560L, 2565L, 2568L, 2578L, 2582L, 2584L, 2588L), minimum =
>> c(3L,
>> >> > >     45L, 122L, 156L, 224L, 387L, 546L, 601L, 669L, 719L, 803L,
>> >> > >     837L, 908L, 959L, 1059L, 1096L, 1128L, 1289L, 1519L, 1748L,
>> >> > >     1844L, 1892L, 2147L), maximum = c(22L, 86L, 147L, 172L, 241L,
>> >> > >     415L, 590L, 656L, 699L, 738L, 830L, 871L, 924L, 1014L, 1082L,
>> >> > >     1119L, 1144L, 1301L, 1543L, 1781L, 1872L, 1925L, 2148L),
>> >> > >     midpoint = c(12.5, 65.5, 134.5, 164, 232.5, 401, 568, 628.5,
>> >> > >     684, 728.5, 816.5, 854, 916, 986.5, 1070.5, 1107.5, 1136,
>> >> > >     1295, 1531, 1764.5, 1858, 1908.5, 2147.5)), row.names = c(NA,
>> >> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_8 =
>> >> > > structure(list(
>> >> > >     Object = c(2514L, 2517L, 2519L, 2520L, 2521L, 2523L, 2525L,
>> >> > >     2526L, 2527L, 2528L, 2529L, 2530L, 2531L, 2532L, 2533L, 2534L,
>> >> > >     2536L, 2543L, 2545L, 2553L, 2557L, 2561L, 2566L), minimum =
>> c(5L,
>> >> > >     44L, 121L, 153L, 224L, 380L, 546L, 603L, 668L, 721L, 802L,
>> >> > >     841L, 907L, 960L, 1006L, 1060L, 1106L, 1288L, 1518L, 1748L,
>> >> > >     1843L, 1893L, 2148L), maximum = c(23L, 86L, 146L, 170L, 242L,
>> >> > >     409L, 588L, 655L, 699L, 738L, 830L, 872L, 924L, 994L, 1029L,
>> >> > >     1084L, 1143L, 1302L, 1543L, 1781L, 1870L, 1925L, 2148L),
>> >> > >     midpoint = c(14, 65, 133.5, 161.5, 233, 394.5, 567, 629,
>> >> > >     683.5, 729.5, 816, 856.5, 915.5, 977, 1017.5, 1072, 1124.5,
>> >> > >     1295, 1530.5, 1764.5, 1856.5, 1909, 2148)), row.names = c(NA,
>> >> > > -23L), class = c("tbl_df", "tbl", "data.frame")), position_tab_9 =
>> >> > > structure(list(
>> >> > >     Object = c(2492L, 2493L, 2497L, 2498L, 2499L, 2501L, 2503L,
>> >> > >     2504L, 2505L, 2506L, 2507L, 2508L, 2509L, 2510L, 2511L, 2513L,
>> >> > >     2516L, 2522L, 2524L, 2532L, 2535L, 2538L), minimum = c(6L,
>> >> > >     44L, 111L, 149L, 224L, 375L, 548L, 596L, 668L, 722L, 800L,
>> >> > >     840L, 908L, 960L, 1005L, 1058L, 1127L, 1289L, 1519L, 1748L,
>> >> > >     1842L, 1891L), maximum = c(24L, 81L, 137L, 167L, 242L, 403L,
>> >> > >     589L, 656L, 699L, 738L, 828L, 872L, 925L, 994L, 1028L, 1081L,
>> >> > >     1149L, 1302L, 1544L, 1780L, 1868L, 1924L), midpoint = c(15,
>> >> > >     62.5, 124, 158, 233, 389, 568.5, 626, 683.5, 730, 814, 856,
>> >> > >     916.5, 977, 1016.5, 1069.5, 1138, 1295.5, 1531.5, 1764, 1855,
>> >> > >     1907.5)), row.names = c(NA, -22L), class = c("tbl_df", "tbl",
>> >> > > "data.frame")), position_tab_10 = structure(list(Object = c(2469L,
>> >> > > 2471L, 2474L, 2475L, 2476L, 2478L, 2481L, 2482L, 2483L, 2484L,
>> >> > > 2485L, 2486L, 2487L, 2488L, 2489L, 2491L, 2495L, 2500L, 2502L,
>> >> > > 2512L, 2515L, 2518L), minimum = c(6L, 38L, 109L, 147L, 223L,
>> >> > > 363L, 548L, 597L, 668L, 719L, 803L, 839L, 908L, 958L, 1004L,
>> >> > > 1058L, 1126L, 1288L, 1519L, 1746L, 1841L, 1892L), maximum = c(24L,
>> >> > > 76L, 134L, 165L, 240L, 394L, 591L, 656L, 698L, 737L, 829L, 869L,
>> >> > > 924L, 996L, 1027L, 1081L, 1147L, 1301L, 1543L, 1781L, 1868L,
>> >> > > 1925L), midpoint = c(15, 57, 121.5, 156, 231.5, 378.5, 569.5,
>> >> > > 626.5, 683, 728, 816, 854, 916, 977, 1015.5, 1069.5, 1136.5,
>> >> > > 1294.5, 1531, 1763.5, 1854.5, 1908.5)), row.names = c(NA, -22L
>> >> > > ), class = c("tbl_df", "tbl", "data.frame")))
>> >> > >
>> >> > > *What is produced when running the base code without any loops:*
>> >> > >
>> >> > > This is the base code without me trying to loop it in anyway,
>> below is
>> >> > what
>> >> > > it produces when its used with dataframe 4 and 5:
>> >> > >
>> >> > > #the code:
>> >> > > list_df$position_tab_5$ID <-
>> >> > unlist(lapply(list_df$position_tab_5$midpoint,
>> >> > > function(x) ifelse(any(abs(x - list_df$position_tab_4$midpoint) <=
>> >> > 1),1,0)))
>> >> > >
>> >> > > ##position_tab_5 after manipulations have occured:
>> >> > > structure(list(Object = c(2580L, 2581L, 2585L, 2586L, 2589L,
>> >> > > 2590L, 2592L, 2593L, 2594L, 2595L, 2596L, 2597L, 2598L, 2599L,
>> >> > > 2601L, 2603L, 2605L, 2610L, 2616L, 2625L, 2629L, 2630L, 2634L
>> >> > > ), minimum = c(3L, 43L, 132L, 223L, 391L, 547L, 643L, 669L, 721L,
>> >> > > 808L, 836L, 861L, 908L, 978L, 1028L, 1057L, 1127L, 1288L, 1519L,
>> >> > > 1748L, 1842L, 1893L, 2148L), maximum = c(21L, 85L, 168L, 241L,
>> >> > > 419L, 629L, 656L, 701L, 738L, 828L, 858L, 890L, 925L, 1013L,
>> >> > > 1050L, 1083L, 1143L, 1301L, 1544L, 1780L, 1869L, 1925L, 2148L
>> >> > > ), midpoint = c(12, 64, 150, 232, 405, 588, 649.5, 685, 729.5,
>> >> > > 818, 847, 875.5, 916.5, 995.5, 1039, 1070, 1135, 1294.5, 1531.5,
>> >> > > 1764, 1855.5, 1909, 2148), ID = c(1, 1, 0, 1, 0, 0, 0, 1, 1,
>> >> > > 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0)), row.names = c(NA,
>> >> > > -23L), class = c("tbl_df", "tbl", "data.frame"))
>> >> > >
>> >> > > #position_tab_4 (the DF pos_tab_5 is being compared to)
>> >> > > structure(list(Object = c(2600L, 2604L, 2606L, 2609L, 2611L,
>> >> > > 2613L, 2614L, 2615L, 2617L, 2618L, 2619L, 2620L, 2621L, 2622L,
>> >> > > 2626L, 2628L, 2632L, 2639L, 2648L, 2651L, 2653L), minimum = c(4L,
>> >> > > 42L, 142L, 223L, 393L, 547L, 595L, 641L, 669L, 720L, 809L, 835L,
>> >> > > 908L, 979L, 1059L, 1127L, 1289L, 1519L, 1749L, 1841L, 1897L),
>> >> > >     maximum = c(22L, 85L, 172L, 241L, 421L, 587L, 629L, 655L,
>> >> > >     701L, 738L, 826L, 890L, 925L, 1019L, 1084L, 1143L, 1301L,
>> >> > >     1544L, 1780L, 1868L, 1925L), midpoint = c(13, 63.5, 157,
>> >> > >     232, 407, 567, 612, 648, 685, 729, 817.5, 862.5, 916.5, 999,
>> >> > >     1071.5, 1135, 1295, 1531.5, 1764.5, 1854.5, 1911)), row.names =
>> >> c(NA,
>> >> > > -21L), class = c("tbl_df", "tbl", "data.frame"))
>> >> > >
>> >> > > *Appreciate any help, anyone can provide!*
>> >> > >
>> >> > >         [[alternative HTML version deleted]]
>> >> > >
>> >> > > ______________________________________________
>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > > and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Jul  5 10:43:35 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 5 Jul 2020 09:43:35 +0100 (BST)
Subject: [R] Can I pass the grouped portions of a dataframe/tibble to a
 function in dplyr
Message-ID: <436569067.11600799.1593938615607.JavaMail.zimbra@psyctc.org>

Apologies if this is a stupid question but searching keeps getting things I know and don't need. 

What I want to do is to use the group-by() power of dplyr to run functions that expect a dataframe/tibble per group but I can't see how do it. Here is a reproducible example. 

### create trivial tibble
n <- 50 
x <- 1:n 
y <- sample(1:3, n, replace = TRUE) 
z <- rnorm(n) 
tib <- as_tibble(cbind(x,y,z)) 

### create trivial function that expects a tibble/data frame
sillyFun <- function(tib){ 
return(list(nrow = nrow(tib), 
ncol = ncol(tib))) 
} 

### works fine on the whole tibble
tib %>% 
summarise(dim = list(sillyFun(.))) %>% 
unnest_wider(dim) 

That gives me:
# A tibble: 1 x 2
   nrow  ncol
  <int> <int>
1    50     3


### So I try the following hoping to apply the function to the grouped tibble
tib %>% 
group_by(y) %>% 
summarise(dim = list(sillyFun(.))) %>% 
unnest_wider(dim)

### But that gives me:
# A tibble: 3 x 3
      y  nrow  ncol
  <dbl> <int> <int>
1     1    50     3
2     2    50     3
3     3    50     3

Clearly "." is still passing the whole tibble, not the grouped subsets.  What I can't find is whether there is an alternative to "." that would pass just the grouped subset of the tibble.

I have bodged my way around this by writing a function that takes individual columns and reassembles them into a data frame that the actual functions I need to use require but that takes me back to a lot of clumsiness both selecting the variables to pass in the dplyr call to the function and putting the reassemble-to-data-frame bit in the function I call.  (The functions I really need are reliability explorations and can called on whole dataframes.)

I know I can do this using base R split and lapply but I feel sure it must be possible to do this within dplyr/tidyverse.  I'm slowly transferring most of my code to the tidyverse and hitting frustrations but also finding that it does really help me program more sensibly, handle relational data structures more easily, and write code that I seem better at reading when I come back to it after months on other things so I am slowly trying to move all my coding to tidyverse.  If I could see how to do this, it would help.

Very sorry if the answer should be blindingly obvious to me.  I'd also love to have pointers to guidance to the tidyverse written for people who aren't professional coders or statisticians and that go a bit beyond the obvious basics of tidyverse into issues like this.

TIA,

Chris

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jul  5 13:04:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 5 Jul 2020 12:04:44 +0100
Subject: [R] Can I pass the grouped portions of a dataframe/tibble to a
 function in dplyr
In-Reply-To: <436569067.11600799.1593938615607.JavaMail.zimbra@psyctc.org>
References: <436569067.11600799.1593938615607.JavaMail.zimbra@psyctc.org>
Message-ID: <95eb1446-5dd4-eeec-f992-4d6ca922992b@sapo.pt>

Hello,

You can pass a grouped tibble to a function with grouped_modify but the 
function must return a data.frame (or similar).

## this will also do it
#sillyFun <- function(tib){
#  tibble(nrow = nrow(tib), ncol = ncol(tib))
#}


sillyFun <- function(tib){
   data.frame(nrow = nrow(tib), ncol = ncol(tib)))
}

tib %>%
   group_by(y) %>%
   group_modify(~ sillyFun(.))
## A tibble: 3 x 3
## Groups:   y [3]
#      y  nrow  ncol
#  <dbl> <int> <int>
#1     1    17     2
#2     2    21     2
#3     3    12     2


Hope this helps,

Rui Barradas

?s 09:43 de 05/07/2020, Chris Evans escreveu:
> Apologies if this is a stupid question but searching keeps getting things I know and don't need.
> 
> What I want to do is to use the group-by() power of dplyr to run functions that expect a dataframe/tibble per group but I can't see how do it. Here is a reproducible example.
> 
> ### create trivial tibble
> n <- 50
> x <- 1:n
> y <- sample(1:3, n, replace = TRUE)
> z <- rnorm(n)
> tib <- as_tibble(cbind(x,y,z))
> 
> ### create trivial function that expects a tibble/data frame
> sillyFun <- function(tib){
> return(list(nrow = nrow(tib),
> ncol = ncol(tib)))
> }
> 
> ### works fine on the whole tibble
> tib %>%
> summarise(dim = list(sillyFun(.))) %>%
> unnest_wider(dim)
> 
> That gives me:
> # A tibble: 1 x 2
>     nrow  ncol
>    <int> <int>
> 1    50     3
> 
> 
> ### So I try the following hoping to apply the function to the grouped tibble
> tib %>%
> group_by(y) %>%
> summarise(dim = list(sillyFun(.))) %>%
> unnest_wider(dim)
> 
> ### But that gives me:
> # A tibble: 3 x 3
>        y  nrow  ncol
>    <dbl> <int> <int>
> 1     1    50     3
> 2     2    50     3
> 3     3    50     3
> 
> Clearly "." is still passing the whole tibble, not the grouped subsets.  What I can't find is whether there is an alternative to "." that would pass just the grouped subset of the tibble.
> 
> I have bodged my way around this by writing a function that takes individual columns and reassembles them into a data frame that the actual functions I need to use require but that takes me back to a lot of clumsiness both selecting the variables to pass in the dplyr call to the function and putting the reassemble-to-data-frame bit in the function I call.  (The functions I really need are reliability explorations and can called on whole dataframes.)
> 
> I know I can do this using base R split and lapply but I feel sure it must be possible to do this within dplyr/tidyverse.  I'm slowly transferring most of my code to the tidyverse and hitting frustrations but also finding that it does really help me program more sensibly, handle relational data structures more easily, and write code that I seem better at reading when I come back to it after months on other things so I am slowly trying to move all my coding to tidyverse.  If I could see how to do this, it would help.
> 
> Very sorry if the answer should be blindingly obvious to me.  I'd also love to have pointers to guidance to the tidyverse written for people who aren't professional coders or statisticians and that go a bit beyond the obvious basics of tidyverse into issues like this.
> 
> TIA,
> 
> Chris
> 

-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jul  5 13:16:19 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 5 Jul 2020 12:16:19 +0100
Subject: [R] Can I pass the grouped portions of a dataframe/tibble to a
 function in dplyr
In-Reply-To: <95eb1446-5dd4-eeec-f992-4d6ca922992b@sapo.pt>
References: <436569067.11600799.1593938615607.JavaMail.zimbra@psyctc.org>
 <95eb1446-5dd4-eeec-f992-4d6ca922992b@sapo.pt>
Message-ID: <5e822ed0-2285-306e-7ee5-c90e444812ef@sapo.pt>

Hello,

I forgot to say I redid the data set setting the RNG seed first.



set.seed(2020)
n <- 50
x <- 1:n
y <- sample(1:3, n, replace = TRUE)
z <- rnorm(n)
tib <- tibble(x,y,z)


Also, don't do

as_tibble(cbind(...))
as.data.frame(cbind(...))


If one of the variables is of a different class (example, "character") 
all variables are coerced to the least common denominator. It's much 
better to call tibble() or data.frame() directly.

Hope this helps,

Rui Barradas


?s 12:04 de 05/07/2020, Rui Barradas escreveu:
> Hello,
> 
> You can pass a grouped tibble to a function with grouped_modify but the 
> function must return a data.frame (or similar).
> 
> ## this will also do it
> #sillyFun <- function(tib){
> #? tibble(nrow = nrow(tib), ncol = ncol(tib))
> #}
> 
> 
> sillyFun <- function(tib){
>  ? data.frame(nrow = nrow(tib), ncol = ncol(tib)))
> }
> 
> tib %>%
>  ? group_by(y) %>%
>  ? group_modify(~ sillyFun(.))
> ## A tibble: 3 x 3
> ## Groups:?? y [3]
> #????? y? nrow? ncol
> #? <dbl> <int> <int>
> #1???? 1??? 17???? 2
> #2???? 2??? 21???? 2
> #3???? 3??? 12???? 2
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 09:43 de 05/07/2020, Chris Evans escreveu:
>> Apologies if this is a stupid question but searching keeps getting 
>> things I know and don't need.
>>
>> What I want to do is to use the group-by() power of dplyr to run 
>> functions that expect a dataframe/tibble per group but I can't see how 
>> do it. Here is a reproducible example.
>>
>> ### create trivial tibble
>> n <- 50
>> x <- 1:n
>> y <- sample(1:3, n, replace = TRUE)
>> z <- rnorm(n)
>> tib <- as_tibble(cbind(x,y,z))
>>
>> ### create trivial function that expects a tibble/data frame
>> sillyFun <- function(tib){
>> return(list(nrow = nrow(tib),
>> ncol = ncol(tib)))
>> }
>>
>> ### works fine on the whole tibble
>> tib %>%
>> summarise(dim = list(sillyFun(.))) %>%
>> unnest_wider(dim)
>>
>> That gives me:
>> # A tibble: 1 x 2
>> ??? nrow? ncol
>> ?? <int> <int>
>> 1??? 50???? 3
>>
>>
>> ### So I try the following hoping to apply the function to the grouped 
>> tibble
>> tib %>%
>> group_by(y) %>%
>> summarise(dim = list(sillyFun(.))) %>%
>> unnest_wider(dim)
>>
>> ### But that gives me:
>> # A tibble: 3 x 3
>> ?????? y? nrow? ncol
>> ?? <dbl> <int> <int>
>> 1???? 1??? 50???? 3
>> 2???? 2??? 50???? 3
>> 3???? 3??? 50???? 3
>>
>> Clearly "." is still passing the whole tibble, not the grouped 
>> subsets.? What I can't find is whether there is an alternative to "." 
>> that would pass just the grouped subset of the tibble.
>>
>> I have bodged my way around this by writing a function that takes 
>> individual columns and reassembles them into a data frame that the 
>> actual functions I need to use require but that takes me back to a lot 
>> of clumsiness both selecting the variables to pass in the dplyr call 
>> to the function and putting the reassemble-to-data-frame bit in the 
>> function I call.? (The functions I really need are reliability 
>> explorations and can called on whole dataframes.)
>>
>> I know I can do this using base R split and lapply but I feel sure it 
>> must be possible to do this within dplyr/tidyverse.? I'm slowly 
>> transferring most of my code to the tidyverse and hitting frustrations 
>> but also finding that it does really help me program more sensibly, 
>> handle relational data structures more easily, and write code that I 
>> seem better at reading when I come back to it after months on other 
>> things so I am slowly trying to move all my coding to tidyverse.? If I 
>> could see how to do this, it would help.
>>
>> Very sorry if the answer should be blindingly obvious to me.? I'd also 
>> love to have pointers to guidance to the tidyverse written for people 
>> who aren't professional coders or statisticians and that go a bit 
>> beyond the obvious basics of tidyverse into issues like this.
>>
>> TIA,
>>
>> Chris
>>
> 

-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From chr|@ho|d @end|ng |rom p@yctc@org  Sun Jul  5 14:00:48 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Sun, 5 Jul 2020 13:00:48 +0100 (BST)
Subject: [R] Can I pass the grouped portions of a dataframe/tibble to a
 function in dplyr
In-Reply-To: <5e822ed0-2285-306e-7ee5-c90e444812ef@sapo.pt>
References: <436569067.11600799.1593938615607.JavaMail.zimbra@psyctc.org>
 <95eb1446-5dd4-eeec-f992-4d6ca922992b@sapo.pt>
 <5e822ed0-2285-306e-7ee5-c90e444812ef@sapo.pt>
Message-ID: <1391555008.11688982.1593950448099.JavaMail.zimbra@psyctc.org>

Ouch.  I should have know all those points Rui: my bad.  Casual behaviour while just rushing up a little example. Good to be reminded. 

group_modify()  is clearly exactly what I wanted and I will experiment with it and make sure I understand it properly.  I see from the help that it evolves from, or supercedes aspects of do() which I think must have been the function I had forgotten.  Even more interestingly I see that it seems to lead me into interesting options and experimental developments in tidyverse that I didn't know.

Excellent.  Perfect help ... many thanks!

Chris

----- Original Message -----
> From: "Rui Barradas" <ruipbarradas at sapo.pt>
> To: "Chris Evans" <chrishold at psyctc.org>, "R-help" <r-help at r-project.org>
> Sent: Sunday, 5 July, 2020 13:16:19
> Subject: Re: [R] Can I pass the grouped portions of a dataframe/tibble to a function in dplyr

> Hello,
> 
> I forgot to say I redid the data set setting the RNG seed first.
> 
> 
> 
> set.seed(2020)
> n <- 50
> x <- 1:n
> y <- sample(1:3, n, replace = TRUE)
> z <- rnorm(n)
> tib <- tibble(x,y,z)
> 
> 
> Also, don't do
> 
> as_tibble(cbind(...))
> as.data.frame(cbind(...))
> 
> 
> If one of the variables is of a different class (example, "character")
> all variables are coerced to the least common denominator. It's much
> better to call tibble() or data.frame() directly.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 12:04 de 05/07/2020, Rui Barradas escreveu:
>> Hello,
>> 
>> You can pass a grouped tibble to a function with grouped_modify but the
>> function must return a data.frame (or similar).
>> 
>> ## this will also do it
>> #sillyFun <- function(tib){
>> #? tibble(nrow = nrow(tib), ncol = ncol(tib))
>> #}
>> 
>> 
>> sillyFun <- function(tib){
>>  ? data.frame(nrow = nrow(tib), ncol = ncol(tib)))
>> }
>> 
>> tib %>%
>>  ? group_by(y) %>%
>>  ? group_modify(~ sillyFun(.))
>> ## A tibble: 3 x 3
>> ## Groups:?? y [3]
>> #????? y? nrow? ncol
>> #? <dbl> <int> <int>
>> #1???? 1??? 17???? 2
>> #2???? 2??? 21???? 2
>> #3???? 3??? 12???? 2
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> ?s 09:43 de 05/07/2020, Chris Evans escreveu:
>>> Apologies if this is a stupid question but searching keeps getting
>>> things I know and don't need.
>>>
>>> What I want to do is to use the group-by() power of dplyr to run
>>> functions that expect a dataframe/tibble per group but I can't see how
>>> do it. Here is a reproducible example.
>>>
>>> ### create trivial tibble
>>> n <- 50
>>> x <- 1:n
>>> y <- sample(1:3, n, replace = TRUE)
>>> z <- rnorm(n)
>>> tib <- as_tibble(cbind(x,y,z))
>>>
>>> ### create trivial function that expects a tibble/data frame
>>> sillyFun <- function(tib){
>>> return(list(nrow = nrow(tib),
>>> ncol = ncol(tib)))
>>> }
>>>
>>> ### works fine on the whole tibble
>>> tib %>%
>>> summarise(dim = list(sillyFun(.))) %>%
>>> unnest_wider(dim)
>>>
>>> That gives me:
>>> # A tibble: 1 x 2
>>> ??? nrow? ncol
>>> ?? <int> <int>
>>> 1??? 50???? 3
>>>
>>>
>>> ### So I try the following hoping to apply the function to the grouped
>>> tibble
>>> tib %>%
>>> group_by(y) %>%
>>> summarise(dim = list(sillyFun(.))) %>%
>>> unnest_wider(dim)
>>>
>>> ### But that gives me:
>>> # A tibble: 3 x 3
>>> ?????? y? nrow? ncol
>>> ?? <dbl> <int> <int>
>>> 1???? 1??? 50???? 3
>>> 2???? 2??? 50???? 3
>>> 3???? 3??? 50???? 3
>>>
>>> Clearly "." is still passing the whole tibble, not the grouped
>>> subsets.? What I can't find is whether there is an alternative to "."
>>> that would pass just the grouped subset of the tibble.
>>>
>>> I have bodged my way around this by writing a function that takes
>>> individual columns and reassembles them into a data frame that the
>>> actual functions I need to use require but that takes me back to a lot
>>> of clumsiness both selecting the variables to pass in the dplyr call
>>> to the function and putting the reassemble-to-data-frame bit in the
>>> function I call.? (The functions I really need are reliability
>>> explorations and can called on whole dataframes.)
>>>
>>> I know I can do this using base R split and lapply but I feel sure it
>>> must be possible to do this within dplyr/tidyverse.? I'm slowly
>>> transferring most of my code to the tidyverse and hitting frustrations
>>> but also finding that it does really help me program more sensibly,
>>> handle relational data structures more easily, and write code that I
>>> seem better at reading when I come back to it after months on other
>>> things so I am slowly trying to move all my coding to tidyverse.? If I
>>> could see how to do this, it would help.
>>>
>>> Very sorry if the answer should be blindingly obvious to me.? I'd also
>>> love to have pointers to guidance to the tidyverse written for people
>>> who aren't professional coders or statisticians and that go a bit
>>> beyond the obvious basics of tidyverse into issues like this.
>>>
>>> TIA,
>>>
>>> Chris
>>>
>> 
> 
> --
> Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
> https://www.avast.com/antivirus

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From cry@n @end|ng |rom b|ngh@mton@edu  Sun Jul  5 20:50:51 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Sun, 5 Jul 2020 14:50:51 -0400
Subject: [R] challenging data merging/joining problem
Message-ID: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>

I've been conducting relatively simple COVID-19 surveillance for our
jurisdiction. We get data on lab test results automatically, and then
interview patients to obtain other information, like clinical details.
We had been recording all data in our long-time data system (call it
dataSystemA). But as of a particular date, there was a major change in
the data system we were compelled to use. Call the new one dataSystemB.
dataSystemA and dataSystemB contain very similar information,
conceptually, but the variable names are all different, and there are
some variables in one that do not appear in the other. Total number of
variables in each is about 50-70.

Furthermore, for about 2 weeks prior to the transition, lab test results
started being deposited into dataSystemB while dataSystemA was still
being used to record the full information from the interviews.
Subsequent to the transition, lab test results and interview information
are being recorded in dataSystemB, while the lab test results alone are
still being automatically deposited into dataSystemA.

Diagrammatically:

dataSystemA usage: ____________________ ............>>

dataSystemB usage:               ......._____________>>

where ________ represents full data and ..... represents partial data,
and >> represents the progress of time.


The following will create MWE of the data wrangling problem, with the
change in data systems made to occur overnight on 2020-07-07:

library(dplyr)
dataSystemA <- tibble(lastName = c("POTTER", "WEASLEY", "GRAINGER",
"LONGBOTTOM"),
                      firstName = c("harry", "ron", "hermione", "neville"),
                      dob = as.Date(Sys.Date() + c(sample(-3650:-3000,
size = 2), -3500, -3450)),
                      onsetDate = as.Date(Sys.Date() + 1:4),
                      symptomatic = c(TRUE, FALSE, NA, NA) )
dataSystemB <- tibble(last_name = c("GRAINGER", "LONGBOTTOM", "MALFOY",
"LOVEGOOD", "DIGGORY"),
                      first_name = c("hermione", "neville", "draco",
"luna", "cedric"),
                      birthdate = as.Date(Sys.Date() + c(-3500, -3450,
sample(-3650:-3000, size = 3))),
                      date_of_onset = as.Date(Sys.Date() + 3:7),
                      symptoms_present = c(TRUE, TRUE, FALSE, FALSE, TRUE))



Obviously, this is all the same public health problem, so I don't want a
big uninterpretable gap in my reports. I am looking for advice on the
best strategy for combining two different tibbles with some overlap in
observations (some patients appear in both data systems, with varying
degrees of completeness of data) and with some of the same things being
mesaured and recorded in the two data systems, but with different
variable names.

I've thought of two different strategies, neither of which seems ideal
but either of which might work:

1. change the variable names in dataSystemB to match their
conceptually-identical variables in dataSystemA, and then use some
version of bind_rows()

2. Create a unique identifier from last names, first names, and dates of
birth, use some type of full_join(), matching on that identifier,
obtaining all columns from both tibbles, and then "collapse"
conceptually-identical variables like onsetDate and date_of_onset using
coalesce()

Sorry for my long-windedness. Grateful for any advice.

--Chris Ryan


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul  5 23:52:42 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 5 Jul 2020 14:52:42 -0700
Subject: [R] challenging data merging/joining problem
In-Reply-To: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
References: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
Message-ID: <CAGxFJbSNhwwX4_pZsejZptgqcg675Ja+cz5YCzmYayvZmxg42g@mail.gmail.com>

*Just my opinion* : --> feel free to disregard

I would suggest that you stop thinking in terms of tidyverse functionality
and instead think of what kind of data structure you need for your ongoing
work and where you will source data to populate that structure both now --
including legacy data -- and in future. *Then* you can decide what
functionality you need and whether/how tidyverse functionality meets those
needs. It sounds like you are tying yourself in knots by restricting
yourself to what you know of one limited paradigm. R has the richness and
flexibility to create general purpose data structures (e.g. via lists) --
tidyverse functionality may or may not be sufficient or convenient for your
needs **once you have fully defined them (which only you can do).**


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jul 5, 2020 at 11:51 AM Christopher W. Ryan <cryan at binghamton.edu>
wrote:

> I've been conducting relatively simple COVID-19 surveillance for our
> jurisdiction. We get data on lab test results automatically, and then
> interview patients to obtain other information, like clinical details.
> We had been recording all data in our long-time data system (call it
> dataSystemA). But as of a particular date, there was a major change in
> the data system we were compelled to use. Call the new one dataSystemB.
> dataSystemA and dataSystemB contain very similar information,
> conceptually, but the variable names are all different, and there are
> some variables in one that do not appear in the other. Total number of
> variables in each is about 50-70.
>
> Furthermore, for about 2 weeks prior to the transition, lab test results
> started being deposited into dataSystemB while dataSystemA was still
> being used to record the full information from the interviews.
> Subsequent to the transition, lab test results and interview information
> are being recorded in dataSystemB, while the lab test results alone are
> still being automatically deposited into dataSystemA.
>
> Diagrammatically:
>
> dataSystemA usage: ____________________ ............>>
>
> dataSystemB usage:               ......._____________>>
>
> where ________ represents full data and ..... represents partial data,
> and >> represents the progress of time.
>
>
> The following will create MWE of the data wrangling problem, with the
> change in data systems made to occur overnight on 2020-07-07:
>
> library(dplyr)
> dataSystemA <- tibble(lastName = c("POTTER", "WEASLEY", "GRAINGER",
> "LONGBOTTOM"),
>                       firstName = c("harry", "ron", "hermione", "neville"),
>                       dob = as.Date(Sys.Date() + c(sample(-3650:-3000,
> size = 2), -3500, -3450)),
>                       onsetDate = as.Date(Sys.Date() + 1:4),
>                       symptomatic = c(TRUE, FALSE, NA, NA) )
> dataSystemB <- tibble(last_name = c("GRAINGER", "LONGBOTTOM", "MALFOY",
> "LOVEGOOD", "DIGGORY"),
>                       first_name = c("hermione", "neville", "draco",
> "luna", "cedric"),
>                       birthdate = as.Date(Sys.Date() + c(-3500, -3450,
> sample(-3650:-3000, size = 3))),
>                       date_of_onset = as.Date(Sys.Date() + 3:7),
>                       symptoms_present = c(TRUE, TRUE, FALSE, FALSE, TRUE))
>
>
>
> Obviously, this is all the same public health problem, so I don't want a
> big uninterpretable gap in my reports. I am looking for advice on the
> best strategy for combining two different tibbles with some overlap in
> observations (some patients appear in both data systems, with varying
> degrees of completeness of data) and with some of the same things being
> mesaured and recorded in the two data systems, but with different
> variable names.
>
> I've thought of two different strategies, neither of which seems ideal
> but either of which might work:
>
> 1. change the variable names in dataSystemB to match their
> conceptually-identical variables in dataSystemA, and then use some
> version of bind_rows()
>
> 2. Create a unique identifier from last names, first names, and dates of
> birth, use some type of full_join(), matching on that identifier,
> obtaining all columns from both tibbles, and then "collapse"
> conceptually-identical variables like onsetDate and date_of_onset using
> coalesce()
>
> Sorry for my long-windedness. Grateful for any advice.
>
> --Chris Ryan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@p@rk4 @end|ng |rom u|c@edu  Mon Jul  6 00:06:52 2020
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Sun, 5 Jul 2020 22:06:52 +0000
Subject: [R] Opening Another Application in R Then Hangs
Message-ID: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>

Hi R Helpers,

I am trying to open another application from within R and then work with it.

I can get the application to open, but R then hangs at that point (spinning blue circle in the middle of the screen) and my subsequent programming does not execute.

Does anybody know how to get R to unlock?

I am using Windows 10 and R4.0.

The example below freezes R on my machine.

Any guidance appreciated.  Thanks.
--John Sparks

setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Accessories")
system2("Notepad",invisible=FALSE)






	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  6 00:08:53 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Jul 2020 15:08:53 -0700
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
Message-ID: <5AE111E1-16BE-4748-8BFB-3DC00B151FE5@dcn.davis.ca.us>

Exit the application you started?

On July 5, 2020 3:06:52 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Hi R Helpers,
>
>I am trying to open another application from within R and then work
>with it.
>
>I can get the application to open, but R then hangs at that point
>(spinning blue circle in the middle of the screen) and my subsequent
>programming does not execute.
>
>Does anybody know how to get R to unlock?
>
>I am using Windows 10 and R4.0.
>
>The example below freezes R on my machine.
>
>Any guidance appreciated.  Thanks.
>--John Sparks
>
>setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start
>Menu/Programs/Accessories")
>system2("Notepad",invisible=FALSE)
>
>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From j@p@rk4 @end|ng |rom u|c@edu  Mon Jul  6 00:16:12 2020
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Sun, 5 Jul 2020 22:16:12 +0000
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <5AE111E1-16BE-4748-8BFB-3DC00B151FE5@dcn.davis.ca.us>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>,
 <5AE111E1-16BE-4748-8BFB-3DC00B151FE5@dcn.davis.ca.us>
Message-ID: <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>

Hi Jeff,

Greatly appreciate your reply, but I don't quite understand it.

Perhaps I should give a little more detail.

For this example, I want to open notepad, then go to notepad and type something in.  So the program

library(KeyboardSimulator)
setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Accessories")
system2("Notepad",invisible=FALSE)
mouse.move(2423,236)
mouse.click()
keybd.type_string("Hello world!")

would do this, but it does not advance passed the system2 command.

Best wishes,
--JJS

________________________________
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Sunday, July 5, 2020 5:08 PM
To: r-help at r-project.org <r-help at r-project.org>; Sparks, John <jspark4 at uic.edu>; R-help <r-help at r-project.org>
Subject: Re: [R] Opening Another Application in R Then Hangs

Exit the application you started?

On July 5, 2020 3:06:52 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Hi R Helpers,
>
>I am trying to open another application from within R and then work
>with it.
>
>I can get the application to open, but R then hangs at that point
>(spinning blue circle in the middle of the screen) and my subsequent
>programming does not execute.
>
>Does anybody know how to get R to unlock?
>
>I am using Windows 10 and R4.0.
>
>The example below freezes R on my machine.
>
>Any guidance appreciated.  Thanks.
>--John Sparks
>
>setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start
>Menu/Programs/Accessories")
>system2("Notepad",invisible=FALSE)
>
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Mon Jul  6 00:11:48 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 6 Jul 2020 00:11:48 +0200
Subject: [R] challenging data merging/joining problem
In-Reply-To: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
References: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
Message-ID: <20200705221148.GA96551@posteo.no>

On 2020-07-05 14:50 -0400, Christopher W. Ryan wrote:
> I've been conducting relatively simple 
> COVID-19 surveillance for our jurisdiction. 

Dear Christopher,

As I am a bit unfamiliar when it comes to the 
tidyverse, I wrote these lines using regular 
data.frames:

	### Convert to data.frame
	dataSystemA <- as.data.frame(dataSystemA)
	dataSystemB <- as.data.frame(dataSystemB)
	
	### Add some unique columns to show how 
	#   they are formatted later in this pipe.
	dataSystemA$someIncompleteInfo <- 1:4
	dataSystemB$other_incomplete_info <-
	  c("Yes", "No", "Perhaps", "Sometimes", "Yes")
	
	### Add the dfs to a list, as perhaps the 
	#   data kan be read somehow using 
	#   something like
	#   sapply(c("A", "B"), read.from.somewhere)
	dat <- list("A"=dataSystemA,
	            "B"=dataSystemB)
	
	### Define a new dataSystem column in boths dfs
	dat <- sapply(names(dat), function(n, dat) {
	  dat[[n]]$dataSystem <- n
	  return(list(dat[[n]]))
	}, dat=dat)
	
	### Read from a csv file column names 
	#   where you have defined which ones 
	#   are conceptually identical.
	text <- "A,B
	lastName,last_name
	firstName,first_name
	dob,birthdate
	onsetDate,date_of_onset
	symptomatic,symptoms_present"
	conceptually.identical <- read.csv(text=text)
	
	### Rename dataSystemA columns to the 
	#   dataSystemB naming convention.
	idx <- match(x=conceptually.identical$A,
	             table=colnames(dat$A))
	colnames(dat$A)[idx] <-
	  conceptually.identical[idx,"B"]
	
	### Find all column names, and fill the
	#   ones that does not exists in each 
	#   df with NA, order the dfs by this 
	#   vector, then rbind the dfs.
	cn <- unique(unlist(lapply(dat, colnames)))
	dat <- sapply(dat, function(x, cn) {
	  x[,cn[!(cn %in% colnames(x))]] <- NA
	  list(x[,cn])
	}, cn=cn)
	dat <- do.call(rbind, dat)
	
	### Order unified df decreasingly by 
	#   last_name and birthdate
	dat <- dat[order(dat$last_name,
	  dat$birthdate, decreasing=FALSE),]
	rownames(dat) <- NULL
	
	dat

which yields

	   last_name first_name  birthdate date_of_onset symptoms_present someIncompleteInfo dataSystem other_incomplete_info
	1    DIGGORY     cedric 2011-12-16    2020-07-12             TRUE                 NA          B                   Yes
	2   GRAINGER   hermione 2010-12-05    2020-07-08               NA                  3          A                  <NA>
	3   GRAINGER   hermione 2010-12-05    2020-07-08             TRUE                 NA          B                   Yes
	4 LONGBOTTOM    neville 2011-01-24    2020-07-09               NA                  4          A                  <NA>
	5 LONGBOTTOM    neville 2011-01-24    2020-07-09             TRUE                 NA          B                    No
	6   LOVEGOOD       luna 2011-03-15    2020-07-11            FALSE                 NA          B             Sometimes
	7     MALFOY      draco 2011-07-04    2020-07-10            FALSE                 NA          B               Perhaps
	8     POTTER      harry 2010-12-16    2020-07-06             TRUE                  1          A                  <NA>
	9    WEASLEY        ron 2010-12-30    2020-07-07            FALSE                  2          A                  <NA>

When comparing the incomplete columns in each 
data system, it might be useful to do some 
reshaping like this:

	cols <- c("last_name", "birthdate", "dataSystem", "date_of_onset")
	reshape(dat[,cols],
	        idvar=c("last_name", "birthdate"),
	        timevar="dataSystem",
	        direction="wide")

which yields

	   last_name  birthdate date_of_onset.B date_of_onset.A
	1    DIGGORY 2011-03-17      2020-07-13            <NA>
	2   GRAINGER 2010-12-06      2020-07-09      2020-07-09
	4 LONGBOTTOM 2011-01-25      2020-07-10      2020-07-10
	6   LOVEGOOD 2010-10-15      2020-07-12            <NA>
	7     MALFOY 2010-12-25      2020-07-11            <NA>
	8     POTTER 2011-05-09            <NA>      2020-07-07
	9    WEASLEY 2012-04-05            <NA>      2020-07-08

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200706/a49f40f1/attachment.sig>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jul  6 00:38:28 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 5 Jul 2020 15:38:28 -0700
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
 <5AE111E1-16BE-4748-8BFB-3DC00B151FE5@dcn.davis.ca.us>
 <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
Message-ID: <d3881739-1388-626f-392b-36d452e80f35@comcast.net>

This list is not the recommended location for support of that Windows 
only package. The URL in the DESCRIPTION file has this to advise:

++++++++++++++++++


      This package doesn't work on my computer! How can I make it work?

Open aGitHub <https://github.com/ChiHangChen/KeyboardSimulator>issue and 
let us know what version of Windows you are using and what keyboard and 
mouse hardware you have connected.

++++++++++++++++++


-- David.

On 7/5/20 3:16 PM, Sparks, John wrote:
> Hi Jeff,
>
> Greatly appreciate your reply, but I don't quite understand it.
>
> Perhaps I should give a little more detail.
>
> For this example, I want to open notepad, then go to notepad and type something in.  So the program
>
> library(KeyboardSimulator)
> setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Accessories")
> system2("Notepad",invisible=FALSE)
> mouse.move(2423,236)
> mouse.click()
> keybd.type_string("Hello world!")
>
> would do this, but it does not advance passed the system2 command.
>
> Best wishes,
> --JJS
>
> ________________________________
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Sent: Sunday, July 5, 2020 5:08 PM
> To: r-help at r-project.org <r-help at r-project.org>; Sparks, John <jspark4 at uic.edu>; R-help <r-help at r-project.org>
> Subject: Re: [R] Opening Another Application in R Then Hangs
>
> Exit the application you started?
>
> On July 5, 2020 3:06:52 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>> Hi R Helpers,
>>
>> I am trying to open another application from within R and then work
>> with it.
>>
>> I can get the application to open, but R then hangs at that point
>> (spinning blue circle in the middle of the screen) and my subsequent
>> programming does not execute.
>>
>> Does anybody know how to get R to unlock?
>>
>> I am using Windows 10 and R4.0.
>>
>> The example below freezes R on my machine.
>>
>> Any guidance appreciated.  Thanks.
>> --John Sparks
>>
>> setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start
>> Menu/Programs/Accessories")
>> system2("Notepad",invisible=FALSE)
>>
>>
>>
>>
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> --
> Sent from my phone. Please excuse my brevity.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Mon Jul  6 00:46:05 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 6 Jul 2020 00:46:05 +0200
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
 <5AE111E1-16BE-4748-8BFB-3DC00B151FE5@dcn.davis.ca.us>
 <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
Message-ID: <20200705224605.GB96551@posteo.no>

On 2020-07-05 22:16 +0000, Sparks, John wrote:
> 
> For this example, I want to open notepad, 
> then go to notepad and type something in.  

Dear John,

Perhaps start Notepad in the background is 
what you mean?  Something like 

	system2("START /B Notepad", invisible=FALSE)

Found it at [1].  I'm not on Windows ever, so 
I can not test it.

What are you trying to achieve here?

Where would the things you type into Notepad 
end up?  Will R read it.  It might be more 
useful to take user input by calling 

	readline(prompt="Enter something here at least: ")

Best,
Rasmus

[1] https://superuser.com/a/591084

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200706/7414ad74/attachment.sig>

From rmh @end|ng |rom temp|e@edu  Mon Jul  6 01:03:05 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Sun, 5 Jul 2020 19:03:05 -0400
Subject: [R] [External]  challenging data merging/joining problem
In-Reply-To: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
References: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
Message-ID: <CAGx1TMDm4Ssb5iw-hGkZr4-5HZnO0YvTfqj2gB5oVruABFD-QQ@mail.gmail.com>

Have you talked directly to the designers of the new database?
One would hope that they had a clear migration path in mind.
Perhaps they just didn't document it to your satisfaction.

Rich

On Sun, Jul 5, 2020 at 2:51 PM Christopher W. Ryan <cryan at binghamton.edu> wrote:
>
> I've been conducting relatively simple COVID-19 surveillance for our
> jurisdiction. We get data on lab test results automatically, and then
> interview patients to obtain other information, like clinical details.
> We had been recording all data in our long-time data system (call it
> dataSystemA). But as of a particular date, there was a major change in
> the data system we were compelled to use. Call the new one dataSystemB.
> dataSystemA and dataSystemB contain very similar information,
> conceptually, but the variable names are all different, and there are
> some variables in one that do not appear in the other. Total number of
> variables in each is about 50-70.
>
> Furthermore, for about 2 weeks prior to the transition, lab test results
> started being deposited into dataSystemB while dataSystemA was still
> being used to record the full information from the interviews.
> Subsequent to the transition, lab test results and interview information
> are being recorded in dataSystemB, while the lab test results alone are
> still being automatically deposited into dataSystemA.
>
> Diagrammatically:
>
> dataSystemA usage: ____________________ ............>>
>
> dataSystemB usage:               ......._____________>>
>
> where ________ represents full data and ..... represents partial data,
> and >> represents the progress of time.
>
>
> The following will create MWE of the data wrangling problem, with the
> change in data systems made to occur overnight on 2020-07-07:
>
> library(dplyr)
> dataSystemA <- tibble(lastName = c("POTTER", "WEASLEY", "GRAINGER",
> "LONGBOTTOM"),
>                       firstName = c("harry", "ron", "hermione", "neville"),
>                       dob = as.Date(Sys.Date() + c(sample(-3650:-3000,
> size = 2), -3500, -3450)),
>                       onsetDate = as.Date(Sys.Date() + 1:4),
>                       symptomatic = c(TRUE, FALSE, NA, NA) )
> dataSystemB <- tibble(last_name = c("GRAINGER", "LONGBOTTOM", "MALFOY",
> "LOVEGOOD", "DIGGORY"),
>                       first_name = c("hermione", "neville", "draco",
> "luna", "cedric"),
>                       birthdate = as.Date(Sys.Date() + c(-3500, -3450,
> sample(-3650:-3000, size = 3))),
>                       date_of_onset = as.Date(Sys.Date() + 3:7),
>                       symptoms_present = c(TRUE, TRUE, FALSE, FALSE, TRUE))
>
>
>
> Obviously, this is all the same public health problem, so I don't want a
> big uninterpretable gap in my reports. I am looking for advice on the
> best strategy for combining two different tibbles with some overlap in
> observations (some patients appear in both data systems, with varying
> degrees of completeness of data) and with some of the same things being
> mesaured and recorded in the two data systems, but with different
> variable names.
>
> I've thought of two different strategies, neither of which seems ideal
> but either of which might work:
>
> 1. change the variable names in dataSystemB to match their
> conceptually-identical variables in dataSystemA, and then use some
> version of bind_rows()
>
> 2. Create a unique identifier from last names, first names, and dates of
> birth, use some type of full_join(), matching on that identifier,
> obtaining all columns from both tibbles, and then "collapse"
> conceptually-identical variables like onsetDate and date_of_onset using
> coalesce()
>
> Sorry for my long-windedness. Grateful for any advice.
>
> --Chris Ryan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jul  6 00:50:44 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Jul 2020 15:50:44 -0700
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>,
 <5AE111E1-16BE-4748-8BFB-3DC00B151FE5@dcn.davis.ca.us>
 <DM5PR13MB11612428E23C6C4BFEB3D6FFFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
Message-ID: <11E73204-A163-4E10-B5A3-69D4A0EA1D33@dcn.davis.ca.us>

If you open an app using the default settings for system2, R normally expects to let you know what the program's return value was, so if it was interactive you would need to terminate the program so there would be a result for system2 to return with. For what you actually appear to be doing you probably want to read ?system2.

On July 5, 2020 3:16:12 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>Hi Jeff,
>
>Greatly appreciate your reply, but I don't quite understand it.
>
>Perhaps I should give a little more detail.
>
>For this example, I want to open notepad, then go to notepad and type
>something in.  So the program
>
>library(KeyboardSimulator)
>setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start
>Menu/Programs/Accessories")
>system2("Notepad",invisible=FALSE)
>mouse.move(2423,236)
>mouse.click()
>keybd.type_string("Hello world!")
>
>would do this, but it does not advance passed the system2 command.
>
>Best wishes,
>--JJS
>
>________________________________
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Sunday, July 5, 2020 5:08 PM
>To: r-help at r-project.org <r-help at r-project.org>; Sparks, John
><jspark4 at uic.edu>; R-help <r-help at r-project.org>
>Subject: Re: [R] Opening Another Application in R Then Hangs
>
>Exit the application you started?
>
>On July 5, 2020 3:06:52 PM PDT, "Sparks, John" <jspark4 at uic.edu> wrote:
>>Hi R Helpers,
>>
>>I am trying to open another application from within R and then work
>>with it.
>>
>>I can get the application to open, but R then hangs at that point
>>(spinning blue circle in the middle of the screen) and my subsequent
>>programming does not execute.
>>
>>Does anybody know how to get R to unlock?
>>
>>I am using Windows 10 and R4.0.
>>
>>The example below freezes R on my machine.
>>
>>Any guidance appreciated.  Thanks.
>>--John Sparks
>>
>>setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start
>>Menu/Programs/Accessories")
>>system2("Notepad",invisible=FALSE)
>>
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jul  6 01:35:44 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 6 Jul 2020 11:35:44 +1200
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>
Message-ID: <CAB8pepwW4q5WQ9q9H3n8G-fbogd2AJgXQk3YsdYhs-eF7T_JBg@mail.gmail.com>

shell ("Notepad", wait=FALSE)

On Mon, Jul 6, 2020 at 10:07 AM Sparks, John <jspark4 at uic.edu> wrote:
>
> Hi R Helpers,
>
> I am trying to open another application from within R and then work with it.
>
> I can get the application to open, but R then hangs at that point (spinning blue circle in the middle of the screen) and my subsequent programming does not execute.
>
> Does anybody know how to get R to unlock?
>
> I am using Windows 10 and R4.0.
>
> The example below freezes R on my machine.
>
> Any guidance appreciated.  Thanks.
> --John Sparks
>
> setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Accessories")
> system2("Notepad",invisible=FALSE)
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j@p@rk4 @end|ng |rom u|c@edu  Mon Jul  6 02:26:03 2020
From: j@p@rk4 @end|ng |rom u|c@edu (Sparks, John)
Date: Mon, 6 Jul 2020 00:26:03 +0000
Subject: [R] Opening Another Application in R Then Hangs
In-Reply-To: <CAB8pepwW4q5WQ9q9H3n8G-fbogd2AJgXQk3YsdYhs-eF7T_JBg@mail.gmail.com>
References: <DM5PR13MB116116026086508F1EB0004FFA680@DM5PR13MB1161.namprd13.prod.outlook.com>,
 <CAB8pepwW4q5WQ9q9H3n8G-fbogd2AJgXQk3YsdYhs-eF7T_JBg@mail.gmail.com>
Message-ID: <DM5PR13MB1161852ACBB590CF18752B38FA690@DM5PR13MB1161.namprd13.prod.outlook.com>

For posterity, Abby's suggestion is spot on.

The small program below demonstrates the functionality.  May need to change numbers in mouse.move depending on where your copy of Notepad opens up.  You can find the position of your mouse on the screen using mouse.get_cursor()

Thanks to all, but especially to Abby.

--JJS


library(KeyboardSimulator)
setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Accessories")
shell ("Notepad", wait=FALSE)
Sys.sleep(3)
mouse.move(362,300)
mouse.click()
keybd.type_string("Hello world!")




________________________________
From: Abby Spurdle <spurdle.a at gmail.com>
Sent: Sunday, July 5, 2020 6:35 PM
To: Sparks, John <jspark4 at uic.edu>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Opening Another Application in R Then Hangs

shell ("Notepad", wait=FALSE)

On Mon, Jul 6, 2020 at 10:07 AM Sparks, John <jspark4 at uic.edu> wrote:
>
> Hi R Helpers,
>
> I am trying to open another application from within R and then work with it.
>
> I can get the application to open, but R then hangs at that point (spinning blue circle in the middle of the screen) and my subsequent programming does not execute.
>
> Does anybody know how to get R to unlock?
>
> I am using Windows 10 and R4.0.
>
> The example below freezes R on my machine.
>
> Any guidance appreciated.  Thanks.
> --John Sparks
>
> setwd("C:/Users/JSparks/AppData/Roaming/Microsoft/Windows/Start Menu/Programs/Accessories")
> system2("Notepad",invisible=FALSE)
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Jul  6 11:03:43 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 6 Jul 2020 12:03:43 +0300
Subject: [R] [External] challenging data merging/joining problem
In-Reply-To: <CAGx1TMDm4Ssb5iw-hGkZr4-5HZnO0YvTfqj2gB5oVruABFD-QQ@mail.gmail.com>
References: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
 <CAGx1TMDm4Ssb5iw-hGkZr4-5HZnO0YvTfqj2gB5oVruABFD-QQ@mail.gmail.com>
Message-ID: <CAGgJW7702t9X7040SJvnC4baCU91DR9hyer+U6=1JvSPo0+Eaw@mail.gmail.com>

Hi Christopher,
This seems pretty standard and straightforward, unless I am missing
something. You can do the "full join" without changing variable names.
Here's a small code example with two tibbles, a and b, where the
column 'x' in a corresponds to the column 'u' in b.

a <- tibble(x=1:15,y=21:35)
b <- tibble(u=c(1:10,51:55),z=31:45)
foo <- merge(a,b,by.x="x",by.y="u",all.x=TRUE,all.y=TRUE)
foo

#     x  y  z
# 1   1 21 31
# 2   2 22 32
# 3   3 23 33
# 4   4 24 34
# 5   5 25 35
# 6   6 26 36
# 7   7 27 37
# 8   8 28 38
# 9   9 29 39
# 10 10 30 40
# 11 11 31 NA
# 12 12 32 NA
# 13 13 33 NA
# 14 14 34 NA
# 15 15 35 NA
# 16 51 NA 41
# 17 52 NA 42
# 18 53 NA 43
# 19 54 NA 44
# 20 55 NA 45

HTH,
Eric

On Mon, Jul 6, 2020 at 2:07 AM Richard M. Heiberger <rmh at temple.edu> wrote:
>
> Have you talked directly to the designers of the new database?
> One would hope that they had a clear migration path in mind.
> Perhaps they just didn't document it to your satisfaction.
>
> Rich
>
> On Sun, Jul 5, 2020 at 2:51 PM Christopher W. Ryan <cryan at binghamton.edu> wrote:
> >
> > I've been conducting relatively simple COVID-19 surveillance for our
> > jurisdiction. We get data on lab test results automatically, and then
> > interview patients to obtain other information, like clinical details.
> > We had been recording all data in our long-time data system (call it
> > dataSystemA). But as of a particular date, there was a major change in
> > the data system we were compelled to use. Call the new one dataSystemB.
> > dataSystemA and dataSystemB contain very similar information,
> > conceptually, but the variable names are all different, and there are
> > some variables in one that do not appear in the other. Total number of
> > variables in each is about 50-70.
> >
> > Furthermore, for about 2 weeks prior to the transition, lab test results
> > started being deposited into dataSystemB while dataSystemA was still
> > being used to record the full information from the interviews.
> > Subsequent to the transition, lab test results and interview information
> > are being recorded in dataSystemB, while the lab test results alone are
> > still being automatically deposited into dataSystemA.
> >
> > Diagrammatically:
> >
> > dataSystemA usage: ____________________ ............>>
> >
> > dataSystemB usage:               ......._____________>>
> >
> > where ________ represents full data and ..... represents partial data,
> > and >> represents the progress of time.
> >
> >
> > The following will create MWE of the data wrangling problem, with the
> > change in data systems made to occur overnight on 2020-07-07:
> >
> > library(dplyr)
> > dataSystemA <- tibble(lastName = c("POTTER", "WEASLEY", "GRAINGER",
> > "LONGBOTTOM"),
> >                       firstName = c("harry", "ron", "hermione", "neville"),
> >                       dob = as.Date(Sys.Date() + c(sample(-3650:-3000,
> > size = 2), -3500, -3450)),
> >                       onsetDate = as.Date(Sys.Date() + 1:4),
> >                       symptomatic = c(TRUE, FALSE, NA, NA) )
> > dataSystemB <- tibble(last_name = c("GRAINGER", "LONGBOTTOM", "MALFOY",
> > "LOVEGOOD", "DIGGORY"),
> >                       first_name = c("hermione", "neville", "draco",
> > "luna", "cedric"),
> >                       birthdate = as.Date(Sys.Date() + c(-3500, -3450,
> > sample(-3650:-3000, size = 3))),
> >                       date_of_onset = as.Date(Sys.Date() + 3:7),
> >                       symptoms_present = c(TRUE, TRUE, FALSE, FALSE, TRUE))
> >
> >
> >
> > Obviously, this is all the same public health problem, so I don't want a
> > big uninterpretable gap in my reports. I am looking for advice on the
> > best strategy for combining two different tibbles with some overlap in
> > observations (some patients appear in both data systems, with varying
> > degrees of completeness of data) and with some of the same things being
> > mesaured and recorded in the two data systems, but with different
> > variable names.
> >
> > I've thought of two different strategies, neither of which seems ideal
> > but either of which might work:
> >
> > 1. change the variable names in dataSystemB to match their
> > conceptually-identical variables in dataSystemA, and then use some
> > version of bind_rows()
> >
> > 2. Create a unique identifier from last names, first names, and dates of
> > birth, use some type of full_join(), matching on that identifier,
> > obtaining all columns from both tibbles, and then "collapse"
> > conceptually-identical variables like onsetDate and date_of_onset using
> > coalesce()
> >
> > Sorry for my long-windedness. Grateful for any advice.
> >
> > --Chris Ryan
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jul  6 15:01:34 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 6 Jul 2020 15:01:34 +0200
Subject: [R] how to calculate odd ratios with R?
Message-ID: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>

Hello,
Is it possible to calculate with a single function the odd ratios?
Now I can use this implement:
```
or <- (De/He)/(Dn/Hn) # Disease exposed, Healthy non-exposed
logo <- log(or)
x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
lower_ci = exp(logo - 1.96*x)
upper_ci = exp(logo + 1.96*x)
cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
    spe = "")
```
for instance,
```
De <-6
Dn <-3
He <-4
Hn <-5
or <- (De/He)/(Dn/Hn)
logo <- log(or)
x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
lower_ci = exp(logo - 1.96*x)
upper_ci = exp(logo + 1.96*x)
cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
    spe = "")
> OR: 2.5 ( 0.37 - 16.889 )
```
Is there a simple function from some package that can also add a
p-value to this test? Or how can I calculate the p-value on my own?
-- 
Best regards,
Luigi


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Jul  6 15:17:57 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Mon, 6 Jul 2020 13:17:57 +0000
Subject: [R] how to calculate odd ratios with R?
In-Reply-To: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
References: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
Message-ID: <MN2PR03MB5167BFBB3DF5C43474571C4EE2690@MN2PR03MB5167.namprd03.prod.outlook.com>

Luigi,
Odds ratios can be produced using a logistic regression, which can be performed using the glm function. The following has a detailed description of how logistic regression can be performed using R:

https://stats.idre.ucla.edu/r/dae/logit-regression/

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Luigi Marongiu <marongiu.luigi at gmail.com>
Sent: Monday, July 6, 2020 9:01 AM
To: r-help <r-help at r-project.org>
Subject: [R] how to calculate odd ratios with R?

Hello,
Is it possible to calculate with a single function the odd ratios?
Now I can use this implement:
```
or <- (De/He)/(Dn/Hn) # Disease exposed, Healthy non-exposed
logo <- log(or)
x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
lower_ci = exp(logo - 1.96*x)
upper_ci = exp(logo + 1.96*x)
cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
    spe = "")
```
for instance,
```
De <-6
Dn <-3
He <-4
Hn <-5
or <- (De/He)/(Dn/Hn)
logo <- log(or)
x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
lower_ci = exp(logo - 1.96*x)
upper_ci = exp(logo + 1.96*x)
cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
    spe = "")
> OR: 2.5 ( 0.37 - 16.889 )
```
Is there a simple function from some package that can also add a
p-value to this test? Or how can I calculate the p-value on my own?
--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7C2cd90411f0e34701d7f308d821acceb7%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637296373389265031&amp;sdata=GVQUX4DafNEu29kEupPbDrNblkQyas3LquN%2FVahCFPw%3D&amp;reserved=0
PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7C2cd90411f0e34701d7f308d821acceb7%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637296373389265031&amp;sdata=9hLF%2F0BrW3Tn%2BleeHoXaoRXY0NNxeXVQZAJQEvLBn7E%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jul  6 15:21:00 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 6 Jul 2020 14:21:00 +0100
Subject: [R] how to calculate odd ratios with R?
In-Reply-To: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
References: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
Message-ID: <d8fac0dc-1b43-b15d-bf81-849500a4698e@dewey.myzen.co.uk>

Dear Luigi

You could try the epitools package which gives a large number of ways of 
doing this. I would have thought that using Wald intervals for the log 
odds ration was not optimal with small frequencies.

Michael

On 06/07/2020 14:01, Luigi Marongiu wrote:
> Hello,
> Is it possible to calculate with a single function the odd ratios?
> Now I can use this implement:
> ```
> or <- (De/He)/(Dn/Hn) # Disease exposed, Healthy non-exposed
> logo <- log(or)
> x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
> lower_ci = exp(logo - 1.96*x)
> upper_ci = exp(logo + 1.96*x)
> cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
>      spe = "")
> ```
> for instance,
> ```
> De <-6
> Dn <-3
> He <-4
> Hn <-5
> or <- (De/He)/(Dn/Hn)
> logo <- log(or)
> x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
> lower_ci = exp(logo - 1.96*x)
> upper_ci = exp(logo + 1.96*x)
> cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
>      spe = "")
>> OR: 2.5 ( 0.37 - 16.889 )
> ```
> Is there a simple function from some package that can also add a
> p-value to this test? Or how can I calculate the p-value on my own?
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jr@| @end|ng |rom po@teo@no  Mon Jul  6 18:15:00 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 6 Jul 2020 18:15:00 +0200
Subject: [R] [External] challenging data merging/joining problem
In-Reply-To: <CAGgJW7702t9X7040SJvnC4baCU91DR9hyer+U6=1JvSPo0+Eaw@mail.gmail.com>
References: <65c1134b-5aaf-6f9f-b1b4-f238f0bc047d@binghamton.edu>
 <CAGx1TMDm4Ssb5iw-hGkZr4-5HZnO0YvTfqj2gB5oVruABFD-QQ@mail.gmail.com>
 <CAGgJW7702t9X7040SJvnC4baCU91DR9hyer+U6=1JvSPo0+Eaw@mail.gmail.com>
Message-ID: <20200706161500.GA753@posteo.no>

On 2020-07-06 12:03 +0300, Eric Berger wrote:
> On Mon, Jul 6, 2020 at 2:07 AM Richard M. Heiberger <rmh at temple.edu> wrote:
> > On Sun, Jul 5, 2020 at 2:51 PM Christopher W. Ryan <cryan at binghamton.edu> wrote:
> > >
> > > I've been conducting relatively simple 
> > > COVID-19 surveillance for our 
> > > jurisdiction. 
> >
> > Have you talked directly to the designers 
> > of the new database?
> 
> Hi Christopher,
> This seems pretty standard and 
> straightforward, unless I am missing 
> something. You can do the "full join" 
> without changing variable names.  Here's a 
> small code example with two tibbles, a and 
> b, where the column 'x' in a corresponds to 
> the column 'u' in b.
> 
> a <- tibble(x=1:15,y=21:35)
> b <- tibble(u=c(1:10,51:55),z=31:45)
> foo <- merge(a,b,by.x="x",by.y="u",all.x=TRUE,all.y=TRUE)

Perhaps something like

	new_names <-
	  c("dob"="birthdate",
	    "lastName"="last_name",
	    "firstName"="first_name")
	idx <- match(x=names(new_names),
	  table=colnames(dataSystemA))
	colnames(dataSystemA)[idx] <- new_names
	merge(
	  x=dataSystemA,
	  y=dataSystemB,
	  by=new_names,
	  all=TRUE)

which yields

	   birthdate  last_name first_name  onsetDate
	1 2010-10-11   LOVEGOOD       luna       <NA>
	2 2010-12-06   GRAINGER   hermione 2020-07-09
	3 2011-01-25 LONGBOTTOM    neville 2020-07-10
	4 2011-07-03     MALFOY      draco       <NA>
	5 2011-07-14    WEASLEY        ron 2020-07-08
	6 2011-10-04     POTTER      harry 2020-07-07
	7 2012-02-13    DIGGORY     cedric       <NA>
	  symptomatic date_of_onset symptoms_present
	1          NA    2020-07-12            FALSE
	2          NA    2020-07-09             TRUE
	3          NA    2020-07-10             TRUE
	4          NA    2020-07-11            FALSE
	5       FALSE          <NA>               NA
	6        TRUE          <NA>               NA
	7          NA    2020-07-13             TRUE

?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200706/b6602a2b/attachment.sig>

From herd_dog @end|ng |rom cox@net  Mon Jul  6 18:29:16 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Mon, 6 Jul 2020 09:29:16 -0700
Subject: [R] National Weather Service Data
In-Reply-To: <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
Message-ID: <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>

I am trying to access National Weather Service forecasting data through the rNOMADS package.  I?m not sure if the Weather Service software ? grib2 ? loaded correctly.  Second, some of the examples in the rNOMADS documentation seem to run correctly but I?m not sure what the output means.  Any anvise would be greatly appreciated.

1 - I tried to load the wgrib2 software from instructions in the following website:

    https://bovineaerospace.wordpress.com/2015/04/26/how-to-install-rnomads-with-grib-file-support-on-windows/

2 ? the instructions say that if it loaded correctly I should get a laundry list similar to what is below from the command: >system(?wgrib2?).



The list I get looks different.  Below is the first 20 or so entries.  How can I check to see if the wgrib2 loaded correctly?

wgrib2 v0.1.9.9 9/2013 Wesley Ebisuzaki, Reinoud Bokhorst, Jaakko Hyv??tti, Dusan Jovic, Kristian Nilssen, Karl Pfeiffer, Pablo Romero, Manfred Schwarb, Arlindo da Silva, Niklas Sondell, Sergey Varlamov
-0xSec           inv  X      Hex dump of section X (0..8)
-MM              inv         reference time MM
-N_ens           inv         number of ensemble members
-RT              inv         type of reference Time
-S               inv         simple inventory with minutes and seconds (subject to change)
-Sec0            inv         contents of section0
-Sec3            inv         contents of section 3 (Grid Definition Section)
-Sec4            inv         Sec 4 values (Product definition section)
-Sec5            inv         Sec 5 values (Data representation section)
-Sec6            inv         show bit-map section
-Sec_len         inv         length of various grib sections
-T               inv         reference time YYYYMMDDHHMMSS
-V               inv         diagnostic output
-VT              inv         verf time = reference_time + forecast_time (YYYYMMDDHHMMSS)
-YY              inv         reference time YYYY

3 ? As I said, some of the documentation examples work and for some I get error messages.  Below is an example of one that seemed to work but I don?t understand the output.

#GribInfo - page 20
urlsOut <- CrawlModels(abbrev="gfs_0p50",depth=2)
ModelParameters <- ParseModelPage(urlsOut[2])#[1] is most recent model
MyPred <- ModelParameters$pred[grep("06$",ModelParameters$pred)]
   Levels <- c("2_m_above_ground","800_mb")
   Variables <- c("TMP","RH")
   GribInfo <- GribGrab(urlsOut[2],MyPred,Levels,Variables)
GribInv <- GribInfo(GribInfo[[1]]$file.name,"grib2")

The command GribInv$inventory returns:

$inventory
[1] "1:0:d=2020070606:TMP:800 mb:6 hour fcst:"                "2:148450:d=2020070606:RH:800 mb:6 hour fcst:"           
[3] "3:414132:d=2020070606:TMP:2 m above ground:6 hour fcst:" "4:571266:d=2020070606:RH:2 m above ground:6 hour fcst:" 

This is supposed to be temperature and relative humidity 2 meters above the ground and at 800 milibars for 2020 ? July 6 ? at ZULU time 0600.  But I have no idea what the numbers 414132 ? second line ? mean.

Any advise would be greatly appreciated.

Philip Heinrich

From: stephen sefick 
Sent: Thursday, July 2, 2020 3:20 PM
To: Philip 
Cc: r-help 
Subject: Re: [R] National Weather Service Data

I am unfamiliar with Rnomads. Could you provide a minimal reproducable example? You are more likely to receive help this way.


On Thu, Jul 2, 2020, 18:06 Philip <herd_dog at cox.net> wrote:

  Is anyone out there familiar with rNOMADS?  It is a package to get into National Weather Service forecasting data with R?

  I'm not sure the Weather Service software named wgrib2 loaded correctly because some of the stuff won't run and I can't make much sense out of some of the output.

  Thanks.
          [[alternative HTML version deleted]]

  ______________________________________________
  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
  https://stat.ethz.ch/mailman/listinfo/r-help
  PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
  and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From t@n@@@ @end|ng |rom gm@||@com  Mon Jul  6 19:11:28 2020
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Mon, 6 Jul 2020 10:11:28 -0700
Subject: [R] algorithms that cluster time series data
Message-ID: <CA+JEM00+H=cvExq1uXPkKzT1CXht5N1zq-aCcQ5C+BPakWnz7Q@mail.gmail.com>

Dear all,

please may I ask for a suggestion regarding the algorithms to cluster the
expression data in single cells (scRNA-seq) at multiple time points :

we do have expression data for 30 000 genes  in 10 datasets that have been
collected at multiple time points,

and i was wondering if you could please recommend *any algorithms/R
packages that could help with the clustering of the gene expression at
different time points.* thanks a lot, and all the best,

-- bogdan

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Mon Jul  6 19:20:34 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Mon, 6 Jul 2020 13:20:34 -0400
Subject: [R] algorithms that cluster time series data
In-Reply-To: <CA+JEM00+H=cvExq1uXPkKzT1CXht5N1zq-aCcQ5C+BPakWnz7Q@mail.gmail.com>
References: <CA+JEM00+H=cvExq1uXPkKzT1CXht5N1zq-aCcQ5C+BPakWnz7Q@mail.gmail.com>
Message-ID: <CAM_vjum0dqqOBkJqqO72wjAzJfW5DGvCyg=zMCbgNzHROtjYvg@mail.gmail.com>

Hi,

Unsupervised classification (clustering) is a huge field. There's an
entire task view devoted to it, where you can see many of the large
array of R packages that perform some sort of clustering.

https://cran.r-project.org/web/views/Cluster.html

Since that is an overwhelming list, you may be best served by looking
at how others in your field have approached similar problems, and then
look for R packages that perform the relevant analyses.

Sarah

On Mon, Jul 6, 2020 at 1:11 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
>
> Dear all,
>
> please may I ask for a suggestion regarding the algorithms to cluster the
> expression data in single cells (scRNA-seq) at multiple time points :
>
> we do have expression data for 30 000 genes  in 10 datasets that have been
> collected at multiple time points,
>
> and i was wondering if you could please recommend *any algorithms/R
> packages that could help with the clustering of the gene expression at
> different time points.* thanks a lot, and all the best,
>
> -- bogdan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From roy@mende|@@ohn @end|ng |rom no@@@gov  Mon Jul  6 19:43:13 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 6 Jul 2020 10:43:13 -0700
Subject: [R] National Weather Service Data
In-Reply-To: <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
Message-ID: <28C66B99-9B31-45E1-BEB0-AF88E81D4C67@noaa.gov>

Hi Philip:

Results look correct to me.  This might help you:

https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/default_inv.html

-Roy


> On Jul 6, 2020, at 9:29 AM, Philip <herd_dog at cox.net> wrote:
> 
> I am trying to access National Weather Service forecasting data through the rNOMADS package.  I?m not sure if the Weather Service software ? grib2 ? loaded correctly.  Second, some of the examples in the rNOMADS documentation seem to run correctly but I?m not sure what the output means.  Any anvise would be greatly appreciated.
> 
> 1 - I tried to load the wgrib2 software from instructions in the following website:
> 
>    https://bovineaerospace.wordpress.com/2015/04/26/how-to-install-rnomads-with-grib-file-support-on-windows/
> 
> 2 ? the instructions say that if it loaded correctly I should get a laundry list similar to what is below from the command: >system(?wgrib2?).
> 
> 
> 
> The list I get looks different.  Below is the first 20 or so entries.  How can I check to see if the wgrib2 loaded correctly?
> 
> wgrib2 v0.1.9.9 9/2013 Wesley Ebisuzaki, Reinoud Bokhorst, Jaakko Hyv??tti, Dusan Jovic, Kristian Nilssen, Karl Pfeiffer, Pablo Romero, Manfred Schwarb, Arlindo da Silva, Niklas Sondell, Sergey Varlamov
> -0xSec           inv  X      Hex dump of section X (0..8)
> -MM              inv         reference time MM
> -N_ens           inv         number of ensemble members
> -RT              inv         type of reference Time
> -S               inv         simple inventory with minutes and seconds (subject to change)
> -Sec0            inv         contents of section0
> -Sec3            inv         contents of section 3 (Grid Definition Section)
> -Sec4            inv         Sec 4 values (Product definition section)
> -Sec5            inv         Sec 5 values (Data representation section)
> -Sec6            inv         show bit-map section
> -Sec_len         inv         length of various grib sections
> -T               inv         reference time YYYYMMDDHHMMSS
> -V               inv         diagnostic output
> -VT              inv         verf time = reference_time + forecast_time (YYYYMMDDHHMMSS)
> -YY              inv         reference time YYYY
> 
> 3 ? As I said, some of the documentation examples work and for some I get error messages.  Below is an example of one that seemed to work but I don?t understand the output.
> 
> #GribInfo - page 20
> urlsOut <- CrawlModels(abbrev="gfs_0p50",depth=2)
> ModelParameters <- ParseModelPage(urlsOut[2])#[1] is most recent model
> MyPred <- ModelParameters$pred[grep("06$",ModelParameters$pred)]
>   Levels <- c("2_m_above_ground","800_mb")
>   Variables <- c("TMP","RH")
>   GribInfo <- GribGrab(urlsOut[2],MyPred,Levels,Variables)
> GribInv <- GribInfo(GribInfo[[1]]$file.name,"grib2")
> 
> The command GribInv$inventory returns:
> 
> $inventory
> [1] "1:0:d=2020070606:TMP:800 mb:6 hour fcst:"                "2:148450:d=2020070606:RH:800 mb:6 hour fcst:"           
> [3] "3:414132:d=2020070606:TMP:2 m above ground:6 hour fcst:" "4:571266:d=2020070606:RH:2 m above ground:6 hour fcst:" 
> 
> This is supposed to be temperature and relative humidity 2 meters above the ground and at 800 milibars for 2020 ? July 6 ? at ZULU time 0600.  But I have no idea what the numbers 414132 ? second line ? mean.
> 
> Any advise would be greatly appreciated.
> 
> Philip Heinrich
> 
> From: stephen sefick 
> Sent: Thursday, July 2, 2020 3:20 PM
> To: Philip 
> Cc: r-help 
> Subject: Re: [R] National Weather Service Data
> 
> I am unfamiliar with Rnomads. Could you provide a minimal reproducable example? You are more likely to receive help this way.
> 
> 
> On Thu, Jul 2, 2020, 18:06 Philip <herd_dog at cox.net> wrote:
> 
>  Is anyone out there familiar with rNOMADS?  It is a package to get into National Weather Service forecasting data with R?
> 
>  I'm not sure the Weather Service software named wgrib2 loaded correctly because some of the stuff won't run and I can't make much sense out of some of the output.
> 
>  Thanks.
>          [[alternative HTML version deleted]]
> 
>  ______________________________________________
>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>  and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From jr@| @end|ng |rom po@teo@no  Mon Jul  6 19:42:46 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 6 Jul 2020 19:42:46 +0200
Subject: [R] National Weather Service Data
In-Reply-To: <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
Message-ID: <20200706174246.GA45429@posteo.no>

On 2020-07-06 09:29 -0700, Philip wrote:
> $inventory
> [1] "1:0:d=2020070606:TMP:800 mb:6 hour fcst:"                "2:148450:d=2020070606:RH:800 mb:6 hour fcst:"           
> [3] "3:414132:d=2020070606:TMP:2 m above ground:6 hour fcst:" "4:571266:d=2020070606:RH:2 m above ground:6 hour fcst:" 
> 
> But I have no idea what the numbers 414132 
> ? second line ? mean.

Dear Philip,

This page[1] says it's the byte location.  
?byte location of the start of the message 
starting from 0? 

Best,
Rasmus

[1] https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/default_inv.html

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200706/64019fec/attachment.sig>

From t@n@@@ @end|ng |rom gm@||@com  Mon Jul  6 20:14:28 2020
From: t@n@@@ @end|ng |rom gm@||@com (Bogdan Tanasa)
Date: Mon, 6 Jul 2020 11:14:28 -0700
Subject: [R] algorithms that cluster time series data
In-Reply-To: <CAM_vjum0dqqOBkJqqO72wjAzJfW5DGvCyg=zMCbgNzHROtjYvg@mail.gmail.com>
References: <CA+JEM00+H=cvExq1uXPkKzT1CXht5N1zq-aCcQ5C+BPakWnz7Q@mail.gmail.com>
 <CAM_vjum0dqqOBkJqqO72wjAzJfW5DGvCyg=zMCbgNzHROtjYvg@mail.gmail.com>
Message-ID: <CA+JEM01f+0Pq=xRP2oA9iYOpN+6soZQSzf0ByEcj3_9Z90A5KQ@mail.gmail.com>

Dear Sarah,

thank you very much for pointing to the list of available packages and
algorithms.

On Mon, Jul 6, 2020 at 10:20 AM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> Unsupervised classification (clustering) is a huge field. There's an
> entire task view devoted to it, where you can see many of the large
> array of R packages that perform some sort of clustering.
>
> https://cran.r-project.org/web/views/Cluster.html
>
> Since that is an overwhelming list, you may be best served by looking
> at how others in your field have approached similar problems, and then
> look for R packages that perform the relevant analyses.
>
> Sarah
>
> On Mon, Jul 6, 2020 at 1:11 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
> >
> > Dear all,
> >
> > please may I ask for a suggestion regarding the algorithms to cluster the
> > expression data in single cells (scRNA-seq) at multiple time points :
> >
> > we do have expression data for 30 000 genes  in 10 datasets that have
> been
> > collected at multiple time points,
> >
> > and i was wondering if you could please recommend *any algorithms/R
> > packages that could help with the clustering of the gene expression at
> > different time points.* thanks a lot, and all the best,
> >
> > -- bogdan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jul  6 21:01:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 6 Jul 2020 12:01:15 -0700
Subject: [R] algorithms that cluster time series data
In-Reply-To: <CAM_vjum0dqqOBkJqqO72wjAzJfW5DGvCyg=zMCbgNzHROtjYvg@mail.gmail.com>
References: <CA+JEM00+H=cvExq1uXPkKzT1CXht5N1zq-aCcQ5C+BPakWnz7Q@mail.gmail.com>
 <CAM_vjum0dqqOBkJqqO72wjAzJfW5DGvCyg=zMCbgNzHROtjYvg@mail.gmail.com>
Message-ID: <CAGxFJbQbBCVBW=WTgBovxpMgiuGimnpzmCbxKGYjD67oiw26jA@mail.gmail.com>

And since this is about RNA expression data, you would do better posting on
the Bioconductor Help site rather than here. You are more likely to find
the expertise and interest you seek there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jul 6, 2020 at 10:22 AM Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Hi,
>
> Unsupervised classification (clustering) is a huge field. There's an
> entire task view devoted to it, where you can see many of the large
> array of R packages that perform some sort of clustering.
>
> https://cran.r-project.org/web/views/Cluster.html
>
> Since that is an overwhelming list, you may be best served by looking
> at how others in your field have approached similar problems, and then
> look for R packages that perform the relevant analyses.
>
> Sarah
>
> On Mon, Jul 6, 2020 at 1:11 PM Bogdan Tanasa <tanasa at gmail.com> wrote:
> >
> > Dear all,
> >
> > please may I ask for a suggestion regarding the algorithms to cluster the
> > expression data in single cells (scRNA-seq) at multiple time points :
> >
> > we do have expression data for 30 000 genes  in 10 datasets that have
> been
> > collected at multiple time points,
> >
> > and i was wondering if you could please recommend *any algorithms/R
> > packages that could help with the clustering of the gene expression at
> > different time points.* thanks a lot, and all the best,
> >
> > -- bogdan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @te|@nML @end|ng |rom co||oc@t|on@@de  Mon Jul  6 22:28:33 2020
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stefan Evert)
Date: Mon, 6 Jul 2020 22:28:33 +0200
Subject: [R] how to calculate odd ratios with R?
In-Reply-To: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
References: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
Message-ID: <8F44062F-1B2C-4365-9132-8452EE0403EF@collocations.de>

fisher.test() computes exact confidence intervals for the odds ratio.

> On 6 Jul 2020, at 15:01, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Is there a simple function from some package that can also add a
> p-value to this test? Or how can I calculate the p-value on my own?


From herd_dog @end|ng |rom cox@net  Tue Jul  7 02:41:05 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Mon, 6 Jul 2020 17:41:05 -0700
Subject: [R] National Weather Service Data
In-Reply-To: <20200706174246.GA45429@posteo.no>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC> <20200706174246.GA45429@posteo.no>
Message-ID: <5CCE4FB770DE4F858303392BFCE9018B@OWNERPC>

Thanks for getting back to me.  It is good to know that I am on the right 
track.

-----Original Message----- 
From: Rasmus Liland
Sent: Monday, July 6, 2020 10:42 AM
To: r-help
Subject: Re: [R] National Weather Service Data

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Tue Jul  7 03:51:58 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 7 Jul 2020 03:51:58 +0200
Subject: [R] National Weather Service Data
In-Reply-To: <5CCE4FB770DE4F858303392BFCE9018B@OWNERPC>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
 <20200706174246.GA45429@posteo.no>
 <5CCE4FB770DE4F858303392BFCE9018B@OWNERPC>
Message-ID: <20200707015158.GB59826@posteo.no>

On 2020-07-06 17:41 -0700, Philip wrote:
> Thanks for getting back to me.  It is good 
> to know that I am on the right track.

Oh, it's always such a pleasure to be of help 
to someone in need :-)

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200707/e466908f/attachment.sig>

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jul  7 08:57:28 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 7 Jul 2020 08:57:28 +0200
Subject: [R] How to compare the fitting of function?
Message-ID: <CAMk+s2SkvBUjoT5-3zSS8M6vqWsVX4W_XRNca4Czm-ZBkS-2MQ@mail.gmail.com>

Hello,
I have fitted two curves to the data. How can I tell which one is more
fitted? By eye (see plot underneath) I would say that the function
Gompertz is better than the function Holling type III; how can I give
a number to this hunch?
This is an example:
```
# functions
holling = function(a, b, x) {
  y = (a * x^2) / (b^2 + x^2)
  return(y)
}
gompertz = function(a, b, c, x) {
  y = a * exp(-b * exp(-c * x))
  return(y)
}
# data
actual <- c(8,  24,  39,  63,  89, 115, 153)
holling <- c(4.478803,  17.404533,  37.384128,  62.492663,  90.683630,
120.118174, 149.347683)
gompertz <- c(11.30771,  22.39017,  38.99516,  61.19318,  88.23403,
118.77225, 151.19849)
# plot
plot(1:length(actual), actual, lty = 1 , type = "l", lwd = 2,
     xlab = "Index", ylab = "Values")
points(1:length(actual), holling, lty = 2, type = "l", col = "red")
points(1:length(actual), gompertz, lty = 3, type = "l", col = "blue")
legend("bottomright",
       legend = c("Actual values", "Holling III", "Gompertz"),
       lty = c(1, 2, 3), lwd = c(2, 1,1), col = c("black", "red", "blue"))
```
Thank you


From o||ver@b@|mer @end|ng |rom un|b@@@ch  Mon Jul  6 23:38:23 2020
From: o||ver@b@|mer @end|ng |rom un|b@@@ch (Oliver Balmer)
Date: Mon, 6 Jul 2020 23:38:23 +0200
Subject: [R] crash when opening existing scripts
Message-ID: <04a54eef-ac83-5b3d-3217-14c516d0f4a1@unibas.ch>

I have a newly installed R (v. 4.0.2) on an all new MacBook Pro with OS 
Catalina (v. 10.15.4). R works perfectly smooth except for one thing: 
Many of my scripts (but not all - and consistently the same) will cause 
R to crash when I attempt to open them either by double-clicking them or 
by opening them from within R with File>Open Recent. I never had that 
problem before and I did not find answers to this problem in older posts 
or StackOverflow. The only way to open them is to open them in another 
text editor and copy-paste them into a new script within R. But when I 
then save that new script and try to reopen it, the same thing happens 
again.

*Dr. Oliver Balmer*
Project leader
Tel. +41 (0)61 284 87 48
oliver.balmer at swisstph.ch

*Swiss Tropical and Public Health Institute*
Socinstrasse 57, 4051 Basel, Switzerland
www.swisstph.ch


	[[alternative HTML version deleted]]


From bhh @end|ng |rom x@4@||@n|  Tue Jul  7 09:38:37 2020
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Tue, 7 Jul 2020 09:38:37 +0200
Subject: [R] crash when opening existing scripts
In-Reply-To: <04a54eef-ac83-5b3d-3217-14c516d0f4a1@unibas.ch>
References: <04a54eef-ac83-5b3d-3217-14c516d0f4a1@unibas.ch>
Message-ID: <D087A35E-D657-4472-AF29-6A29154D6576@xs4all.nl>



> On 6 Jul 2020, at 23:38, Oliver Balmer <oliver.balmer at unibas.ch> wrote:
> 
> I have a newly installed R (v. 4.0.2) on an all new MacBook Pro with OS 
> Catalina (v. 10.15.4). R works perfectly smooth except for one thing: 
> Many of my scripts (but not all - and consistently the same) will cause 
> R to crash when I attempt to open them either by double-clicking them or 
> by opening them from within R with File>Open Recent. I never had that 
> problem before and I did not find answers to this problem in older posts 
> or StackOverflow. The only way to open them is to open them in another 
> text editor and copy-paste them into a new script within R. But when I 
> then save that new script and try to reopen it, the same thing happens 
> again.
> 

This belongs on the R-SIG-Mac list (https://stat.ethz.ch/pipermail/r-sig-mac/).

See this thread:  https://stat.ethz.ch/pipermail/r-sig-mac/2020-June/013575.html

and the solution: https://stat.ethz.ch/pipermail/r-sig-mac/2020-July/013641.html

Berend Hasselman


From c@t@||nro|bu @end|ng |rom gm@||@com  Tue Jul  7 12:00:11 2020
From: c@t@||nro|bu @end|ng |rom gm@||@com (Catalin Roibu)
Date: Tue, 7 Jul 2020 13:00:11 +0300
Subject: [R] unique scale color ggplot2
Message-ID: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>

Dear R users,

I want to create a plot for multiple sites and to keep the same color range
scale (the correlation values range from -0.5 to 0.7 for all data, but I
have sites with different min and max).

I used this code:
cols<-c("#0288D1", "#039BE5", "#03A9F4","#29B6F6", "#4FC3F7", "#FFCDD2",
"#E57373", "#F44336", "#E53935", "#D32F2F", "#C62828", "#B71C1C")
zCuts <-seq(-.5, 0.6, by = 0.1)
p<-ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill = cut(cor,
zCuts))) +
  geom_tile() +
  scale_fill_manual(values=cols)

but for each site the scale color is different.


Please help me to solve this problem!

Thank you!


Bests!

Catalin




-- 

-
-
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jul  7 12:44:10 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 7 Jul 2020 12:44:10 +0200
Subject: [R] unique scale color ggplot2
In-Reply-To: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>
References: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>
Message-ID: <CAJuCY5wA74CMAbYt2AnLMyOTCyN2dZH0U2NLEOhokG7dRNt5QA@mail.gmail.com>

Dear Catalin,

use scale_fill_gradient() and set fixed limits

ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill = cut(cor,
zCuts))) +
  geom_tile() +
  scale_fill_gradient(limits = c(-0.7, 0.7))

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 7 jul. 2020 om 12:02 schreef Catalin Roibu <catalinroibu at gmail.com>:

> Dear R users,
>
> I want to create a plot for multiple sites and to keep the same color range
> scale (the correlation values range from -0.5 to 0.7 for all data, but I
> have sites with different min and max).
>
> I used this code:
> cols<-c("#0288D1", "#039BE5", "#03A9F4","#29B6F6", "#4FC3F7", "#FFCDD2",
> "#E57373", "#F44336", "#E53935", "#D32F2F", "#C62828", "#B71C1C")
> zCuts <-seq(-.5, 0.6, by = 0.1)
> p<-ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill = cut(cor,
> zCuts))) +
>   geom_tile() +
>   scale_fill_manual(values=cols)
>
> but for each site the scale color is different.
>
>
> Please help me to solve this problem!
>
> Thank you!
>
>
> Bests!
>
> Catalin
>
>
>
>
> --
>
> -
> -
> Catalin-Constantin ROIBU
> Lecturer PhD, Forestry engineer
> Forestry Faculty of Suceava
> Str. Universitatii no. 13, Suceava, 720229, Romania
> office phone      +4 0230 52 29 78, ext. 531
> mobile phone    +4 0745 53 18 01
> FAX:                +4 0230 52 16 64
> silvic.usv.ro <http://www.usv.ro/>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Jul  7 13:31:47 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 7 Jul 2020 14:31:47 +0300
Subject: [R] How to compare the fitting of function?
In-Reply-To: <CAMk+s2SkvBUjoT5-3zSS8M6vqWsVX4W_XRNca4Czm-ZBkS-2MQ@mail.gmail.com>
References: <CAMk+s2SkvBUjoT5-3zSS8M6vqWsVX4W_XRNca4Czm-ZBkS-2MQ@mail.gmail.com>
Message-ID: <20200707143147.1162eb40@trisector>

On Tue, 7 Jul 2020 08:57:28 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

>I would say that the function Gompertz is better than the function
>Holling type III; how can I give a number to this hunch?

There are many different goodness-of-fit measures; typically,
regression problems are solved by minimising the sums of squared
residuals, so you can just take a look at those (sum((y.predicted -
y.reference)^2)). Root-mean-square-error [*] is another widely used
metric. When comparing different methods, one should be aware of
multiple comparisons problem [**] and potential for overfitting [***].

All this and more is discussed in books on statistics and regression,
such as Regression Modeling Strategies by Frank E. Harrell, Jr.
[doi:10.1007/978-3-319-19425-7]. For more advice on statistics,
consider dedicated communities such as
<https://stats.stackexchange.com/>, since statistics advice is
considered off-topic here in R-help.

-- 
Best regards,
Ivan

[*] https://en.wikipedia.org/wiki/RMSE

[**] https://en.wikipedia.org/wiki/Multiple_testing

[***] https://en.wikipedia.org/wiki/Overfitting


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jul  7 13:35:29 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 7 Jul 2020 13:35:29 +0200
Subject: [R] How to compare the fitting of function?
In-Reply-To: <20200707143147.1162eb40@trisector>
References: <CAMk+s2SkvBUjoT5-3zSS8M6vqWsVX4W_XRNca4Czm-ZBkS-2MQ@mail.gmail.com>
 <20200707143147.1162eb40@trisector>
Message-ID: <CAMk+s2QFqx9cT6mixhw+=NHRBmDPbZyZMgd3j0SMiddLc-WAcA@mail.gmail.com>

Thank you. The problem was the implementation of the goodness-of-fit
in R (any method, really).
regards

On Tue, Jul 7, 2020 at 1:31 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Tue, 7 Jul 2020 08:57:28 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> >I would say that the function Gompertz is better than the function
> >Holling type III; how can I give a number to this hunch?
>
> There are many different goodness-of-fit measures; typically,
> regression problems are solved by minimising the sums of squared
> residuals, so you can just take a look at those (sum((y.predicted -
> y.reference)^2)). Root-mean-square-error [*] is another widely used
> metric. When comparing different methods, one should be aware of
> multiple comparisons problem [**] and potential for overfitting [***].
>
> All this and more is discussed in books on statistics and regression,
> such as Regression Modeling Strategies by Frank E. Harrell, Jr.
> [doi:10.1007/978-3-319-19425-7]. For more advice on statistics,
> consider dedicated communities such as
> <https://stats.stackexchange.com/>, since statistics advice is
> considered off-topic here in R-help.
>
> --
> Best regards,
> Ivan
>
> [*] https://en.wikipedia.org/wiki/RMSE
>
> [**] https://en.wikipedia.org/wiki/Multiple_testing
>
> [***] https://en.wikipedia.org/wiki/Overfitting



-- 
Best regards,
Luigi


From nejood96 @end|ng |rom y@hoo@com  Sun Jul  5 16:38:46 2020
From: nejood96 @end|ng |rom y@hoo@com (nejood Al-walidi)
Date: Sun, 5 Jul 2020 14:38:46 +0000 (UTC)
Subject: [R] Recommenderlab pacakge
References: <633807704.2682750.1593959926748.ref@mail.yahoo.com>
Message-ID: <633807704.2682750.1593959926748@mail.yahoo.com>

Dear all,My name is Nejood.?
I'm interested in Rstudio.?
I'm looking for using the Recommenderlab package for tracing requirements and source code.?
My problem with the dataset.?How can I prepare my dataset to use in recommenderlab package??The datasets for requirements traceability.The data sets for two artifacts in requirements traceability:Source code and requirements.?I attached two types of datasets(CSV and XML).Please, I need your help.?I didn't find any solution to my problem.?I would appreciate it if you help me as soon as.
Your's sincerely?Nejood


From jr@| @end|ng |rom po@teo@no  Tue Jul  7 18:23:38 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 7 Jul 2020 18:23:38 +0200
Subject: [R] Recommenderlab pacakge
In-Reply-To: <633807704.2682750.1593959926748@mail.yahoo.com>
References: <633807704.2682750.1593959926748.ref@mail.yahoo.com>
 <633807704.2682750.1593959926748@mail.yahoo.com>
Message-ID: <20200707162338.GA15996@posteo.no>

Dear nejood,

Please provide a miniminal reproducible 
example.

On 2020-07-05 14:38 +0000, nejood Al-walidi via R-help wrote:
| I'm looking for using the 
| Recommenderlab package for tracing 
| requirements and source code.? My 
| problem with the dataset.?How can I 
| prepare my dataset to use in 
| recommenderlab package??

The vignette[1] is usually a good 
starting point.  It is listed at the end 
of the readme[2] ...

| The datasets for requirements 
| traceability.The data sets for two 
| artifacts in requirements 
| traceability:Source code and 
| requirements.

I am not able to understand this.

| I attached two types of datasets(CSV 
| and XML).

It is not possible to send csv and xml 
files on this list, you have to put them 
somewhere else, e.g. github.

Best,
Rasmus

[1] https://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf
[2] https://github.com/mhahsler/recommenderlab/blob/master/README.md


From jr@| @end|ng |rom po@teo@no  Tue Jul  7 18:42:13 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 7 Jul 2020 18:42:13 +0200
Subject: [R] unique scale color ggplot2
In-Reply-To: <CAJuCY5wA74CMAbYt2AnLMyOTCyN2dZH0U2NLEOhokG7dRNt5QA@mail.gmail.com>
References: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>
 <CAJuCY5wA74CMAbYt2AnLMyOTCyN2dZH0U2NLEOhokG7dRNt5QA@mail.gmail.com>
Message-ID: <20200707164213.GB15996@posteo.no>

On 2020-07-07 12:44 +0200, Thierry Onkelinx via R-help wrote:
> Op di 7 jul. 2020 om 12:02 schreef Catalin Roibu <catalinroibu at gmail.com>:
> > 
> > Dear R users,
> >
> > I want to create a plot for multiple 
> > sites and to keep the same color 
> > range scale (the correlation values 
> > range from -0.5 to 0.7 for all data, 
> > but I have sites with different min 
> > and max).
> >
> > I used this code:
> > cols<-c("#0288D1", "#039BE5", "#03A9F4","#29B6F6", "#4FC3F7", "#FFCDD2",
> > "#E57373", "#F44336", "#E53935", "#D32F2F", "#C62828", "#B71C1C")
> > zCuts <-seq(-.5, 0.6, by = 0.1)
> > p<-ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill = cut(cor,
> > zCuts))) +
> >   geom_tile() +
> >   scale_fill_manual(values=cols)
> >
> > but for each site the scale color is different.
> >
> 
> Dear Catalin,
> 
> use scale_fill_gradient() and set fixed limits
> 
> ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill = cut(cor,
> zCuts))) +
>   geom_tile() +
>   scale_fill_gradient(limits = c(-0.7, 0.7))

Hmm ... what might df1 have looked like 
... creating a df with columns spei, 
month, cor, and zCuts containing 1:5 
doesn't do the trick ... 

	df1 <-
	  data.frame(
	    spei=1:5,
	    month=1:5,
	    cor=1:5,
	    zCuts=1:5
	  )
	cols <-
	  c("#0288D1", "#039BE5",
	    "#03A9F4","#29B6F6", "#4FC3F7",
	    "#FFCDD2", "#E57373", "#F44336",
	    "#E53935", "#D32F2F", "#C62828",
	    "#B71C1C")
	zCuts <- seq(-.5, 0.6, by=0.1)
	filename <- "/tmp/catalin1.png"
	width <- 800
	height <- 600
	res <- 150
	png(filename=filename, width=width, height=height, res=res)
	mapping <- ggplot2::aes(
	  x = as.factor(spei),
	  y = as.factor(month),
	  fill = cut(cor, zCuts)
	)
	p <- ggplot2::ggplot(df1, mapping=mapping) +
	   ggplot2::geom_tile() +
	   ggplot2::scale_fill_gradient(limits = c(-0.7, 0.7))
	#   ggplot2::scale_fill_manual(values=cols)
	p
	dev.off()

... which only produces the error

	Error: Discrete value supplied to continuous scale
	Execution halted

V

r


From th|erry@onke||nx @end|ng |rom |nbo@be  Tue Jul  7 19:23:44 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Tue, 7 Jul 2020 19:23:44 +0200
Subject: [R] unique scale color ggplot2
In-Reply-To: <20200707164213.GB15996@posteo.no>
References: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>
 <CAJuCY5wA74CMAbYt2AnLMyOTCyN2dZH0U2NLEOhokG7dRNt5QA@mail.gmail.com>
 <20200707164213.GB15996@posteo.no>
Message-ID: <CAJuCY5yX67A5Mra0kA8ThP4QPMLECqGby76aSTWt8BtA=JCQMw@mail.gmail.com>

Don't use the cut() function.

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op di 7 jul. 2020 om 18:42 schreef Rasmus Liland <jral at posteo.no>:

> On 2020-07-07 12:44 +0200, Thierry Onkelinx via R-help wrote:
> > Op di 7 jul. 2020 om 12:02 schreef Catalin Roibu <catalinroibu at gmail.com
> >:
> > >
> > > Dear R users,
> > >
> > > I want to create a plot for multiple
> > > sites and to keep the same color
> > > range scale (the correlation values
> > > range from -0.5 to 0.7 for all data,
> > > but I have sites with different min
> > > and max).
> > >
> > > I used this code:
> > > cols<-c("#0288D1", "#039BE5", "#03A9F4","#29B6F6", "#4FC3F7",
> "#FFCDD2",
> > > "#E57373", "#F44336", "#E53935", "#D32F2F", "#C62828", "#B71C1C")
> > > zCuts <-seq(-.5, 0.6, by = 0.1)
> > > p<-ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill =
> cut(cor,
> > > zCuts))) +
> > >   geom_tile() +
> > >   scale_fill_manual(values=cols)
> > >
> > > but for each site the scale color is different.
> > >
> >
> > Dear Catalin,
> >
> > use scale_fill_gradient() and set fixed limits
> >
> > ggplot(df1, aes(x=as.factor(spei), y=as.factor(month), fill = cut(cor,
> > zCuts))) +
> >   geom_tile() +
> >   scale_fill_gradient(limits = c(-0.7, 0.7))
>
> Hmm ... what might df1 have looked like
> ... creating a df with columns spei,
> month, cor, and zCuts containing 1:5
> doesn't do the trick ...
>
>         df1 <-
>           data.frame(
>             spei=1:5,
>             month=1:5,
>             cor=1:5,
>             zCuts=1:5
>           )
>         cols <-
>           c("#0288D1", "#039BE5",
>             "#03A9F4","#29B6F6", "#4FC3F7",
>             "#FFCDD2", "#E57373", "#F44336",
>             "#E53935", "#D32F2F", "#C62828",
>             "#B71C1C")
>         zCuts <- seq(-.5, 0.6, by=0.1)
>         filename <- "/tmp/catalin1.png"
>         width <- 800
>         height <- 600
>         res <- 150
>         png(filename=filename, width=width, height=height, res=res)
>         mapping <- ggplot2::aes(
>           x = as.factor(spei),
>           y = as.factor(month),
>           fill = cut(cor, zCuts)
>         )
>         p <- ggplot2::ggplot(df1, mapping=mapping) +
>            ggplot2::geom_tile() +
>            ggplot2::scale_fill_gradient(limits = c(-0.7, 0.7))
>         #   ggplot2::scale_fill_manual(values=cols)
>         p
>         dev.off()
>
> ... which only produces the error
>
>         Error: Discrete value supplied to continuous scale
>         Execution halted
>
> V
>
> r
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Tue Jul  7 19:43:28 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 7 Jul 2020 19:43:28 +0200
Subject: [R] unique scale color ggplot2
In-Reply-To: <CAJuCY5yX67A5Mra0kA8ThP4QPMLECqGby76aSTWt8BtA=JCQMw@mail.gmail.com>
References: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>
 <CAJuCY5wA74CMAbYt2AnLMyOTCyN2dZH0U2NLEOhokG7dRNt5QA@mail.gmail.com>
 <20200707164213.GB15996@posteo.no>
 <CAJuCY5yX67A5Mra0kA8ThP4QPMLECqGby76aSTWt8BtA=JCQMw@mail.gmail.com>
Message-ID: <20200707174328.GA19074@posteo.no>

On 2020-07-07 19:23 +0200, Thierry Onkelinx wrote:
> 
> Don't use the cut() function.

Ah, I see it now.  Changing 

	fill = cut(cor, zCuts)

to

	fill = cor

did it, probably.  Perhaps Catalin agrees.


From |vowe| @end|ng |rom gm@||@com  Wed Jul  8 06:20:39 2020
From: |vowe| @end|ng |rom gm@||@com (ivo welch)
Date: Tue, 7 Jul 2020 21:20:39 -0700
Subject: [R] parallel number of cores according to memory?
Message-ID: <CAPr7RtUd99n_VeYG0AFnBe5ZfgprgZWuW4qgdNSLvgS+9guJxQ@mail.gmail.com>

if I understand correctly, R makes a copy of the full environment for each
process.  thus, even if I have 32 processors, if I only have 64GB of RAM
and my R process holds about 10GB, I should probably not spawn 32 processes.

has anyone written a function that sets the number of cores for use (in
mclapply) to be guessed at by appropriate memory requirements (e.g.,
"amount-of-RAM"/"RAM held by R")?

(it would be even nicer if I could declare my 8GB data frame to be
read-only and to be shared among my processes, but this is presumably
technically very difficult.)

pointers appreciated.

/iaw

	[[alternative HTML version deleted]]


From m|n@to-n@k@z@w@ @end|ng |rom um|n@net  Tue Jul  7 07:57:27 2020
From: m|n@to-n@k@z@w@ @end|ng |rom um|n@net (Minato Nakazawa)
Date: Tue, 7 Jul 2020 14:57:27 +0900
Subject: [R] how to calculate odd ratios with R?
In-Reply-To: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
References: <CAMk+s2RERrPE4EnDASqpyihZDTjxcPu=gAXjFLgtrrvc1N1TAA@mail.gmail.com>
Message-ID: <20200707145727.76cd369cc2fcb2ca064d402a@umin.net>


A review (sorry in Japanese) on the calculation of odds ratios 
with confidence intervals using several packages in R is given
by Prof. Okumura, Mie Univ.

https://oku.edu.mie-u.ac.jp/~okumura/stat/2by2.html

x <- matrix(c(6, 3, 4, 5), 2)
# using vcd
library(vcd)
res <- oddsratio(x)
exp(confint(res))
summary(res)
# Note: summary(oddsratio(x, log=FALSE)) gives inappropriate p-value.
# using fmsb
library(fmsb)
oddsratio(x, p.calc.by.independence=FALSE)

Best,
Minato Nakazawa

On Mon, 6 Jul 2020 15:01:34 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Hello,
> Is it possible to calculate with a single function the odd ratios?
> Now I can use this implement:
> ```
> or <- (De/He)/(Dn/Hn) # Disease exposed, Healthy non-exposed
> logo <- log(or)
> x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
> lower_ci = exp(logo - 1.96*x)
> upper_ci = exp(logo + 1.96*x)
> cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
>     spe = "")
> ```
> for instance,
> ```
> De <-6
> Dn <-3
> He <-4
> Hn <-5
> or <- (De/He)/(Dn/Hn)
> logo <- log(or)
> x <- sqrt(((1/De) + (1/He) + (1/Dn) + (1/Hn)))
> lower_ci = exp(logo - 1.96*x)
> upper_ci = exp(logo + 1.96*x)
> cat("OR:", round(or, 3), "(", round(lower_ci, 3), "-", round(upper_ci, 3), ")",
>     spe = "")
> > OR: 2.5 ( 0.37 - 16.889 )
> ```
> Is there a simple function from some package that can also add a
> p-value to this test? Or how can I calculate the p-value on my own?
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Minato Nakazawa <minato-nakazawa at umin.net>
Professor, Division of Global Health, Department of Public Health,
Kobe University Graduate School of Health Sciences
[web] http://minato.sip21c.org/
[phone] +81-78-796-4551
[mobile e-mail] minatonakazawa at gmail.com


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jul  8 06:40:50 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 07 Jul 2020 21:40:50 -0700
Subject: [R] parallel number of cores according to memory?
In-Reply-To: <CAPr7RtUd99n_VeYG0AFnBe5ZfgprgZWuW4qgdNSLvgS+9guJxQ@mail.gmail.com>
References: <CAPr7RtUd99n_VeYG0AFnBe5ZfgprgZWuW4qgdNSLvgS+9guJxQ@mail.gmail.com>
Message-ID: <6C215610-CA71-48E6-937C-453823507823@dcn.davis.ca.us>

Use an operating system that supports forking, like Linux or MacOSX, and use the parallel package mclapply function or similar to share memory for read operations. [1]

And stop posting in HTML here.

[1] https://cran.r-project.org/web/views/HighPerformanceComputing.html

On July 7, 2020 9:20:39 PM PDT, ivo welch <ivowel at gmail.com> wrote:
>if I understand correctly, R makes a copy of the full environment for
>each
>process.  thus, even if I have 32 processors, if I only have 64GB of
>RAM
>and my R process holds about 10GB, I should probably not spawn 32
>processes.
>
>has anyone written a function that sets the number of cores for use (in
>mclapply) to be guessed at by appropriate memory requirements (e.g.,
>"amount-of-RAM"/"RAM held by R")?
>
>(it would be even nicer if I could declare my 8GB data frame to be
>read-only and to be shared among my processes, but this is presumably
>technically very difficult.)
>
>pointers appreciated.
>
>/iaw
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From |vowe| @end|ng |rom gm@||@com  Wed Jul  8 07:15:15 2020
From: |vowe| @end|ng |rom gm@||@com (ivo welch)
Date: Tue, 7 Jul 2020 22:15:15 -0700
Subject: [R] parallel number of cores according to memory?
In-Reply-To: <6C215610-CA71-48E6-937C-453823507823@dcn.davis.ca.us>
References: <CAPr7RtUd99n_VeYG0AFnBe5ZfgprgZWuW4qgdNSLvgS+9guJxQ@mail.gmail.com>
 <6C215610-CA71-48E6-937C-453823507823@dcn.davis.ca.us>
Message-ID: <CAPr7RtVAN_U-uY0jdNQL=HU_T6u5fNo0Ke62w+7mCWW5y56wyQ@mail.gmail.com>

ugghhh---apologies.  although in 2020, it would be nice if the mailing
list had an automatic html filter (or even bouncer!)

I am using macos.  alas, my experiments suggest that `mclapply()` on a
32-core intel system with 64GB of RAM, where the input data frame is
8GB and the output is about 500MB per core (to be stitched together
into about 16GB), the system starts swapping like crazy, comes to a
halt, and then usually crashes.

/iaw


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jul  8 07:22:40 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 07 Jul 2020 22:22:40 -0700
Subject: [R] parallel number of cores according to memory?
In-Reply-To: <CAPr7RtVAN_U-uY0jdNQL=HU_T6u5fNo0Ke62w+7mCWW5y56wyQ@mail.gmail.com>
References: <CAPr7RtUd99n_VeYG0AFnBe5ZfgprgZWuW4qgdNSLvgS+9guJxQ@mail.gmail.com>
 <6C215610-CA71-48E6-937C-453823507823@dcn.davis.ca.us>
 <CAPr7RtVAN_U-uY0jdNQL=HU_T6u5fNo0Ke62w+7mCWW5y56wyQ@mail.gmail.com>
Message-ID: <327B80A5-C624-423E-B1A5-F07015B1E796@dcn.davis.ca.us>

The list does strip html, but the quality of what remains varies greatly.

Are you using tidyverse functions in your workers? Sounds to me like you are doing something in the workers that is triggering making copies of the input data frame.

On July 7, 2020 10:15:15 PM PDT, ivo welch <ivowel at gmail.com> wrote:
>ugghhh---apologies.  although in 2020, it would be nice if the mailing
>list had an automatic html filter (or even bouncer!)
>
>I am using macos.  alas, my experiments suggest that `mclapply()` on a
>32-core intel system with 64GB of RAM, where the input data frame is
>8GB and the output is about 500MB per core (to be stitched together
>into about 16GB), the system starts swapping like crazy, comes to a
>halt, and then usually crashes.
>
>/iaw

-- 
Sent from my phone. Please excuse my brevity.


From |vo@we|ch @end|ng |rom uc|@@edu  Wed Jul  8 08:12:47 2020
From: |vo@we|ch @end|ng |rom uc|@@edu (ivo welch)
Date: Tue, 7 Jul 2020 23:12:47 -0700
Subject: [R] parallel number of cores according to memory?
In-Reply-To: <327B80A5-C624-423E-B1A5-F07015B1E796@dcn.davis.ca.us>
References: <CAPr7RtUd99n_VeYG0AFnBe5ZfgprgZWuW4qgdNSLvgS+9guJxQ@mail.gmail.com>
 <6C215610-CA71-48E6-937C-453823507823@dcn.davis.ca.us>
 <CAPr7RtVAN_U-uY0jdNQL=HU_T6u5fNo0Ke62w+7mCWW5y56wyQ@mail.gmail.com>
 <327B80A5-C624-423E-B1A5-F07015B1E796@dcn.davis.ca.us>
Message-ID: <CAJrNScTF73EMyPSNg5m1bkaNfVkR5wEx31Tyk7nYqrU7ykm1Rg@mail.gmail.com>

no, I'm not.   mostly conventional use afaik.  if this should not be
happening, I can trace it down to a small reproducible example to
figure it out.

--
Ivo Welch (ivo.welch at ucla.edu)

--
Ivo Welch (ivo.welch at ucla.edu)
http://www.ivo-welch.info/
J. Fred Weston Distinguished Professor of Finance, UCLA Anderson



On Tue, Jul 7, 2020 at 10:24 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> The list does strip html, but the quality of what remains varies greatly.
>
> Are you using tidyverse functions in your workers? Sounds to me like you are doing something in the workers that is triggering making copies of the input data frame.
>
> On July 7, 2020 10:15:15 PM PDT, ivo welch <ivowel at gmail.com> wrote:
> >ugghhh---apologies.  although in 2020, it would be nice if the mailing
> >list had an automatic html filter (or even bouncer!)
> >
> >I am using macos.  alas, my experiments suggest that `mclapply()` on a
> >32-core intel system with 64GB of RAM, where the input data frame is
> >8GB and the output is about 500MB per core (to be stitched together
> >into about 16GB), the system starts swapping like crazy, comes to a
> >halt, and then usually crashes.
> >
> >/iaw
>
> --
> Sent from my phone. Please excuse my brevity.


From chr|@@prener @end|ng |rom @|u@edu  Wed Jul  8 02:15:32 2020
From: chr|@@prener @end|ng |rom @|u@edu (Chris Prener)
Date: Wed, 8 Jul 2020 00:15:32 +0000
Subject: [R] useR! Live Events Underway!
Message-ID: <469F2023-0901-461D-8DED-DBDC249FCB84@slu.edu>

Hi all,
Our first breakout session for useR! 2020 was today, and our welcome session begins tomorrow followed by Martin M?chler and Luke Tierney?s keynotes and our panel of R Core contributors. The Slido site for Q and A<https://app.sli.do/event/ccilmxcz/live/questions> is already open. If you have questions about R Core, where R is headed, or questions for Martin and Luke, please post them there! Then, head back there for the livestream tomorrow. A full list of our live events is available here<https://user2020.r-project.org/program/agenda/>. Our site also includes links to posters and videos, and will include tutorial information as soon as it is available.

We look forward to seeing you all at our events this week!

Best,
Chris Prener, Heidi Seibold, and Jenine Harris
user! 2020 Co-Leads


	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

From c@t@||nro|bu @end|ng |rom gm@||@com  Wed Jul  8 13:37:42 2020
From: c@t@||nro|bu @end|ng |rom gm@||@com (Catalin Roibu)
Date: Wed, 8 Jul 2020 14:37:42 +0300
Subject: [R] unique scale color ggplot2
In-Reply-To: <20200707174328.GA19074@posteo.no>
References: <CAEW+BDJXxGLxBKd=OWtW4xmAfnWaFx4ggfufnvcELbEbJvJL-w@mail.gmail.com>
 <CAJuCY5wA74CMAbYt2AnLMyOTCyN2dZH0U2NLEOhokG7dRNt5QA@mail.gmail.com>
 <20200707164213.GB15996@posteo.no>
 <CAJuCY5yX67A5Mra0kA8ThP4QPMLECqGby76aSTWt8BtA=JCQMw@mail.gmail.com>
 <20200707174328.GA19074@posteo.no>
Message-ID: <CAEW+BDKRQa5hFxMwmT4ot8jdgyN3Cr2T4=dL7rdKWzLR6uAXTA@mail.gmail.com>

Dear all,

Thank you for your email and help. I solved the problem!

All the best!

Catalin

On Tue, 7 Jul 2020 at 20:43, Rasmus Liland <jral at posteo.no> wrote:

> On 2020-07-07 19:23 +0200, Thierry Onkelinx wrote:
> >
> > Don't use the cut() function.
>
> Ah, I see it now.  Changing
>
>         fill = cut(cor, zCuts)
>
> to
>
>         fill = cor
>
> did it, probably.  Perhaps Catalin agrees.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 

-
-
Catalin-Constantin ROIBU
?
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Wed Jul  8 17:19:14 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Wed, 8 Jul 2020 08:19:14 -0700
Subject: [R] National Weather Service Data
In-Reply-To: <A5E1093B-0129-4892-A5DD-02768971D970@noaa.gov>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
 <28C66B99-9B31-45E1-BEB0-AF88E81D4C67@noaa.gov>
 <197A5AE5DF294658913B204791ECF6AF@OWNERPC>
 <A5E1093B-0129-4892-A5DD-02768971D970@noaa.gov>
Message-ID: <0CB660599A55486686F8E86AE58420C4@OWNERPC>

Thanks again for confirming that the wgrib2 software loaded correctly.  I 
have been making good progress finding variables related to low level winds 
such as the HGT series that, as you know, converts millibars to altitude 
MSL.

The next step is to look at Rapid Refresh (RAP).  Can you direct me to 
someplace that has the names of the forecast models - equivalent to gfs_0p50 
for the Global Forecast System?

Thanks.

-----Original Message----- 
From: Roy Mendelssohn - NOAA Federal
Sent: Monday, July 6, 2020 6:35 PM
To: Philip
Subject: Re: [R] National Weather Service Data

Skimming the docs seems to assume a lot of knowledge of the data.  The best 
I can see there are two temperature variables:

> tmpsfc (surface air temperature, K)
> tmp2m (air temperature at 2m, K)

and one relative humidity:

> rh2m (relative humidity at 2m, %)

Depending on what you are after,  you might find it easier to use the UAF 
ERDDAP server (https://upwell.pfeg.noaa.gov/erddap/griddap/ncep_global.html) 
and 'rerddap' to get the data.  'rerddap' will read in the data into a nice 
tibble,  I also think the documentation is clearer with some nice vignettes 
and the ability to get info about the data.  For example the command

> rerddap::info('ncep_global')

returns:


> <ERDDAP info> ncep_global
>  Base URL: https://upwell.pfeg.noaa.gov/erddap/
>  Dimensions (range):
>      time: (2011-05-06T12:00:00Z, 2020-07-08T12:00:00Z)
>      latitude: (-90.0, 90.0)
>      longitude: (0.0, 359.5)
>  Variables:
>      dlwrfsfc:
>          Units: W m-2
>      dswrfsfc:
>          Units: W m-2
>      pratesfc:
>          Units: kg m-2 s-1
>      prmslmsl:
>          Units: Pa
>      rh2m:
>          Units: %
>      tmp2m:
>          Units: K
>      tmpsfc:
>          Units: K
>      ugrd10m:
>          Units: m s-1
>      vgrd10m:
>          Units: m s-1

which would have answered a lot of your questions.  If you had saved that 
command to a variable  there would be a lot more information,  that is just 
the summary.

HTH,

-Roy

>
> On Jul 6, 2020, at 5:47 PM, Philip <herd_dog at cox.net> wrote:
>
> Thanks for getting back to me.  It is good to know that I am on the right 
> track.
>
> I understand now that the output byte location of the data in the grib2 
> file not the actual data which in this case would be the 2 am forecast six 
> hours into the future.  Can you advise me which of the examples in Dr. 
> Bowman's rNOMADS documentation will get me the tem[perature and relative 
> humidity data?
>
> Philip.
>
> -----Original Message----- From: Roy Mendelssohn - NOAA Federal
> Sent: Monday, July 6, 2020 10:43 AM
> To: Philip
> Cc: stephen sefick ; r-help
> Subject: Re: [R] National Weather Service Data
>
> Hi Philip:
>
> Results look correct to me.  This might help you:
>
> https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/default_inv.html
>
> -Roy
>
>
>> On Jul 6, 2020, at 9:29 AM, Philip <herd_dog at cox.net> wrote:
>>
>> I am trying to access National Weather Service forecasting data through 
>> the rNOMADS package.  I?m not sure if the Weather Service software ? 
>> grib2 ? loaded correctly.  Second, some of the examples in the rNOMADS 
>> documentation seem to run correctly but I?m not sure what the output 
>> means.  Any anvise would be greatly appreciated.
>>
>> 1 - I tried to load the wgrib2 software from instructions in the 
>> following website:
>>
>> https://bovineaerospace.wordpress.com/2015/04/26/how-to-install-rnomads-with-grib-file-support-on-windows/
>>
>> 2 ? the instructions say that if it loaded correctly I should get a 
>> laundry list similar to what is below from the command: 
>>  >system(?wgrib2?).
>>
>>
>>
>> The list I get looks different.  Below is the first 20 or so entries. 
>> How can I check to see if the wgrib2 loaded correctly?
>>
>> wgrib2 v0.1.9.9 9/2013 Wesley Ebisuzaki, Reinoud Bokhorst, Jaakko 
>> Hyv??tti, Dusan Jovic, Kristian Nilssen, Karl Pfeiffer, Pablo Romero, 
>> Manfred Schwarb, Arlindo da Silva, Niklas Sondell, Sergey Varlamov
>> -0xSec           inv  X      Hex dump of section X (0..8)
>> -MM              inv         reference time MM
>> -N_ens           inv         number of ensemble members
>> -RT              inv         type of reference Time
>> -S               inv         simple inventory with minutes and seconds 
>> (subject to change)
>> -Sec0            inv         contents of section0
>> -Sec3            inv         contents of section 3 (Grid Definition 
>> Section)
>> -Sec4            inv         Sec 4 values (Product definition section)
>> -Sec5            inv         Sec 5 values (Data representation section)
>> -Sec6            inv         show bit-map section
>> -Sec_len         inv         length of various grib sections
>> -T               inv         reference time YYYYMMDDHHMMSS
>> -V               inv         diagnostic output
>> -VT              inv         verf time = reference_time + forecast_time 
>> (YYYYMMDDHHMMSS)
>> -YY              inv         reference time YYYY
>>
>> 3 ? As I said, some of the documentation examples work and for some I get 
>> error messages.  Below is an example of one that seemed to work but I don?t 
>> understand the output.
>>
>> #GribInfo - page 20
>> urlsOut <- CrawlModels(abbrev="gfs_0p50",depth=2)
>> ModelParameters <- ParseModelPage(urlsOut[2])#[1] is most recent model
>> MyPred <- ModelParameters$pred[grep("06$",ModelParameters$pred)]
>>  Levels <- c("2_m_above_ground","800_mb")
>>  Variables <- c("TMP","RH")
>>  GribInfo <- GribGrab(urlsOut[2],MyPred,Levels,Variables)
>> GribInv <- GribInfo(GribInfo[[1]]$file.name,"grib2")
>>
>> The command GribInv$inventory returns:
>>
>> $inventory
>> [1] "1:0:d=2020070606:TMP:800 mb:6 hour fcst:" 
>> "2:148450:d=2020070606:RH:800 mb:6 hour fcst:"
>> [3] "3:414132:d=2020070606:TMP:2 m above ground:6 hour fcst:" 
>> "4:571266:d=2020070606:RH:2 m above ground:6 hour fcst:"
>>
>> This is supposed to be temperature and relative humidity 2 meters above 
>> the ground and at 800 milibars for 2020 ? July 6 ? at ZULU time 0600. 
>> But I have no idea what the numbers 414132 ? second line ? mean.
>>
>> Any advise would be greatly appreciated.
>>
>> Philip Heinrich
>>
>> From: stephen sefick
>> Sent: Thursday, July 2, 2020 3:20 PM
>> To: Philip
>> Cc: r-help
>> Subject: Re: [R] National Weather Service Data
>>
>> I am unfamiliar with Rnomads. Could you provide a minimal reproducable 
>> example? You are more likely to receive help this way.
>>
>>
>> On Thu, Jul 2, 2020, 18:06 Philip <herd_dog at cox.net> wrote:
>>
>> Is anyone out there familiar with rNOMADS?  It is a package to get into 
>> National Weather Service forecasting data with R?
>>
>> I'm not sure the Weather Service software named wgrib2 loaded correctly 
>> because some of the stuff won't run and I can't make much sense out of 
>> some of the output.
>>
>> Thanks.
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S. 
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK 
> Jr.
>

**********************
"The contents of this message do not reflect any position of the U.S. 
Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected"
"the arc of the moral universe is long, but it bends toward justice" -MLK 
Jr.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Wed Jul  8 18:43:34 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Wed, 8 Jul 2020 09:43:34 -0700
Subject: [R] National Weather Service Data
In-Reply-To: <0CB660599A55486686F8E86AE58420C4@OWNERPC>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
 <28C66B99-9B31-45E1-BEB0-AF88E81D4C67@noaa.gov>
 <197A5AE5DF294658913B204791ECF6AF@OWNERPC>
 <A5E1093B-0129-4892-A5DD-02768971D970@noaa.gov>
 <0CB660599A55486686F8E86AE58420C4@OWNERPC>
Message-ID: <729266C1-8117-4A81-BD85-FB64B5703BEA@noaa.gov>

I would suggest looking at the NOMADS page for information on what is available through NOMADS:

https://nomads.ncep.noaa.gov

-Roy


> On Jul 8, 2020, at 8:19 AM, Philip <herd_dog at cox.net> wrote:
> 
> Thanks again for confirming that the wgrib2 software loaded correctly.  I have been making good progress finding variables related to low level winds such as the HGT series that, as you know, converts millibars to altitude MSL.
> 
> The next step is to look at Rapid Refresh (RAP).  Can you direct me to someplace that has the names of the forecast models - equivalent to gfs_0p50 for the Global Forecast System?
> 
> Thanks.
> 
> -----Original Message----- From: Roy Mendelssohn - NOAA Federal
> Sent: Monday, July 6, 2020 6:35 PM
> To: Philip
> Subject: Re: [R] National Weather Service Data
> 
> Skimming the docs seems to assume a lot of knowledge of the data.  The best I can see there are two temperature variables:
> 
>> tmpsfc (surface air temperature, K)
>> tmp2m (air temperature at 2m, K)
> 
> and one relative humidity:
> 
>> rh2m (relative humidity at 2m, %)
> 
> Depending on what you are after,  you might find it easier to use the UAF ERDDAP server (https://upwell.pfeg.noaa.gov/erddap/griddap/ncep_global.html) and 'rerddap' to get the data.  'rerddap' will read in the data into a nice tibble,  I also think the documentation is clearer with some nice vignettes and the ability to get info about the data.  For example the command
> 
>> rerddap::info('ncep_global')
> 
> returns:
> 
> 
>> <ERDDAP info> ncep_global
>> Base URL: https://upwell.pfeg.noaa.gov/erddap/
>> Dimensions (range):
>>     time: (2011-05-06T12:00:00Z, 2020-07-08T12:00:00Z)
>>     latitude: (-90.0, 90.0)
>>     longitude: (0.0, 359.5)
>> Variables:
>>     dlwrfsfc:
>>         Units: W m-2
>>     dswrfsfc:
>>         Units: W m-2
>>     pratesfc:
>>         Units: kg m-2 s-1
>>     prmslmsl:
>>         Units: Pa
>>     rh2m:
>>         Units: %
>>     tmp2m:
>>         Units: K
>>     tmpsfc:
>>         Units: K
>>     ugrd10m:
>>         Units: m s-1
>>     vgrd10m:
>>         Units: m s-1
> 
> which would have answered a lot of your questions.  If you had saved that command to a variable  there would be a lot more information,  that is just the summary.
> 
> HTH,
> 
> -Roy
> 
>> 
>> On Jul 6, 2020, at 5:47 PM, Philip <herd_dog at cox.net> wrote:
>> 
>> Thanks for getting back to me.  It is good to know that I am on the right track.
>> 
>> I understand now that the output byte location of the data in the grib2 file not the actual data which in this case would be the 2 am forecast six hours into the future.  Can you advise me which of the examples in Dr. Bowman's rNOMADS documentation will get me the tem[perature and relative humidity data?
>> 
>> Philip.
>> 
>> -----Original Message----- From: Roy Mendelssohn - NOAA Federal
>> Sent: Monday, July 6, 2020 10:43 AM
>> To: Philip
>> Cc: stephen sefick ; r-help
>> Subject: Re: [R] National Weather Service Data
>> 
>> Hi Philip:
>> 
>> Results look correct to me.  This might help you:
>> 
>> https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/default_inv.html
>> 
>> -Roy
>> 
>> 
>>> On Jul 6, 2020, at 9:29 AM, Philip <herd_dog at cox.net> wrote:
>>> 
>>> I am trying to access National Weather Service forecasting data through the rNOMADS package.  I?m not sure if the Weather Service software ? grib2 ? loaded correctly.  Second, some of the examples in the rNOMADS documentation seem to run correctly but I?m not sure what the output means.  Any anvise would be greatly appreciated.
>>> 
>>> 1 - I tried to load the wgrib2 software from instructions in the following website:
>>> 
>>> https://bovineaerospace.wordpress.com/2015/04/26/how-to-install-rnomads-with-grib-file-support-on-windows/
>>> 
>>> 2 ? the instructions say that if it loaded correctly I should get a laundry list similar to what is below from the command:  >system(?wgrib2?).
>>> 
>>> 
>>> 
>>> The list I get looks different.  Below is the first 20 or so entries. How can I check to see if the wgrib2 loaded correctly?
>>> 
>>> wgrib2 v0.1.9.9 9/2013 Wesley Ebisuzaki, Reinoud Bokhorst, Jaakko Hyv??tti, Dusan Jovic, Kristian Nilssen, Karl Pfeiffer, Pablo Romero, Manfred Schwarb, Arlindo da Silva, Niklas Sondell, Sergey Varlamov
>>> -0xSec           inv  X      Hex dump of section X (0..8)
>>> -MM              inv         reference time MM
>>> -N_ens           inv         number of ensemble members
>>> -RT              inv         type of reference Time
>>> -S               inv         simple inventory with minutes and seconds (subject to change)
>>> -Sec0            inv         contents of section0
>>> -Sec3            inv         contents of section 3 (Grid Definition Section)
>>> -Sec4            inv         Sec 4 values (Product definition section)
>>> -Sec5            inv         Sec 5 values (Data representation section)
>>> -Sec6            inv         show bit-map section
>>> -Sec_len         inv         length of various grib sections
>>> -T               inv         reference time YYYYMMDDHHMMSS
>>> -V               inv         diagnostic output
>>> -VT              inv         verf time = reference_time + forecast_time (YYYYMMDDHHMMSS)
>>> -YY              inv         reference time YYYY
>>> 
>>> 3 ? As I said, some of the documentation examples work and for some I get error messages.  Below is an example of one that seemed to work but I don?t understand the output.
>>> 
>>> #GribInfo - page 20
>>> urlsOut <- CrawlModels(abbrev="gfs_0p50",depth=2)
>>> ModelParameters <- ParseModelPage(urlsOut[2])#[1] is most recent model
>>> MyPred <- ModelParameters$pred[grep("06$",ModelParameters$pred)]
>>> Levels <- c("2_m_above_ground","800_mb")
>>> Variables <- c("TMP","RH")
>>> GribInfo <- GribGrab(urlsOut[2],MyPred,Levels,Variables)
>>> GribInv <- GribInfo(GribInfo[[1]]$file.name,"grib2")
>>> 
>>> The command GribInv$inventory returns:
>>> 
>>> $inventory
>>> [1] "1:0:d=2020070606:TMP:800 mb:6 hour fcst:" "2:148450:d=2020070606:RH:800 mb:6 hour fcst:"
>>> [3] "3:414132:d=2020070606:TMP:2 m above ground:6 hour fcst:" "4:571266:d=2020070606:RH:2 m above ground:6 hour fcst:"
>>> 
>>> This is supposed to be temperature and relative humidity 2 meters above the ground and at 800 milibars for 2020 ? July 6 ? at ZULU time 0600. But I have no idea what the numbers 414132 ? second line ? mean.
>>> 
>>> Any advise would be greatly appreciated.
>>> 
>>> Philip Heinrich
>>> 
>>> From: stephen sefick
>>> Sent: Thursday, July 2, 2020 3:20 PM
>>> To: Philip
>>> Cc: r-help
>>> Subject: Re: [R] National Weather Service Data
>>> 
>>> I am unfamiliar with Rnomads. Could you provide a minimal reproducable example? You are more likely to receive help this way.
>>> 
>>> 
>>> On Thu, Jul 2, 2020, 18:06 Philip <herd_dog at cox.net> wrote:
>>> 
>>> Is anyone out there familiar with rNOMADS?  It is a package to get into National Weather Service forecasting data with R?
>>> 
>>> I'm not sure the Weather Service software named wgrib2 loaded correctly because some of the stuff won't run and I can't make much sense out of some of the output.
>>> 
>>> Thanks.
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>> 
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From herd_dog @end|ng |rom cox@net  Wed Jul  8 19:37:00 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Wed, 8 Jul 2020 10:37:00 -0700
Subject: [R] National Weather Service Data
In-Reply-To: <729266C1-8117-4A81-BD85-FB64B5703BEA@noaa.gov>
References: <086B46A8D1A2497AA82D27A3F131DE9B@OWNERPC>
 <CADKEMqjk+fXk_pv3UZHXGy7HTRES-VYZ0jk=GgUXYmLewJQh4w@mail.gmail.com>
 <D6E95147B1F747F6A2DB2A9E3FC78519@OWNERPC>
 <28C66B99-9B31-45E1-BEB0-AF88E81D4C67@noaa.gov>
 <197A5AE5DF294658913B204791ECF6AF@OWNERPC>
 <A5E1093B-0129-4892-A5DD-02768971D970@noaa.gov>
 <0CB660599A55486686F8E86AE58420C4@OWNERPC>
 <729266C1-8117-4A81-BD85-FB64B5703BEA@noaa.gov>
Message-ID: <4CE2A142DDAC421E9428BB458F9C47A7@OWNERPC>

Thanks.

Found the url's, names, and abbreviations on Daniel Bowman's rNOMADS package 
for R - NOMADS Real time List.

Thanks.

-----Original Message----- 
From: Roy Mendelssohn - NOAA Federal
Sent: Wednesday, July 8, 2020 9:43 AM
To: Philip
Cc: r-help
Subject: Re: [R] National Weather Service Data

I would suggest looking at the NOMADS page for information on what is 
available through NOMADS:

https://nomads.ncep.noaa.gov

-Roy


> On Jul 8, 2020, at 8:19 AM, Philip <herd_dog at cox.net> wrote:
>
> Thanks again for confirming that the wgrib2 software loaded correctly.  I 
> have been making good progress finding variables related to low level 
> winds such as the HGT series that, as you know, converts millibars to 
> altitude MSL.
>
> The next step is to look at Rapid Refresh (RAP).  Can you direct me to 
> someplace that has the names of the forecast models - equivalent to 
> gfs_0p50 for the Global Forecast System?
>
> Thanks.
>
> -----Original Message----- From: Roy Mendelssohn - NOAA Federal
> Sent: Monday, July 6, 2020 6:35 PM
> To: Philip
> Subject: Re: [R] National Weather Service Data
>
> Skimming the docs seems to assume a lot of knowledge of the data.  The 
> best I can see there are two temperature variables:
>
>> tmpsfc (surface air temperature, K)
>> tmp2m (air temperature at 2m, K)
>
> and one relative humidity:
>
>> rh2m (relative humidity at 2m, %)
>
> Depending on what you are after,  you might find it easier to use the UAF 
> ERDDAP server 
> (https://upwell.pfeg.noaa.gov/erddap/griddap/ncep_global.html) and 
> 'rerddap' to get the data.  'rerddap' will read in the data into a nice 
> tibble,  I also think the documentation is clearer with some nice 
> vignettes and the ability to get info about the data.  For example the 
> command
>
>> rerddap::info('ncep_global')
>
> returns:
>
>
>> <ERDDAP info> ncep_global
>> Base URL: https://upwell.pfeg.noaa.gov/erddap/
>> Dimensions (range):
>>     time: (2011-05-06T12:00:00Z, 2020-07-08T12:00:00Z)
>>     latitude: (-90.0, 90.0)
>>     longitude: (0.0, 359.5)
>> Variables:
>>     dlwrfsfc:
>>         Units: W m-2
>>     dswrfsfc:
>>         Units: W m-2
>>     pratesfc:
>>         Units: kg m-2 s-1
>>     prmslmsl:
>>         Units: Pa
>>     rh2m:
>>         Units: %
>>     tmp2m:
>>         Units: K
>>     tmpsfc:
>>         Units: K
>>     ugrd10m:
>>         Units: m s-1
>>     vgrd10m:
>>         Units: m s-1
>
> which would have answered a lot of your questions.  If you had saved that 
> command to a variable  there would be a lot more information,  that is 
> just the summary.
>
> HTH,
>
> -Roy
>
>>
>> On Jul 6, 2020, at 5:47 PM, Philip <herd_dog at cox.net> wrote:
>>
>> Thanks for getting back to me.  It is good to know that I am on the right 
>> track.
>>
>> I understand now that the output byte location of the data in the grib2 
>> file not the actual data which in this case would be the 2 am forecast 
>> six hours into the future.  Can you advise me which of the examples in 
>> Dr. Bowman's rNOMADS documentation will get me the tem[perature and 
>> relative humidity data?
>>
>> Philip.
>>
>> -----Original Message----- From: Roy Mendelssohn - NOAA Federal
>> Sent: Monday, July 6, 2020 10:43 AM
>> To: Philip
>> Cc: stephen sefick ; r-help
>> Subject: Re: [R] National Weather Service Data
>>
>> Hi Philip:
>>
>> Results look correct to me.  This might help you:
>>
>> https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/default_inv.html
>>
>> -Roy
>>
>>
>>> On Jul 6, 2020, at 9:29 AM, Philip <herd_dog at cox.net> wrote:
>>>
>>> I am trying to access National Weather Service forecasting data through 
>>> the rNOMADS package.  I?m not sure if the Weather Service software ? 
>>> grib2 ? loaded correctly.  Second, some of the examples in the rNOMADS 
>>> documentation seem to run correctly but I?m not sure what the output 
>>> means.  Any anvise would be greatly appreciated.
>>>
>>> 1 - I tried to load the wgrib2 software from instructions in the 
>>> following website:
>>>
>>> https://bovineaerospace.wordpress.com/2015/04/26/how-to-install-rnomads-with-grib-file-support-on-windows/
>>>
>>> 2 ? the instructions say that if it loaded correctly I should get a 
>>> laundry list similar to what is below from the command: 
>>>   >system(?wgrib2?).
>>>
>>>
>>>
>>> The list I get looks different.  Below is the first 20 or so entries. 
>>> How can I check to see if the wgrib2 loaded correctly?
>>>
>>> wgrib2 v0.1.9.9 9/2013 Wesley Ebisuzaki, Reinoud Bokhorst, Jaakko 
>>> Hyv??tti, Dusan Jovic, Kristian Nilssen, Karl Pfeiffer, Pablo Romero, 
>>> Manfred Schwarb, Arlindo da Silva, Niklas Sondell, Sergey Varlamov
>>> -0xSec           inv  X      Hex dump of section X (0..8)
>>> -MM              inv         reference time MM
>>> -N_ens           inv         number of ensemble members
>>> -RT              inv         type of reference Time
>>> -S               inv         simple inventory with minutes and seconds 
>>> (subject to change)
>>> -Sec0            inv         contents of section0
>>> -Sec3            inv         contents of section 3 (Grid Definition 
>>> Section)
>>> -Sec4            inv         Sec 4 values (Product definition section)
>>> -Sec5            inv         Sec 5 values (Data representation section)
>>> -Sec6            inv         show bit-map section
>>> -Sec_len         inv         length of various grib sections
>>> -T               inv         reference time YYYYMMDDHHMMSS
>>> -V               inv         diagnostic output
>>> -VT              inv         verf time = reference_time + forecast_time 
>>> (YYYYMMDDHHMMSS)
>>> -YY              inv         reference time YYYY
>>>
>>> 3 ? As I said, some of the documentation examples work and for some I 
>>> get error messages.  Below is an example of one that seemed to work but 
>>> I don?t understand the output.
>>>
>>> #GribInfo - page 20
>>> urlsOut <- CrawlModels(abbrev="gfs_0p50",depth=2)
>>> ModelParameters <- ParseModelPage(urlsOut[2])#[1] is most recent model
>>> MyPred <- ModelParameters$pred[grep("06$",ModelParameters$pred)]
>>> Levels <- c("2_m_above_ground","800_mb")
>>> Variables <- c("TMP","RH")
>>> GribInfo <- GribGrab(urlsOut[2],MyPred,Levels,Variables)
>>> GribInv <- GribInfo(GribInfo[[1]]$file.name,"grib2")
>>>
>>> The command GribInv$inventory returns:
>>>
>>> $inventory
>>> [1] "1:0:d=2020070606:TMP:800 mb:6 hour fcst:" 
>>> "2:148450:d=2020070606:RH:800 mb:6 hour fcst:"
>>> [3] "3:414132:d=2020070606:TMP:2 m above ground:6 hour fcst:" 
>>> "4:571266:d=2020070606:RH:2 m above ground:6 hour fcst:"
>>>
>>> This is supposed to be temperature and relative humidity 2 meters above 
>>> the ground and at 800 milibars for 2020 ? July 6 ? at ZULU time 0600. 
>>> But I have no idea what the numbers 414132 ? second line ? mean.
>>>
>>> Any advise would be greatly appreciated.
>>>
>>> Philip Heinrich
>>>
>>> From: stephen sefick
>>> Sent: Thursday, July 2, 2020 3:20 PM
>>> To: Philip
>>> Cc: r-help
>>> Subject: Re: [R] National Weather Service Data
>>>
>>> I am unfamiliar with Rnomads. Could you provide a minimal reproducable 
>>> example? You are more likely to receive help this way.
>>>
>>>
>>> On Thu, Jul 2, 2020, 18:06 Philip <herd_dog at cox.net> wrote:
>>>
>>> Is anyone out there familiar with rNOMADS?  It is a package to get into 
>>> National Weather Service forecasting data with R?
>>>
>>> I'm not sure the Weather Service software named wgrib2 loaded correctly 
>>> because some of the stuff won't run and I can't make much sense out of 
>>> some of the output.
>>>
>>> Thanks.
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. 
>> Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected"
>> "the arc of the moral universe is long, but it bends toward justice" -MLK 
>> Jr.
>>
>
> **********************
> "The contents of this message do not reflect any position of the U.S. 
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK 
> Jr.
>

**********************
"The contents of this message do not reflect any position of the U.S. 
Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected"
"the arc of the moral universe is long, but it bends toward justice" -MLK 
Jr.


From o@@m@78he|ny @end|ng |rom gm@||@com  Wed Jul  8 10:04:16 2020
From: o@@m@78he|ny @end|ng |rom gm@||@com (Osama Mostafa)
Date: Wed, 8 Jul 2020 10:04:16 +0200
Subject: [R] Estimate garch model by GMM
Message-ID: <CAFeRt_evH=bUuojkgjt=pEJm5a-2GEdqQ-r7AgdeVz-_BENs9w@mail.gmail.com>

Dear Professors



Hope this e-mail find you well. I am currently doing my Masters in
statistics and econometrics and my thesis is about the Properties and
Estimation of Garch Models and their applications I need to know if it is
to possible to estimate Garch model by Generalized Method of Moments
<http://cameron.econ.ucdavis.edu/mmabook/transparencies/ct06_gmm.pdf>

 (GMM) method using R . and If it possible I need a example of it by coding



My sincere regards,

ossama

	[[alternative HTML version deleted]]


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Wed Jul  8 20:31:10 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Wed, 8 Jul 2020 20:31:10 +0200
Subject: [R] output from R to simple html
Message-ID: <"H000007100174024.1594233070.sx.f1-outsourcing.eu*"@MHS>



I would like to parse some input to an R script and use its result 
output (maybe in json) on a web page. I think this shiny framework is a 
bit over kill. What is the simplest to implement this? 


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul  8 21:56:36 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Jul 2020 12:56:36 -0700
Subject: [R] output from R to simple html
In-Reply-To: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
References: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
Message-ID: <CAGxFJbT+P4UOtMwhuJD4VB5WmHJbOB4AOuPJL3jcdkb_+w0rfQ@mail.gmail.com>

This might be helpful:

https://cran.r-project.org/web/views/WebTechnologies.html

Cheers,
Bert

On Wed, Jul 8, 2020 at 12:02 PM Marc Roos <M.Roos at f1-outsourcing.eu> wrote:

>
>
> I would like to parse some input to an R script and use its result
> output (maybe in json) on a web page. I think this shiny framework is a
> bit over kill. What is the simplest to implement this?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Jul  8 22:00:04 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 8 Jul 2020 16:00:04 -0400
Subject: [R] Estimate garch model by GMM
In-Reply-To: <CAFeRt_evH=bUuojkgjt=pEJm5a-2GEdqQ-r7AgdeVz-_BENs9w@mail.gmail.com>
References: <CAFeRt_evH=bUuojkgjt=pEJm5a-2GEdqQ-r7AgdeVz-_BENs9w@mail.gmail.com>
Message-ID: <CAM_vjuksrFk0Z95ChEL43eP2EwtvmYeWb+JNnZpRG_EaAQDVow@mail.gmail.com>

Hi,

The very useful search engine rseek.org lists a lot of packages,
functions, and tutorials for Garch modeling in R. Perhaps some of
those meet your requirements.

Sarah

On Wed, Jul 8, 2020 at 3:02 PM Osama Mostafa <osama78hefny at gmail.com> wrote:
>
> Dear Professors
>
>
>
> Hope this e-mail find you well. I am currently doing my Masters in
> statistics and econometrics and my thesis is about the Properties and
> Estimation of Garch Models and their applications I need to know if it is
> to possible to estimate Garch model by Generalized Method of Moments
> <http://cameron.econ.ucdavis.edu/mmabook/transparencies/ct06_gmm.pdf>
>
>  (GMM) method using R . and If it possible I need a example of it by coding
>
>
>
> My sincere regards,
>
> ossama
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jul  8 22:06:59 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 8 Jul 2020 13:06:59 -0700
Subject: [R] Estimate garch model by GMM
In-Reply-To: <CAFeRt_evH=bUuojkgjt=pEJm5a-2GEdqQ-r7AgdeVz-_BENs9w@mail.gmail.com>
References: <CAFeRt_evH=bUuojkgjt=pEJm5a-2GEdqQ-r7AgdeVz-_BENs9w@mail.gmail.com>
Message-ID: <CAGxFJbTb8ZPDiijdt6KCP8XnbRY7C5MdWo0b=Ps5_Ym-QC0UAQ@mail.gmail.com>

Well, as a first suggestion, you should improve your research skills before
posting here: A web search on "garch models in R" came up with what looked
like many useful hits (including rugarch).

See also the GARCH section of the CRAN Time Series CRAN task view

https://CRAN.R-project.org/view=TimeSeries

Also read the posting guide for this list linked below to learn how to post
properly (for example, post in plain text, not HTML, which can get mangled).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jul 8, 2020 at 12:02 PM Osama Mostafa <osama78hefny at gmail.com>
wrote:

> Dear Professors
>
>
>
> Hope this e-mail find you well. I am currently doing my Masters in
> statistics and econometrics and my thesis is about the Properties and
> Estimation of Garch Models and their applications I need to know if it is
> to possible to estimate Garch model by Generalized Method of Moments
> <http://cameron.econ.ucdavis.edu/mmabook/transparencies/ct06_gmm.pdf>
>
>  (GMM) method using R . and If it possible I need a example of it by coding
>
>
>
> My sincere regards,
>
> ossama
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com  Thu Jul  9 01:19:37 2020
From: jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com (Michael Hannon)
Date: Wed, 8 Jul 2020 16:19:37 -0700
Subject: [R] output from R to simple html
In-Reply-To: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
References: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
Message-ID: <CACdH2Za9sgDXbiRN-g-7-yyHb5uNRMgLsNkLBWDnwgN3H3injQ@mail.gmail.com>

I can't tell what kind of structure you want to output, but one simple
thing that I've done along these lines is to use knitr::kable to
output a dataframe in either HTML or LaTeX format (for direct
inclusion on a web page or to convert to PDF for other uses).

-- Mike

On Wed, Jul 8, 2020 at 12:02 PM Marc Roos <M.Roos at f1-outsourcing.eu> wrote:
>
>
>
> I would like to parse some input to an R script and use its result
> output (maybe in json) on a web page. I think this shiny framework is a
> bit over kill. What is the simplest to implement this?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jul  9 02:15:24 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 08 Jul 2020 17:15:24 -0700
Subject: [R] output from R to simple html
In-Reply-To: <CACdH2Za9sgDXbiRN-g-7-yyHb5uNRMgLsNkLBWDnwgN3H3injQ@mail.gmail.com>
References: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
 <CACdH2Za9sgDXbiRN-g-7-yyHb5uNRMgLsNkLBWDnwgN3H3injQ@mail.gmail.com>
Message-ID: <798D1833-80F0-485E-AAE4-85122DD03C3A@dcn.davis.ca.us>

Perhaps an answer as simple as using the rmarkdown package to generate a standalone html file is all the OP needs?

On July 8, 2020 4:19:37 PM PDT, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
>I can't tell what kind of structure you want to output, but one simple
>thing that I've done along these lines is to use knitr::kable to
>output a dataframe in either HTML or LaTeX format (for direct
>inclusion on a web page or to convert to PDF for other uses).
>
>-- Mike
>
>On Wed, Jul 8, 2020 at 12:02 PM Marc Roos <M.Roos at f1-outsourcing.eu>
>wrote:
>>
>>
>>
>> I would like to parse some input to an R script and use its result
>> output (maybe in json) on a web page. I think this shiny framework is
>a
>> bit over kill. What is the simplest to implement this?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @c|@bo|@zz@ @end|ng |rom gm@||@com  Thu Jul  9 12:09:01 2020
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Thu, 9 Jul 2020 12:09:01 +0200
Subject: [R] Fixed effects regression constant (intercept) using lfe::felm
Message-ID: <CABZtLWy2XfOouj13iLS8-F8stqvgyFL6odO+NhdcSNSM=i9gYA@mail.gmail.com>

Dear list users,
When calculating a panel data regression with multiple fixed effects
using the function felm() from the lfe package, no constant term (i.e.
intercept) is generated in the summary results.

In an old post on stackoverflow [1], someone suggested that it is
possible to retrieve the value of the intercept by using the function
lfe::getfe, setting the field "ef" equal to "zm2".

However, I get different results when comparing the value of the
intercept calculated by the function lm, with that obtained with the
function lfe::getfe.

Here's a reproducible example:

library(lfe)

# set seed for reproducible example
set.seed(123)

## generate independent variables
x <- rnorm(4000)
x2 <- rnorm(length(x))

## create individual and firm ids
id <- factor(sample(500,length(x),replace=TRUE))
firm <- factor(sample(300,length(x),replace=TRUE))

## generate dependent variable
id.eff <- rlnorm(nlevels(id))
firm.eff <- rexp(nlevels(firm))
y <- x + 0.25*x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))

## estimate results
est <- felm(y ~ x + x2 | id + firm)
est2 <- lm(y ~ x + x2 + id + firm)

## Compare estimates
coef(est)
#         x        x2
# 1.017696 0.246784
coef(est2)[2:3]
#         x        x2
# 1.017696 0.246784

# estimate fixed effects
fe_est <- getfe(est, ef = "zm2")

## Compare intercept
fe_est[grepl("icpt", rownames(fe_est)), ]
#          effect  obs comp
# icpt.1 2.583704 4000    1
coef(est2)[1]
# (Intercept)
#   7.312307

I am wondering if anyone can explain this difference.
Also, I would like to know if it is possible to obtain a reliable
approximation of the value of the intercept estimated by lm using
lfe::getfe.

Best,
Valerio

P.s.Observe that 3 weeks ago I have posted this question on
stackoverflow [2] but no one answered.

[1] https://stackoverflow.com/questions/49351201/fixed-effects-regression-constant-intercept-using-lfe-felm-in-r
[2] https://stackoverflow.com/questions/62497705/estimate-of-constant-term-using-r-felmlfe-package-and-differences-with-stats

Valerio Leone Sciabolazza, Ph.D.
Department of Business and Economics
University of Naples, Parthenope.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jul  9 14:59:12 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 9 Jul 2020 14:59:12 +0200
Subject: [R] plot shows exponential values incompatible with data
Message-ID: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>

Hello,
I have these vectors:
```
X <- 1:7
Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
213484643920, 580311678200)
plot(Y~X)
```
The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
axis does not start at 1e9?



-- 
Best regards,
Luigi


From mp @end|ng |rom bodk@n@net  Wed Jul  8 21:52:36 2020
From: mp @end|ng |rom bodk@n@net (Martin Petr)
Date: Wed, 8 Jul 2020 21:52:36 +0200
Subject: [R] [R-pkgs] admixr: An Interface for Running 'ADMIXTOOLS' Analyses
Message-ID: <CADwGh-7j9nYgr0xV6xOdB-6heHgAaBELiL6GhSm2AQ1qY_A9Vw@mail.gmail.com>

Dear R users,

I would like to introduce my R package, admixr, which provides an interface
for performing population genetic analyses using the ADMIXTOOLS suite of
command-line utilities: https://cran.r-project.org/package=admixr.

ADMIXTOOLS (https://www.genetics.org/content/192/3/1065) is a very popular
software in population genetics. However, because each of its command-line
programs requires configuration files specific to each analysis, it is very
cumbersome to use.

The admixr package wraps around ADMIXTOOLS utilities and presents them as
if they were simple R functions. It achieves this by creating all
intermediate files needed by ADMIXTOOLS and extracting relevant statistics
from generated output files, which all happens under the hood.

Extended tutorial and overview of the package can be found at:
https://bodkan.net/admixr/articles/tutorial.html
Any feedback is welcome at: https://github.com/bodkan/admixr/issues

Best regards,
Martin Petr

-- 
www.bodkan.net

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jul  9 15:44:50 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 9 Jul 2020 13:44:50 +0000
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <388_1594299576_069CxaRX020258_CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
References: <388_1594299576_069CxaRX020258_CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
Message-ID: <6C8E6124-E43F-4687-A858-FF263923F931@mcmaster.ca>

Dear Luigi,

> On Jul 9, 2020, at 8:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Hello,
> I have these vectors:
> ```
> X <- 1:7
> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
> 213484643920, 580311678200)
> plot(Y~X)
> ```
> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
> axis does not start at 1e9?

Because you're plotting on a linear, not log, scale, and 0*10^11 = 0. 

> round(Y/1e11)
[1] 0 0 0 0 1 2 6

Then try plot(log(Y) ~ X).

I hope this helps,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox
> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jul  9 15:59:16 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 9 Jul 2020 15:59:16 +0200
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <6C8E6124-E43F-4687-A858-FF263923F931@mcmaster.ca>
References: <388_1594299576_069CxaRX020258_CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
 <6C8E6124-E43F-4687-A858-FF263923F931@mcmaster.ca>
Message-ID: <CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>

Thank you,
but why it does not work in linear? With the log scale, I know it
works but I am not looking for it; is there a way to force a linear
scale?
Regards
Luigi

On Thu, Jul 9, 2020 at 3:44 PM Fox, John <jfox at mcmaster.ca> wrote:
>
> Dear Luigi,
>
> > On Jul 9, 2020, at 8:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have these vectors:
> > ```
> > X <- 1:7
> > Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
> > 213484643920, 580311678200)
> > plot(Y~X)
> > ```
> > The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
> > axis does not start at 1e9?
>
> Because you're plotting on a linear, not log, scale, and 0*10^11 = 0.
>
> > round(Y/1e11)
> [1] 0 0 0 0 1 2 6
>
> Then try plot(log(Y) ~ X).
>
> I hope this helps,
>  John
>
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best regards,
Luigi


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jul  9 16:15:05 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Jul 2020 07:15:05 -0700
Subject: [R] 
 Fixed effects regression constant (intercept) using lfe::felm
In-Reply-To: <CABZtLWy2XfOouj13iLS8-F8stqvgyFL6odO+NhdcSNSM=i9gYA@mail.gmail.com>
References: <CABZtLWy2XfOouj13iLS8-F8stqvgyFL6odO+NhdcSNSM=i9gYA@mail.gmail.com>
Message-ID: <CAGxFJbTEy1YN3G16rwohwiqw5H2K9KN9paNfrUOiR6x+4c4pFA@mail.gmail.com>

While you may get lucky here, your experience on SO indicates that you may
do better by contacting the package maintainer (?maintainer) and asking
him/her to refer you to appropriate references, as this sounds like a
statistical methodology query.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jul 9, 2020 at 3:09 AM Valerio Leone Sciabolazza <
sciabolazza at gmail.com> wrote:

> Dear list users,
> When calculating a panel data regression with multiple fixed effects
> using the function felm() from the lfe package, no constant term (i.e.
> intercept) is generated in the summary results.
>
> In an old post on stackoverflow [1], someone suggested that it is
> possible to retrieve the value of the intercept by using the function
> lfe::getfe, setting the field "ef" equal to "zm2".
>
> However, I get different results when comparing the value of the
> intercept calculated by the function lm, with that obtained with the
> function lfe::getfe.
>
> Here's a reproducible example:
>
> library(lfe)
>
> # set seed for reproducible example
> set.seed(123)
>
> ## generate independent variables
> x <- rnorm(4000)
> x2 <- rnorm(length(x))
>
> ## create individual and firm ids
> id <- factor(sample(500,length(x),replace=TRUE))
> firm <- factor(sample(300,length(x),replace=TRUE))
>
> ## generate dependent variable
> id.eff <- rlnorm(nlevels(id))
> firm.eff <- rexp(nlevels(firm))
> y <- x + 0.25*x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))
>
> ## estimate results
> est <- felm(y ~ x + x2 | id + firm)
> est2 <- lm(y ~ x + x2 + id + firm)
>
> ## Compare estimates
> coef(est)
> #         x        x2
> # 1.017696 0.246784
> coef(est2)[2:3]
> #         x        x2
> # 1.017696 0.246784
>
> # estimate fixed effects
> fe_est <- getfe(est, ef = "zm2")
>
> ## Compare intercept
> fe_est[grepl("icpt", rownames(fe_est)), ]
> #          effect  obs comp
> # icpt.1 2.583704 4000    1
> coef(est2)[1]
> # (Intercept)
> #   7.312307
>
> I am wondering if anyone can explain this difference.
> Also, I would like to know if it is possible to obtain a reliable
> approximation of the value of the intercept estimated by lm using
> lfe::getfe.
>
> Best,
> Valerio
>
> P.s.Observe that 3 weeks ago I have posted this question on
> stackoverflow [2] but no one answered.
>
> [1]
> https://stackoverflow.com/questions/49351201/fixed-effects-regression-constant-intercept-using-lfe-felm-in-r
> [2]
> https://stackoverflow.com/questions/62497705/estimate-of-constant-term-using-r-felmlfe-package-and-differences-with-stats
>
> Valerio Leone Sciabolazza, Ph.D.
> Department of Business and Economics
> University of Naples, Parthenope.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jul  9 16:16:32 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 9 Jul 2020 14:16:32 +0000
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <23963_1594303516_069E5FWM005320_CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
References: <388_1594299576_069CxaRX020258_CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
 <6C8E6124-E43F-4687-A858-FF263923F931@mcmaster.ca>
 <23963_1594303516_069E5FWM005320_CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
Message-ID: <C35200DE-1145-43C4-85BA-3C8D10C4B16F@mcmaster.ca>

Dear Luigi,

> On Jul 9, 2020, at 9:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Thank you,
> but why it does not work in linear? With the log scale, I know it
> works but I am not looking for it; is there a way to force a linear
> scale?

The scale *is* linear and the choice of tick marks, which are evenly spaced, is reasonable, given that 10^9 is 2 orders of magnitude smaller than 10^11. That is, on a linear scale with this range, 10^9 isn't much larger than 0.

If you really want a tick at 10^9, then you can just put one there:

plot(Y~X, axes=FALSE, frame=TRUE)
axis(1)
axis(2, at=c(1e9, (1:6)*1e11))

But now the ticks aren't evenly spaced (though they appear to be because, as I mentioned, 10^9 is "close" to 0).

Best,
 John

> Regards
> Luigi
> 
> On Thu, Jul 9, 2020 at 3:44 PM Fox, John <jfox at mcmaster.ca> wrote:
>> 
>> Dear Luigi,
>> 
>>> On Jul 9, 2020, at 8:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>> 
>>> Hello,
>>> I have these vectors:
>>> ```
>>> X <- 1:7
>>> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
>>> 213484643920, 580311678200)
>>> plot(Y~X)
>>> ```
>>> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
>>> axis does not start at 1e9?
>> 
>> Because you're plotting on a linear, not log, scale, and 0*10^11 = 0.
>> 
>>> round(Y/1e11)
>> [1] 0 0 0 0 1 2 6
>> 
>> Then try plot(log(Y) ~ X).
>> 
>> I hope this helps,
>> John
>> 
>>  -----------------------------
>>  John Fox, Professor Emeritus
>>  McMaster University
>>  Hamilton, Ontario, Canada
>>  Web: http::/socserv.mcmaster.ca/jfox
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jul  9 16:22:25 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Jul 2020 07:22:25 -0700
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
References: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
Message-ID: <CAGxFJbTzvxarSmT4hwhZZ6P6T7sguhX6A+DUVygWKXKw_x0Kkw@mail.gmail.com>

Please consult ?axis and follow its links (e.g. "axTicks" and "pretty") for
the details of the algorithm used to construct axis annotation.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jul 9, 2020 at 5:59 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have these vectors:
> ```
> X <- 1:7
> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
> 213484643920, 580311678200)
> plot(Y~X)
> ```
> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
> axis does not start at 1e9?
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Jul  9 16:25:32 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 9 Jul 2020 10:25:32 -0400
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
References: <CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
Message-ID: <D0C790CE-CF2F-4C9E-9974-B6B5D6D1D6A2@comcast.net>

Use the xlim option in the plot function?

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Jul 9, 2020, at 10:06 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> ?Thank you,
> but why it does not work in linear? With the log scale, I know it
> works but I am not looking for it; is there a way to force a linear
> scale?
> Regards
> Luigi
> 
>> On Thu, Jul 9, 2020 at 3:44 PM Fox, John <jfox at mcmaster.ca> wrote:
>> 
>> Dear Luigi,
>> 
>>>> On Jul 9, 2020, at 8:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>> 
>>> Hello,
>>> I have these vectors:
>>> ```
>>> X <- 1:7
>>> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
>>> 213484643920, 580311678200)
>>> plot(Y~X)
>>> ```
>>> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
>>> axis does not start at 1e9?
>> 
>> Because you're plotting on a linear, not log, scale, and 0*10^11 = 0.
>> 
>>> round(Y/1e11)
>> [1] 0 0 0 0 1 2 6
>> 
>> Then try plot(log(Y) ~ X).
>> 
>> I hope this helps,
>> John
>> 
>>  -----------------------------
>>  John Fox, Professor Emeritus
>>  McMaster University
>>  Hamilton, Ontario, Canada
>>  Web: http::/socserv.mcmaster.ca/jfox
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jul  9 17:24:41 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 9 Jul 2020 16:24:41 +0100
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
References: <388_1594299576_069CxaRX020258_CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
 <6C8E6124-E43F-4687-A858-FF263923F931@mcmaster.ca>
 <CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
Message-ID: <baee6a81-5889-877f-babd-fc2d9a3ada4b@sapo.pt>

Hello,

Like this?

plot(Y~X, log="y")



Hope this helps,

Rui Barradas

?s 14:59 de 09/07/20, Luigi Marongiu escreveu:
> Thank you,
> but why it does not work in linear? With the log scale, I know it
> works but I am not looking for it; is there a way to force a linear
> scale?
> Regards
> Luigi
> 
> On Thu, Jul 9, 2020 at 3:44 PM Fox, John <jfox at mcmaster.ca> wrote:
>>
>> Dear Luigi,
>>
>>> On Jul 9, 2020, at 8:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>
>>> Hello,
>>> I have these vectors:
>>> ```
>>> X <- 1:7
>>> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
>>> 213484643920, 580311678200)
>>> plot(Y~X)
>>> ```
>>> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
>>> axis does not start at 1e9?
>>
>> Because you're plotting on a linear, not log, scale, and 0*10^11 = 0.
>>
>>> round(Y/1e11)
>> [1] 0 0 0 0 1 2 6
>>
>> Then try plot(log(Y) ~ X).
>>
>> I hope this helps,
>>   John
>>
>>    -----------------------------
>>    John Fox, Professor Emeritus
>>    McMaster University
>>    Hamilton, Ontario, Canada
>>    Web: http::/socserv.mcmaster.ca/jfox
>>>
>>>
>>>
>>> --
>>> Best regards,
>>> Luigi
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
>


From j|ox @end|ng |rom mcm@@ter@c@  Thu Jul  9 17:36:49 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 9 Jul 2020 15:36:49 +0000
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <6387_1594305931_069EjSJW008001_D0C790CE-CF2F-4C9E-9974-B6B5D6D1D6A2@comcast.net>
References: <CAMk+s2Q9L_W_A_PUkftAf6brO64Dmd3T=kPOmd__p5i5Zh0Qpg@mail.gmail.com>
 <6387_1594305931_069EjSJW008001_D0C790CE-CF2F-4C9E-9974-B6B5D6D1D6A2@comcast.net>
Message-ID: <BA90CF8B-81E9-4414-93F4-04D9838DA41B@mcmaster.ca>

Dear Bernard,

> On Jul 9, 2020, at 10:25 AM, Bernard Comcast <mcgarvey.bernard at comcast.net> wrote:
> 
> Use the xlim option in the plot function?

I think you mean ylim, but as you'll find out when you try it, you still (reasonably) get an evenly spaced tick mark at 0:

plot(Y ~ X, ylim=c(1e9, 6e11))

The "right" thing to do with exponential values is to plot on a log scale or (as Rui reasonably suggested) use a logged axis.

Best,
 John

> 
> Bernard
> Sent from my iPhone so please excuse the spelling!"
> 
>> On Jul 9, 2020, at 10:06 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> 
>> ?Thank you,
>> but why it does not work in linear? With the log scale, I know it
>> works but I am not looking for it; is there a way to force a linear
>> scale?
>> Regards
>> Luigi
>> 
>>> On Thu, Jul 9, 2020 at 3:44 PM Fox, John <jfox at mcmaster.ca> wrote:
>>> 
>>> Dear Luigi,
>>> 
>>>>> On Jul 9, 2020, at 8:59 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>>> 
>>>> Hello,
>>>> I have these vectors:
>>>> ```
>>>> X <- 1:7
>>>> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
>>>> 213484643920, 580311678200)
>>>> plot(Y~X)
>>>> ```
>>>> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
>>>> axis does not start at 1e9?
>>> 
>>> Because you're plotting on a linear, not log, scale, and 0*10^11 = 0.
>>> 
>>>> round(Y/1e11)
>>> [1] 0 0 0 0 1 2 6
>>> 
>>> Then try plot(log(Y) ~ X).
>>> 
>>> I hope this helps,
>>> John
>>> 
>>> -----------------------------
>>> John Fox, Professor Emeritus
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> Web: http::/socserv.mcmaster.ca/jfox
>>>> 
>>>> 
>>>> 
>>>> --
>>>> Best regards,
>>>> Luigi
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> -- 
>> Best regards,
>> Luigi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Thu Jul  9 18:44:10 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 9 Jul 2020 18:44:10 +0200
Subject: [R] 
 Fixed effects regression constant (intercept) using lfe::felm
In-Reply-To: <CAGxFJbTEy1YN3G16rwohwiqw5H2K9KN9paNfrUOiR6x+4c4pFA@mail.gmail.com>
References: <CABZtLWy2XfOouj13iLS8-F8stqvgyFL6odO+NhdcSNSM=i9gYA@mail.gmail.com>
 <CAGxFJbTEy1YN3G16rwohwiqw5H2K9KN9paNfrUOiR6x+4c4pFA@mail.gmail.com>
Message-ID: <20200709164410.GB47330@posteo.no>

On 2020-07-09 07:15 -0700, Bert Gunter wrote:
> On Thu, Jul 9, 2020 at 3:09 AM Valerio Leone Sciabolazza <sciabolazza at gmail.com> wrote:
> > 
> > When calculating a panel data 
> > regression with multiple fixed 
> > effects using the function felm() 
> > from the lfe package, no constant 
> > term (i.e.  intercept) is generated 
> > in the summary results.
> >
> > Also, I would like to know if it is 
> > possible to obtain a reliable 
> > approximation of the value of the 
> > intercept estimated by lm using 
> > lfe::getfe.
> 
> you may do better by contacting the 
> package maintainer (?maintainer) and 
> asking him/her to refer you to 
> appropriate references, as this sounds 
> like a statistical methodology query.

Valerio,

these are such interesting questions.  

Rememeber to post a follow-up of your 
findings here and on SO if you are able 
to solve this.

V

r

-- 
 _________________________________________
/ Difficulty                              \
|                                         |
| Practice no-action; Attend to           |
| do-nothing; Taste the flavorless,       |
| Magnify the small, Multiply the few,    |
| Return love for hate. Deal with the     |
| difficult while it is yet easy; Deal    |
| with the great while it is yet small;   |
| The difficult develops naturally from   |
| the easy, And the great from the small; |
| So the sage, by dealing with the small, |
| Achieves the great. Who finds it easy   |
| to promise finds it hard to be trusted; |
| Who takes things lightly finds things   |
| difficult; The sage recognizes          |
| difficulty, and so has none.            |
|                                         |
\ -- Lao Tse, "Tao Te Ching"              /
 -----------------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200709/4bab4da5/attachment.sig>

From drj|m|emon @end|ng |rom gm@||@com  Fri Jul 10 06:08:10 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 10 Jul 2020 14:08:10 +1000
Subject: [R] output from R to simple html
In-Reply-To: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
References: <H000007100174024.1594233070.sx.f1-outsourcing.eu*@MHS>
Message-ID: <CA+8X3fUk2EqMfLXJuV_0bx=ns8A935bS1mQTXugU5wTTUHT9Nw@mail.gmail.com>

Hi Marc,
The "htmlize" function in the prettyR package might be what you are looking for.

Jim

On Thu, Jul 9, 2020 at 5:02 AM Marc Roos <M.Roos at f1-outsourcing.eu> wrote:
>
>
>
> I would like to parse some input to an R script and use its result
> output (maybe in json) on a web page. I think this shiny framework is a
> bit over kill. What is the simplest to implement this?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Jul 10 06:13:52 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 10 Jul 2020 14:13:52 +1000
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
References: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
Message-ID: <CA+8X3fUhT90h-cF62gKr=O_PGaXThyWGFkDtDA4hH3ONS8kxew@mail.gmail.com>

Hi Luigi,
This is a result of the "pretty" function that calculates hopefully
good looking axis ticks automatically. You can always specify
ylim=c(1.0E09,max(Y)) if you want.

Jim

On Thu, Jul 9, 2020 at 10:59 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have these vectors:
> ```
> X <- 1:7
> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
> 213484643920, 580311678200)
> plot(Y~X)
> ```
> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
> axis does not start at 1e9?
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Jul 10 08:59:27 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 10 Jul 2020 08:59:27 +0200
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <CA+8X3fUhT90h-cF62gKr=O_PGaXThyWGFkDtDA4hH3ONS8kxew@mail.gmail.com>
References: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
 <CA+8X3fUhT90h-cF62gKr=O_PGaXThyWGFkDtDA4hH3ONS8kxew@mail.gmail.com>
Message-ID: <CAMk+s2RppuqqtLdZxQgtAgdBf9zxFN5YyrrMu7-FdCijwki_zw@mail.gmail.com>

Thank you!
I reckon the main problem is the large data range, anyway. I should
stick with logarithmic scales...
Best regards
Luigi

On Fri, Jul 10, 2020 at 6:14 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> This is a result of the "pretty" function that calculates hopefully
> good looking axis ticks automatically. You can always specify
> ylim=c(1.0E09,max(Y)) if you want.
>
> Jim
>
> On Thu, Jul 9, 2020 at 10:59 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have these vectors:
> > ```
> > X <- 1:7
> > Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
> > 213484643920, 580311678200)
> > plot(Y~X)
> > ```
> > The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
> > axis does not start at 1e9?
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jul 10 14:58:32 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 10 Jul 2020 12:58:32 +0000
Subject: [R] plot shows exponential values incompatible with data
In-Reply-To: <7296_1594354722_06A4IfgI016223_CA+8X3fUhT90h-cF62gKr=O_PGaXThyWGFkDtDA4hH3ONS8kxew@mail.gmail.com>
References: <CAMk+s2QU_DoVmc62L499CBNQ5BEX5qrDeeV=U+WpM7uteMU45g@mail.gmail.com>
 <7296_1594354722_06A4IfgI016223_CA+8X3fUhT90h-cF62gKr=O_PGaXThyWGFkDtDA4hH3ONS8kxew@mail.gmail.com>
Message-ID: <E7FECA58-5955-4A24-AE88-37409F84903B@mcmaster.ca>

Dear Jim,

As I pointed out yesterday, setting ylim as you suggest still results in "0e+00" as the smallest tick mark, as it should for evenly spaced ticks. 

Best,
 John

> On Jul 10, 2020, at 12:13 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Luigi,
> This is a result of the "pretty" function that calculates hopefully
> good looking axis ticks automatically. You can always specify
> ylim=c(1.0E09,max(Y)) if you want.
> 
> Jim
> 
> On Thu, Jul 9, 2020 at 10:59 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> 
>> Hello,
>> I have these vectors:
>> ```
>> X <- 1:7
>> Y <- c(1438443863, 3910100650, 10628760108, 28891979048, 78536576706,
>> 213484643920, 580311678200)
>> plot(Y~X)
>> ```
>> The y-axis starts at 0e0, but the first value is 1.4 billion. Why the
>> axis does not start at 1e9?
>> 
>> 
>> 
>> --
>> Best regards,
>> Luigi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d@n|e||obo1990 @end|ng |rom y@hoo@com  Fri Jul 10 13:36:13 2020
From: d@n|e||obo1990 @end|ng |rom y@hoo@com (Arun Kumar Saha)
Date: Fri, 10 Jul 2020 11:36:13 +0000 (UTC)
Subject: [R] Bivariate ReLU Distribution
References: <1398793978.9432149.1594380973005.ref@mail.yahoo.com>
Message-ID: <1398793978.9432149.1594380973005@mail.yahoo.com>

Hi,
I would rather have a Statistics related question hope experts here can provide some suggestions. I have posted this request in some other forum but failed to generate meaningful response
I am looking for some technical document on deriving the Distribution function for sum of 2?ReLU(?)=max{0,?} distributions i.e?max{0,?1} +?max{0,?2} where X1 and X2 jointly follow some bivariate Nomal distribution.
There are few technical notes available for univariate?ReLU distribution, however I failed to find any spec for bivariate/multivariate setup.
Any pointer on above subject will be highly helpful.
	[[alternative HTML version deleted]]


From p@u||n@@@ko| @end|ng |rom hotm@||@com  Fri Jul 10 15:32:36 2020
From: p@u||n@@@ko| @end|ng |rom hotm@||@com (Paulina Skolasinska)
Date: Fri, 10 Jul 2020 13:32:36 +0000
Subject: [R] How to differ stats_cor labels by group on a ggplot
Message-ID: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>

'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.

I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW

> for (i in 18:21) {
  p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) + 
    geom_smooth(method="lm") + 
    geom_point(size = 4) +
    geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
    scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) + 
    stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
    stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black", 
                 label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
  
  ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
}

From @b|tbo| @end|ng |rom @ent@com  Fri Jul 10 19:50:18 2020
From: @b|tbo| @end|ng |rom @ent@com (Jean-Louis Abitbol)
Date: Fri, 10 Jul 2020 19:50:18 +0200
Subject: [R] Character (1a, 1b) to numeric
Message-ID: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>

Dear All

I have a character vector,  representing histology stages, such as for example:
xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")

and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.

I would want to convert xc, for plotting reasons, to a numeric vector such as

xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)

Unfortunately I have no clue on how to do that.

Thanks for any help and apologies if I am missing the obvious way to do it.

JL
-- 
Verif30042020


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jul 10 20:10:27 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 10 Jul 2020 18:10:27 +0000
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
Message-ID: <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>

Dear Jean-Louis,

There must be many ways to do this. Here's one simple way (with no claim of optimality!):

> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> 
> set.seed(123) # for reproducibility
> x <- sample(xc, 20, replace=TRUE) # "data"
> 
> names(xn) <- xc
> z <- xn[x]
> 
> data.frame(z, x)
     z  x
1  2.5 2b
2  2.5 2b
3  1.5 1b
4  2.3 2a
5  1.5 1b
6  1.3 1a
7  1.3 1a
8  2.3 2a
9  1.5 1b
10 2.0  2
11 1.7 1c
12 2.3 2a
13 2.3 2a
14 1.0  1
15 1.3 1a
16 1.5 1b
17 2.7 2c
18 2.0  2
19 1.5 1b
20 1.5 1b

I hope this helps,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com> wrote:
> 
> Dear All
> 
> I have a character vector,  representing histology stages, such as for example:
> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> 
> and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
> 
> I would want to convert xc, for plotting reasons, to a numeric vector such as
> 
> xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> 
> Unfortunately I have no clue on how to do that.
> 
> Thanks for any help and apologies if I am missing the obvious way to do it.
> 
> JL
> -- 
> Verif30042020
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Fri Jul 10 20:11:15 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 10 Jul 2020 14:11:15 -0400
Subject: [R] [External]  Character (1a, 1b) to numeric
In-Reply-To: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
Message-ID: <CAGx1TMD2V8QuJdew7XLAPZpJGTqifx-VmFr_aEATcYf=KscnAA@mail.gmail.com>

> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> testdata <- rep(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), times=1:8)
> testdata
 [1] "1"  "1a" "1a" "1b" "1b" "1b" "1c" "1c" "1c" "1c" "2"  "2"  "2"  "2"  "2"
[16] "2a" "2a" "2a" "2a" "2a" "2a" "2b" "2b" "2b" "2b" "2b" "2b" "2b" "2c" "2c"
[31] "2c" "2c" "2c" "2c" "2c" "2c"
> ?match
> xn[match(testdata, xc)]
 [1] 1.0 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 1.7 2.0 2.0 2.0 2.0 2.0 2.3 2.3 2.3 2.3
[20] 2.3 2.3 2.5 2.5 2.5 2.5 2.5 2.5 2.5 2.7 2.7 2.7 2.7 2.7 2.7 2.7 2.7
>

On Fri, Jul 10, 2020 at 1:51 PM Jean-Louis Abitbol <abitbol at sent.com> wrote:
>
> Dear All
>
> I have a character vector,  representing histology stages, such as for example:
> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>
> and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
>
> I would want to convert xc, for plotting reasons, to a numeric vector such as
>
> xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
>
> Unfortunately I have no clue on how to do that.
>
> Thanks for any help and apologies if I am missing the obvious way to do it.
>
> JL
> --
> Verif30042020
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jul 10 20:20:18 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 10 Jul 2020 11:20:18 -0700
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
Message-ID: <A8301FFA-2464-41FC-AE39-2F3DB88DC294@dcn.davis.ca.us>

Obvious is in the eye of the beholder. Presuming your letters don't go beyond "i":

a) Lookup table:

tbl <- read.table( text=
"OldCode  NewCode
1         1
1a        1.1
1b        1.2
1c        1.3
2         2
2a        2.1
2b        2.2
", as.is=TRUE, header=TRUE )

tblv <- setNames( tbl$NewCode, tbl$OldCode )
test <- c( "2", "1c", "2b" )
as.vector( tblv[ test ] )

b) String manipulation:

n <- as.integer( sub( "[a-i]$", "", test ) )
d <- match( sub( "^\\d+", "", test ), letters[1:9] )
d[ is.na( d ) ] <- 0
n + d / 10

On July 10, 2020 10:50:18 AM PDT, Jean-Louis Abitbol <abitbol at sent.com> wrote:
>Dear All
>
>I have a character vector,  representing histology stages, such as for
>example:
>xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>
>and this goes on to 3, 3a etc in various order for each patient. I do
>have of course a pre-established  classification available which does
>change according to the histology criteria under assessment.
>
>I would want to convert xc, for plotting reasons, to a numeric vector
>such as
>
>xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
>
>Unfortunately I have no clue on how to do that.
>
>Thanks for any help and apologies if I am missing the obvious way to do
>it.
>
>JL

-- 
Sent from my phone. Please excuse my brevity.


From dc@r|@on @end|ng |rom t@mu@edu  Fri Jul 10 21:28:03 2020
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Fri, 10 Jul 2020 14:28:03 -0500
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
Message-ID: <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>

Here is a different approach:

xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
xn
# [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7

David L Carlson
Professor Emeritus of Anthropology
Texas A&M University

On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Jean-Louis,
>
> There must be many ways to do this. Here's one simple way (with no claim
> of optimality!):
>
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> >
> > set.seed(123) # for reproducibility
> > x <- sample(xc, 20, replace=TRUE) # "data"
> >
> > names(xn) <- xc
> > z <- xn[x]
> >
> > data.frame(z, x)
>      z  x
> 1  2.5 2b
> 2  2.5 2b
> 3  1.5 1b
> 4  2.3 2a
> 5  1.5 1b
> 6  1.3 1a
> 7  1.3 1a
> 8  2.3 2a
> 9  1.5 1b
> 10 2.0  2
> 11 1.7 1c
> 12 2.3 2a
> 13 2.3 2a
> 14 1.0  1
> 15 1.3 1a
> 16 1.5 1b
> 17 2.7 2c
> 18 2.0  2
> 19 1.5 1b
> 20 1.5 1b
>
> I hope this helps,
>  John
>
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
>
> > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com>
> wrote:
> >
> > Dear All
> >
> > I have a character vector,  representing histology stages, such as for
> example:
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> >
> > and this goes on to 3, 3a etc in various order for each patient. I do
> have of course a pre-established  classification available which does
> change according to the histology criteria under assessment.
> >
> > I would want to convert xc, for plotting reasons, to a numeric vector
> such as
> >
> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> >
> > Unfortunately I have no clue on how to do that.
> >
> > Thanks for any help and apologies if I am missing the obvious way to do
> it.
> >
> > JL
> > --
> > Verif30042020
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 10 21:54:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 10 Jul 2020 12:54:09 -0700
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
Message-ID: <CAGxFJbTRdr-4RPh+oF=V454GfL5moJ2wvHDmZrPPXQ0e7R723Q@mail.gmail.com>

... and continuing with this cute little thread...

I found the OP's specification a little imprecise -- are your values always
a string that begins with *some sort" of numeric value followed by "some
sort" of alpha code? That is, could the numeric value be several digits and
the alpha code several letters? Probably not, and the existing solutions
you have been provided are almost certainly all you need. But for fun,
assuming this more general specification, here is a general way to split
your alphanumeric codes up into numeric and alpha parts and then convert by
using a couple of sub() 's.

> set.seed(131)
> xc <- sample(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), 15, replace
= TRUE)
> nums <- sub("[[:alpha:]]+","",xc)  ## extract numeric part
> alph <- sub("\\d+","",xc)   ## extract alpha part
> codes <- letters[1:3] ## whatever alpha codes are used
> vals <- setNames(c(.3,.5,.7), codes) ## whatever numeric values to
convert codes to
> xnew <- as.numeric(nums) + ifelse(alph == "",0, vals[alph])
> data.frame (xc = xc, xnew = xnew)
   xc xnew
1  1a  1.3
2   2  2.0
3  1c  1.7
4  1c  1.7
5  1b  1.5
6  1a  1.3
7   2  2.0
8   2  2.0
9  1a  1.3
10 1a  1.3
11 2c  2.7
12 1b  1.5
13 1b  1.5
14  1  1.0
15 1c  1.7

Echoing others, no claim for optimality in any sense.

Cheers,
Bert


On Fri, Jul 10, 2020 at 12:28 PM David Carlson <dcarlson at tamu.edu> wrote:

> Here is a different approach:
>
> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> xn
> # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
>
> David L Carlson
> Professor Emeritus of Anthropology
> Texas A&M University
>
> On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
>
> > Dear Jean-Louis,
> >
> > There must be many ways to do this. Here's one simple way (with no claim
> > of optimality!):
> >
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > >
> > > set.seed(123) # for reproducibility
> > > x <- sample(xc, 20, replace=TRUE) # "data"
> > >
> > > names(xn) <- xc
> > > z <- xn[x]
> > >
> > > data.frame(z, x)
> >      z  x
> > 1  2.5 2b
> > 2  2.5 2b
> > 3  1.5 1b
> > 4  2.3 2a
> > 5  1.5 1b
> > 6  1.3 1a
> > 7  1.3 1a
> > 8  2.3 2a
> > 9  1.5 1b
> > 10 2.0  2
> > 11 1.7 1c
> > 12 2.3 2a
> > 13 2.3 2a
> > 14 1.0  1
> > 15 1.3 1a
> > 16 1.5 1b
> > 17 2.7 2c
> > 18 2.0  2
> > 19 1.5 1b
> > 20 1.5 1b
> >
> > I hope this helps,
> >  John
> >
> >   -----------------------------
> >   John Fox, Professor Emeritus
> >   McMaster University
> >   Hamilton, Ontario, Canada
> >   Web: http::/socserv.mcmaster.ca/jfox
> >
> > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com>
> > wrote:
> > >
> > > Dear All
> > >
> > > I have a character vector,  representing histology stages, such as for
> > example:
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > >
> > > and this goes on to 3, 3a etc in various order for each patient. I do
> > have of course a pre-established  classification available which does
> > change according to the histology criteria under assessment.
> > >
> > > I would want to convert xc, for plotting reasons, to a numeric vector
> > such as
> > >
> > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > >
> > > Unfortunately I have no clue on how to do that.
> > >
> > > Thanks for any help and apologies if I am missing the obvious way to do
> > it.
> > >
> > > JL
> > > --
> > > Verif30042020
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > PLEASE do read the posting guide
> >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > PLEASE do read the posting guide
> >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jul 10 22:02:47 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 10 Jul 2020 20:02:47 +0000
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
Message-ID: <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>

Hi,

We've had several solutions, and I was curious about their relative efficiency. Here's a test with a moderately large data vector:

> library("microbenchmark")
> set.seed(123) # for reproducibility
> x <- sample(xc, 1e4, replace=TRUE) # "data"
> microbenchmark(John = John <- xn[x], 
+                Rich = Rich <- xn[match(x, xc)], 
+                Jeff = Jeff <- {
+                 n <- as.integer( sub( "[a-i]$", "", x ) )
+                 d <- match( sub( "^\\d+", "", x ), letters[1:9] )
+                 d[ is.na( d ) ] <- 0
+                 n + d / 10
+                 },
+                David = David <- as.numeric(gsub("a", ".3", 
+                                      gsub("b", ".5", 
+                                           gsub("c", ".7", x)))),
+                times=1000L
+                )
Unit: microseconds
  expr       min        lq       mean     median         uq       max neval cld
  John   228.816   345.371   513.5614   503.5965   533.0635  10829.08  1000 a  
  Rich   217.395   343.035   534.2074   489.0075   518.3260  15388.96  1000 a  
  Jeff 10325.471 13070.737 15387.2545 15397.9790 17204.0115 153486.94  1000  b 
 David 14256.673 18148.492 20185.7156 20170.3635 22067.6690  34998.95  1000   c
> all.equal(John, Rich)
[1] TRUE
> all.equal(John, David)
[1] "names for target but not for current"
> all.equal(John, Jeff)
[1] "names for target but not for current" "Mean relative difference: 0.1498243" 

Of course, efficiency isn't the only consideration, and aesthetically (and no doubt subjectively) I prefer Rich Heiberger's solution. OTOH, Jeff's solution is more general in that it generates the correspondence between letters and numbers. The argument for Jeff's solution would, however, be stronger if it gave the desired answer.

Best,
 John

> On Jul 10, 2020, at 3:28 PM, David Carlson <dcarlson at tamu.edu> wrote:
> 
> Here is a different approach:
> 
> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> xn
> # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> 
> David L Carlson
> Professor Emeritus of Anthropology
> Texas A&M University
> 
> On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> Dear Jean-Louis,
> 
> There must be many ways to do this. Here's one simple way (with no claim of optimality!):
> 
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > 
> > set.seed(123) # for reproducibility
> > x <- sample(xc, 20, replace=TRUE) # "data"
> > 
> > names(xn) <- xc
> > z <- xn[x]
> > 
> > data.frame(z, x)
>      z  x
> 1  2.5 2b
> 2  2.5 2b
> 3  1.5 1b
> 4  2.3 2a
> 5  1.5 1b
> 6  1.3 1a
> 7  1.3 1a
> 8  2.3 2a
> 9  1.5 1b
> 10 2.0  2
> 11 1.7 1c
> 12 2.3 2a
> 13 2.3 2a
> 14 1.0  1
> 15 1.3 1a
> 16 1.5 1b
> 17 2.7 2c
> 18 2.0  2
> 19 1.5 1b
> 20 1.5 1b
> 
> I hope this helps,
>  John
> 
>   -----------------------------
>   John Fox, Professor Emeritus
>   McMaster University
>   Hamilton, Ontario, Canada
>   Web: http::/socserv.mcmaster.ca/jfox
> 
> > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com> wrote:
> > 
> > Dear All
> > 
> > I have a character vector,  representing histology stages, such as for example:
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > 
> > and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
> > 
> > I would want to convert xc, for plotting reasons, to a numeric vector such as
> > 
> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > 
> > Unfortunately I have no clue on how to do that.
> > 
> > Thanks for any help and apologies if I am missing the obvious way to do it.
> > 
> > JL
> > -- 
> > Verif30042020
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$ 
> > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$ 
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$ 
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$ 
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Fri Jul 10 22:21:06 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 10 Jul 2020 20:21:06 +0000
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CAGxFJbTRdr-4RPh+oF=V454GfL5moJ2wvHDmZrPPXQ0e7R723Q@mail.gmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <CAGxFJbTRdr-4RPh+oF=V454GfL5moJ2wvHDmZrPPXQ0e7R723Q@mail.gmail.com>
Message-ID: <43ED69CD-5CCB-4857-9D9B-1B26426FF14F@mcmaster.ca>

Dear Bert,

Wouldn't you know it, but your contribution arrived just after I pressed "send" on my last message? So here's how your solution compares:

> microbenchmark(John = John <- xn[x], 
+                Rich = Rich <- xn[match(x, xc)], 
+                Jeff = Jeff <- {
+                   n <- as.integer( sub( "[a-i]$", "", x ) )
+                   d <- match( sub( "^\\d+", "", x ), letters[1:9] )
+                   d[ is.na( d ) ] <- 0
+                   n + d / 10
+                },
+                David = David <- as.numeric(gsub("a", ".3", 
+                                      gsub("b", ".5", 
+                                           gsub("c", ".7", x)))),
+                Bert = Bert <- {
+                   nums <- sub("[[:alpha:]]+","",x)  
+                   alph <- sub("\\d+","",x)  
+                   as.numeric(nums) + ifelse(alph == "",0, vals[alph])
+                },
+                times=1000L
+                )
Unit: microseconds
  expr       min         lq       mean    median         uq       max neval  cld
  John   261.739   373.9765   599.9411   536.571   569.3750  14489.48  1000 a   
  Rich   250.697   372.4450   542.3208   520.383   554.7215  10682.73  1000 a   
  Jeff 10879.223 13477.7665 15647.7856 15549.255 17516.7420 146155.28  1000  b  
 David 14337.510 18375.0100 20325.8796 20187.174 22161.0195  32575.31  1000    d
  Bert 12344.506 15753.2510 18024.2757 17702.838 19973.0465  32043.80  1000   c 
> all.equal(John, Rich)
[1] TRUE
> all.equal(John, David)
[1] "names for target but not for current"
> all.equal(John, Jeff)
[1] "names for target but not for current" "Mean relative difference: 0.1498243" 
> all.equal(John, Bert)
[1] "names for target but not for current"

To make the comparison fair, I moved the parts of the solutions that don't depend on the length of the data outside the benchmark. Your solution does have the virtue of providing the right answer.

Best,
 John

> On Jul 10, 2020, at 3:54 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ... and continuing with this cute little thread...
> 
> I found the OP's specification a little imprecise -- are your values always a string that begins with *some sort" of numeric value followed by "some sort" of alpha code? That is, could the numeric value be several digits and the alpha code several letters? Probably not, and the existing solutions you have been provided are almost certainly all you need. But for fun, assuming this more general specification, here is a general way to split your alphanumeric codes up into numeric and alpha parts and then convert by using a couple of sub() 's.
> 
> > set.seed(131)
> > xc <- sample(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), 15, replace = TRUE) 
> > nums <- sub("[[:alpha:]]+","",xc)  ## extract numeric part
> > alph <- sub("\\d+","",xc)   ## extract alpha part
> > codes <- letters[1:3] ## whatever alpha codes are used
> > vals <- setNames(c(.3,.5,.7), codes) ## whatever numeric values to convert codes to
> > xnew <- as.numeric(nums) + ifelse(alph == "",0, vals[alph])
> > data.frame (xc = xc, xnew = xnew)
>    xc xnew
> 1  1a  1.3
> 2   2  2.0
> 3  1c  1.7
> 4  1c  1.7
> 5  1b  1.5
> 6  1a  1.3
> 7   2  2.0
> 8   2  2.0
> 9  1a  1.3
> 10 1a  1.3
> 11 2c  2.7
> 12 1b  1.5
> 13 1b  1.5
> 14  1  1.0
> 15 1c  1.7
> 
> Echoing others, no claim for optimality in any sense.
> 
> Cheers,
> Bert
> 
> 
> On Fri, Jul 10, 2020 at 12:28 PM David Carlson <dcarlson at tamu.edu> wrote:
> Here is a different approach:
> 
> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> xn
> # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> 
> David L Carlson
> Professor Emeritus of Anthropology
> Texas A&M University
> 
> On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> 
> > Dear Jean-Louis,
> >
> > There must be many ways to do this. Here's one simple way (with no claim
> > of optimality!):
> >
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > >
> > > set.seed(123) # for reproducibility
> > > x <- sample(xc, 20, replace=TRUE) # "data"
> > >
> > > names(xn) <- xc
> > > z <- xn[x]
> > >
> > > data.frame(z, x)
> >      z  x
> > 1  2.5 2b
> > 2  2.5 2b
> > 3  1.5 1b
> > 4  2.3 2a
> > 5  1.5 1b
> > 6  1.3 1a
> > 7  1.3 1a
> > 8  2.3 2a
> > 9  1.5 1b
> > 10 2.0  2
> > 11 1.7 1c
> > 12 2.3 2a
> > 13 2.3 2a
> > 14 1.0  1
> > 15 1.3 1a
> > 16 1.5 1b
> > 17 2.7 2c
> > 18 2.0  2
> > 19 1.5 1b
> > 20 1.5 1b
> >
> > I hope this helps,
> >  John
> >
> >   -----------------------------
> >   John Fox, Professor Emeritus
> >   McMaster University
> >   Hamilton, Ontario, Canada
> >   Web: http::/socserv.mcmaster.ca/jfox
> >
> > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com>
> > wrote:
> > >
> > > Dear All
> > >
> > > I have a character vector,  representing histology stages, such as for
> > example:
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > >
> > > and this goes on to 3, 3a etc in various order for each patient. I do
> > have of course a pre-established  classification available which does
> > change according to the histology criteria under assessment.
> > >
> > > I would want to convert xc, for plotting reasons, to a numeric vector
> > such as
> > >
> > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > >
> > > Unfortunately I have no clue on how to do that.
> > >
> > > Thanks for any help and apologies if I am missing the obvious way to do
> > it.
> > >
> > > JL
> > > --
> > > Verif30042020
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >
> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > PLEASE do read the posting guide
> > https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > PLEASE do read the posting guide
> > https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jul 10 22:26:37 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 10 Jul 2020 13:26:37 -0700
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <43ED69CD-5CCB-4857-9D9B-1B26426FF14F@mcmaster.ca>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <CAGxFJbTRdr-4RPh+oF=V454GfL5moJ2wvHDmZrPPXQ0e7R723Q@mail.gmail.com>
 <43ED69CD-5CCB-4857-9D9B-1B26426FF14F@mcmaster.ca>
Message-ID: <CAGxFJbQ9E1sq-aOJTe4p+Hi5c1zQN8apvo7kQ-Vhgf-vsW9mCw@mail.gmail.com>

Thanks! As I said, cute exercise.

Best,
Bert




On Fri, Jul 10, 2020 at 1:21 PM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Bert,
>
> Wouldn't you know it, but your contribution arrived just after I pressed
> "send" on my last message? So here's how your solution compares:
>
> > microbenchmark(John = John <- xn[x],
> +                Rich = Rich <- xn[match(x, xc)],
> +                Jeff = Jeff <- {
> +                   n <- as.integer( sub( "[a-i]$", "", x ) )
> +                   d <- match( sub( "^\\d+", "", x ), letters[1:9] )
> +                   d[ is.na( d ) ] <- 0
> +                   n + d / 10
> +                },
> +                David = David <- as.numeric(gsub("a", ".3",
> +                                      gsub("b", ".5",
> +                                           gsub("c", ".7", x)))),
> +                Bert = Bert <- {
> +                   nums <- sub("[[:alpha:]]+","",x)
> +                   alph <- sub("\\d+","",x)
> +                   as.numeric(nums) + ifelse(alph == "",0, vals[alph])
> +                },
> +                times=1000L
> +                )
> Unit: microseconds
>   expr       min         lq       mean    median         uq       max
> neval  cld
>   John   261.739   373.9765   599.9411   536.571   569.3750  14489.48
> 1000 a
>   Rich   250.697   372.4450   542.3208   520.383   554.7215  10682.73
> 1000 a
>   Jeff 10879.223 13477.7665 15647.7856 15549.255 17516.7420 146155.28
> 1000  b
>  David 14337.510 18375.0100 20325.8796 20187.174 22161.0195  32575.31
> 1000    d
>   Bert 12344.506 15753.2510 18024.2757 17702.838 19973.0465  32043.80
> 1000   c
> > all.equal(John, Rich)
> [1] TRUE
> > all.equal(John, David)
> [1] "names for target but not for current"
> > all.equal(John, Jeff)
> [1] "names for target but not for current" "Mean relative difference:
> 0.1498243"
> > all.equal(John, Bert)
> [1] "names for target but not for current"
>
> To make the comparison fair, I moved the parts of the solutions that don't
> depend on the length of the data outside the benchmark. Your solution does
> have the virtue of providing the right answer.
>
> Best,
>  John
>
> > On Jul 10, 2020, at 3:54 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > ... and continuing with this cute little thread...
> >
> > I found the OP's specification a little imprecise -- are your values
> always a string that begins with *some sort" of numeric value followed by
> "some sort" of alpha code? That is, could the numeric value be several
> digits and the alpha code several letters? Probably not, and the existing
> solutions you have been provided are almost certainly all you need. But for
> fun, assuming this more general specification, here is a general way to
> split your alphanumeric codes up into numeric and alpha parts and then
> convert by using a couple of sub() 's.
> >
> > > set.seed(131)
> > > xc <- sample(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), 15,
> replace = TRUE)
> > > nums <- sub("[[:alpha:]]+","",xc)  ## extract numeric part
> > > alph <- sub("\\d+","",xc)   ## extract alpha part
> > > codes <- letters[1:3] ## whatever alpha codes are used
> > > vals <- setNames(c(.3,.5,.7), codes) ## whatever numeric values to
> convert codes to
> > > xnew <- as.numeric(nums) + ifelse(alph == "",0, vals[alph])
> > > data.frame (xc = xc, xnew = xnew)
> >    xc xnew
> > 1  1a  1.3
> > 2   2  2.0
> > 3  1c  1.7
> > 4  1c  1.7
> > 5  1b  1.5
> > 6  1a  1.3
> > 7   2  2.0
> > 8   2  2.0
> > 9  1a  1.3
> > 10 1a  1.3
> > 11 2c  2.7
> > 12 1b  1.5
> > 13 1b  1.5
> > 14  1  1.0
> > 15 1c  1.7
> >
> > Echoing others, no claim for optimality in any sense.
> >
> > Cheers,
> > Bert
> >
> >
> > On Fri, Jul 10, 2020 at 12:28 PM David Carlson <dcarlson at tamu.edu>
> wrote:
> > Here is a different approach:
> >
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> > xn
> > # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> >
> > David L Carlson
> > Professor Emeritus of Anthropology
> > Texas A&M University
> >
> > On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> >
> > > Dear Jean-Louis,
> > >
> > > There must be many ways to do this. Here's one simple way (with no
> claim
> > > of optimality!):
> > >
> > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > >
> > > > set.seed(123) # for reproducibility
> > > > x <- sample(xc, 20, replace=TRUE) # "data"
> > > >
> > > > names(xn) <- xc
> > > > z <- xn[x]
> > > >
> > > > data.frame(z, x)
> > >      z  x
> > > 1  2.5 2b
> > > 2  2.5 2b
> > > 3  1.5 1b
> > > 4  2.3 2a
> > > 5  1.5 1b
> > > 6  1.3 1a
> > > 7  1.3 1a
> > > 8  2.3 2a
> > > 9  1.5 1b
> > > 10 2.0  2
> > > 11 1.7 1c
> > > 12 2.3 2a
> > > 13 2.3 2a
> > > 14 1.0  1
> > > 15 1.3 1a
> > > 16 1.5 1b
> > > 17 2.7 2c
> > > 18 2.0  2
> > > 19 1.5 1b
> > > 20 1.5 1b
> > >
> > > I hope this helps,
> > >  John
> > >
> > >   -----------------------------
> > >   John Fox, Professor Emeritus
> > >   McMaster University
> > >   Hamilton, Ontario, Canada
> > >   Web: http::/socserv.mcmaster.ca/jfox
> > >
> > > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com>
> > > wrote:
> > > >
> > > > Dear All
> > > >
> > > > I have a character vector,  representing histology stages, such as
> for
> > > example:
> > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > >
> > > > and this goes on to 3, 3a etc in various order for each patient. I do
> > > have of course a pre-established  classification available which does
> > > change according to the histology criteria under assessment.
> > > >
> > > > I would want to convert xc, for plotting reasons, to a numeric vector
> > > such as
> > > >
> > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > >
> > > > Unfortunately I have no clue on how to do that.
> > > >
> > > > Thanks for any help and apologies if I am missing the obvious way to
> do
> > > it.
> > > >
> > > > JL
> > > > --
> > > > Verif30042020
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >
> > >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > > PLEASE do read the posting guide
> > >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >
> > >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > PLEASE do read the posting guide
> > >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From @b|tbo| @end|ng |rom @ent@com  Fri Jul 10 22:19:05 2020
From: @b|tbo| @end|ng |rom @ent@com (Jean-Louis Abitbol)
Date: Fri, 10 Jul 2020 22:19:05 +0200
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
Message-ID: <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>

Many thanks to all. This help-list is wonderful.

I have used Rich Heiberger solution using match and found something to learn in each answer. 

off topic, I also enjoyed very much his 2008 paper on the graphical presentation of safety data....

Best wishes.


On Fri, Jul 10, 2020, at 10:02 PM, Fox, John wrote:
> Hi,
> 
> We've had several solutions, and I was curious about their relative 
> efficiency. Here's a test with a moderately large data vector:
> 
> > library("microbenchmark")
> > set.seed(123) # for reproducibility
> > x <- sample(xc, 1e4, replace=TRUE) # "data"
> > microbenchmark(John = John <- xn[x], 
> +                Rich = Rich <- xn[match(x, xc)], 
> +                Jeff = Jeff <- {
> +                 n <- as.integer( sub( "[a-i]$", "", x ) )
> +                 d <- match( sub( "^\\d+", "", x ), letters[1:9] )
> +                 d[ is.na( d ) ] <- 0
> +                 n + d / 10
> +                 },
> +                David = David <- as.numeric(gsub("a", ".3", 
> +                                      gsub("b", ".5", 
> +                                           gsub("c", ".7", x)))),
> +                times=1000L
> +                )
> Unit: microseconds
>   expr       min        lq       mean     median         uq       max neval cld
>   John   228.816   345.371   513.5614   503.5965   533.0635  10829.08  1000 a  
>   Rich   217.395   343.035   534.2074   489.0075   518.3260  15388.96  1000 a  
>   Jeff 10325.471 13070.737 15387.2545 15397.9790 17204.0115 153486.94  1000  b 
>  David 14256.673 18148.492 20185.7156 20170.3635 22067.6690  34998.95  1000   c
> > all.equal(John, Rich)
> [1] TRUE
> > all.equal(John, David)
> [1] "names for target but not for current"
> > all.equal(John, Jeff)
> [1] "names for target but not for current" "Mean relative difference: 
> 0.1498243" 
> 
> Of course, efficiency isn't the only consideration, and aesthetically 
> (and no doubt subjectively) I prefer Rich Heiberger's solution. OTOH, 
> Jeff's solution is more general in that it generates the correspondence 
> between letters and numbers. The argument for Jeff's solution would, 
> however, be stronger if it gave the desired answer.
> 
> Best,
>  John
> 
> > On Jul 10, 2020, at 3:28 PM, David Carlson <dcarlson at tamu.edu> wrote:
> > 
> > Here is a different approach:
> > 
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> > xn
> > # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> > 
> > David L Carlson
> > Professor Emeritus of Anthropology
> > Texas A&M University
> > 
> > On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> > Dear Jean-Louis,
> > 
> > There must be many ways to do this. Here's one simple way (with no claim of optimality!):
> > 
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > 
> > > set.seed(123) # for reproducibility
> > > x <- sample(xc, 20, replace=TRUE) # "data"
> > > 
> > > names(xn) <- xc
> > > z <- xn[x]
> > > 
> > > data.frame(z, x)
> >      z  x
> > 1  2.5 2b
> > 2  2.5 2b
> > 3  1.5 1b
> > 4  2.3 2a
> > 5  1.5 1b
> > 6  1.3 1a
> > 7  1.3 1a
> > 8  2.3 2a
> > 9  1.5 1b
> > 10 2.0  2
> > 11 1.7 1c
> > 12 2.3 2a
> > 13 2.3 2a
> > 14 1.0  1
> > 15 1.3 1a
> > 16 1.5 1b
> > 17 2.7 2c
> > 18 2.0  2
> > 19 1.5 1b
> > 20 1.5 1b
> > 
> > I hope this helps,
> >  John
> > 
> >   -----------------------------
> >   John Fox, Professor Emeritus
> >   McMaster University
> >   Hamilton, Ontario, Canada
> >   Web: http::/socserv.mcmaster.ca/jfox
> > 
> > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com> wrote:
> > > 
> > > Dear All
> > > 
> > > I have a character vector,  representing histology stages, such as for example:
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > 
> > > and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
> > > 
> > > I would want to convert xc, for plotting reasons, to a numeric vector such as
> > > 
> > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > 
> > > Unfortunately I have no clue on how to do that.
> > > 
> > > Thanks for any help and apologies if I am missing the obvious way to do it.
> > > 
> > > JL
> > > -- 
> > > Verif30042020
> > > 
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$ 
> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$ 
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$ 
> > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$ 
> > and provide commented, minimal, self-contained, reproducible code.
> 
>

-- 
Verif30042020


From @purd|e@@ @end|ng |rom gm@||@com  Sat Jul 11 03:31:51 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 11 Jul 2020 13:31:51 +1200
Subject: [R] Bivariate ReLU Distribution
In-Reply-To: <1398793978.9432149.1594380973005@mail.yahoo.com>
References: <1398793978.9432149.1594380973005.ref@mail.yahoo.com>
 <1398793978.9432149.1594380973005@mail.yahoo.com>
Message-ID: <CAB8pepxi3u3CGp-1BDk0KBqr+pod9MMSFK_CndbDUohFjqJtMA@mail.gmail.com>

NOTE: LIMITED TESTING
(You may want to check this carefully, if you're interested in using it).

library (kubik)
library (mvtnorm)

sim.cdf <- function (mx, my, sdx, sdy, cor, ..., n=2e5)
    sim.cdf.2 (mx, my, sdx^2, sdy^2, sdx * sdy * cor, n=n)

sim.cdf.2 <- function (mx, my, vx, vy, cov, ..., n=2e5)
{   m <- c (mx, my)
    v <- matrix (c (vx, cov, cov, vy), 2, 2)
    u <- rmvnorm (2 * n, m, v)
    for (i in 1:(2 * n) )
        u [i] <- max (0, u [i])
    z <- u [1:n] + u [(n + 1):(2 * n)]

    P0 <- sum (z == 0) / n

    z2 <- z [z != 0]
    z2 <- c (-z2, z2)
    de <- density (z2)
    xFh <- chs.integral (de$x, de$y)

    cx <- seq (0, max (de$x), length.out=60)
    cy <- xFh (cx)
    cy <- cy - cy [1]
    cy <- P0 + cy * (1 - P0) / cy [60]

    cs = chs.constraints (increasing=TRUE)
    chs (cx, cy, constraints=cs, outside = c (0, cy [60]) )
}

#X1, X2 means: 0 and 2
#X1, Y2 sds: 1.5 and 3.5
#cor (X1, X2): 0.75
Fh <- sim.cdf (0, 2, 1.5, 3.5, 0.75)

plot (Fh, ylim = c (0, 1.05), yaxs="i")

#prob 1 < U < 2
Fh (2) - Fh (1)


On Sat, Jul 11, 2020 at 1:49 AM Arun Kumar Saha via R-help
<r-help at r-project.org> wrote:
>
> Hi,
> I would rather have a Statistics related question hope experts here can provide some suggestions. I have posted this request in some other forum but failed to generate meaningful response
> I am looking for some technical document on deriving the Distribution function for sum of 2 ReLU(?)=max{0,?} distributions i.e max{0,?1} + max{0,?2} where X1 and X2 jointly follow some bivariate Nomal distribution.
> There are few technical notes available for univariate ReLU distribution, however I failed to find any spec for bivariate/multivariate setup.
> Any pointer on above subject will be highly helpful.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Sat Jul 11 03:37:35 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 11 Jul 2020 13:37:35 +1200
Subject: [R] Bivariate ReLU Distribution
In-Reply-To: <CAB8pepxi3u3CGp-1BDk0KBqr+pod9MMSFK_CndbDUohFjqJtMA@mail.gmail.com>
References: <1398793978.9432149.1594380973005.ref@mail.yahoo.com>
 <1398793978.9432149.1594380973005@mail.yahoo.com>
 <CAB8pepxi3u3CGp-1BDk0KBqr+pod9MMSFK_CndbDUohFjqJtMA@mail.gmail.com>
Message-ID: <CAB8pepyfdqjrUR=MEPEeD1+LCnjEsv=X2iNrpJUo=uWPvCpN0Q@mail.gmail.com>

Last line should use outside = c (0, 1).
But not that important.

On Sat, Jul 11, 2020 at 1:31 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> NOTE: LIMITED TESTING
> (You may want to check this carefully, if you're interested in using it).
>
> library (kubik)
> library (mvtnorm)
>
> sim.cdf <- function (mx, my, sdx, sdy, cor, ..., n=2e5)
>     sim.cdf.2 (mx, my, sdx^2, sdy^2, sdx * sdy * cor, n=n)
>
> sim.cdf.2 <- function (mx, my, vx, vy, cov, ..., n=2e5)
> {   m <- c (mx, my)
>     v <- matrix (c (vx, cov, cov, vy), 2, 2)
>     u <- rmvnorm (2 * n, m, v)
>     for (i in 1:(2 * n) )
>         u [i] <- max (0, u [i])
>     z <- u [1:n] + u [(n + 1):(2 * n)]
>
>     P0 <- sum (z == 0) / n
>
>     z2 <- z [z != 0]
>     z2 <- c (-z2, z2)
>     de <- density (z2)
>     xFh <- chs.integral (de$x, de$y)
>
>     cx <- seq (0, max (de$x), length.out=60)
>     cy <- xFh (cx)
>     cy <- cy - cy [1]
>     cy <- P0 + cy * (1 - P0) / cy [60]
>
>     cs = chs.constraints (increasing=TRUE)
>     chs (cx, cy, constraints=cs, outside = c (0, cy [60]) )
> }
>
> #X1, X2 means: 0 and 2
> #X1, Y2 sds: 1.5 and 3.5
> #cor (X1, X2): 0.75
> Fh <- sim.cdf (0, 2, 1.5, 3.5, 0.75)
>
> plot (Fh, ylim = c (0, 1.05), yaxs="i")
>
> #prob 1 < U < 2
> Fh (2) - Fh (1)
>
>
> On Sat, Jul 11, 2020 at 1:49 AM Arun Kumar Saha via R-help
> <r-help at r-project.org> wrote:
> >
> > Hi,
> > I would rather have a Statistics related question hope experts here can provide some suggestions. I have posted this request in some other forum but failed to generate meaningful response
> > I am looking for some technical document on deriving the Distribution function for sum of 2 ReLU(?)=max{0,?} distributions i.e max{0,?1} + max{0,?2} where X1 and X2 jointly follow some bivariate Nomal distribution.
> > There are few technical notes available for univariate ReLU distribution, however I failed to find any spec for bivariate/multivariate setup.
> > Any pointer on above subject will be highly helpful.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sat Jul 11 04:08:37 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 11 Jul 2020 14:08:37 +1200
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
Message-ID: <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>

This can be done very simply because vectors in R can have
named elements, and can be indexed by strings.

> stage <- c("1" = 1, "1a" = 1.3, "1b" = 1.5, "1c" = 1.7,
+            "2" = 2, "2a" = 2.3, "2b" = 2.5, "2c" = 2.7,
+            "3" = 3, "3a" = 3.3, "3b" = 3.5, "3c" = 3.7)

> testdata <- rep(c("1", "1a", "1b", "1c",
+                   "2", "2a", "2b", "2c",
+                   "3", "3a", "3b", "3c"), times=c(1:6,6:1))

> stage[testdata]
  1  1a  1a  1b  1b  1b  1c  1c  1c  1c   2   2   2   2   2  2a  2a  2a  2a
 2a
1.0 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 1.7 2.0 2.0 2.0 2.0 2.0 2.3 2.3 2.3 2.3
2.3
 2a  2b  2b  2b  2b  2b  2b  2c  2c  2c  2c  2c   3   3   3   3  3a  3a  3a
 3b
2.3 2.5 2.5 2.5 2.5 2.5 2.5 2.7 2.7 2.7 2.7 2.7 3.0 3.0 3.0 3.0 3.3 3.3 3.3
3.5
 3b  3c
3.5 3.7

On Sat, 11 Jul 2020 at 05:51, Jean-Louis Abitbol <abitbol at sent.com> wrote:

> Dear All
>
> I have a character vector,  representing histology stages, such as for
> example:
> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>
> and this goes on to 3, 3a etc in various order for each patient. I do have
> of course a pre-established  classification available which does change
> according to the histology criteria under assessment.
>
> I would want to convert xc, for plotting reasons, to a numeric vector such
> as
>
> xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
>
> Unfortunately I have no clue on how to do that.
>
> Thanks for any help and apologies if I am missing the obvious way to do it.
>
> JL
> --
> Verif30042020
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Jul 11 06:09:51 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 11 Jul 2020 14:09:51 +1000
Subject: [R] How to differ stats_cor labels by group on a ggplot
In-Reply-To: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>
References: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>
Message-ID: <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>

Hi Paulina,
Without data it's hard to work out what you are doing. Even a small
simulated data set would help to get answers.

Jim

On Fri, Jul 10, 2020 at 11:49 PM Paulina Skolasinska
<paulina.skol at hotmail.com> wrote:
>
> 'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.
>
> I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW
>
> > for (i in 18:21) {
>   p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
>     geom_smooth(method="lm") +
>     geom_point(size = 4) +
>     geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
>     scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) +
>     stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
>     stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black",
>                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
>
>   ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
> }
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Sat Jul 11 07:16:25 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 11 Jul 2020 08:16:25 +0300
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>
Message-ID: <CAGgJW74QdODbH0gUcAa2qrKePwk54ugrRgtab64kWXYvhHqjEw@mail.gmail.com>

xn <- as.numeric(sub("c",".7",sub("b",".5",sub("a",".3",xc))))


On Sat, Jul 11, 2020 at 5:09 AM Richard O'Keefe <raoknz at gmail.com> wrote:

> This can be done very simply because vectors in R can have
> named elements, and can be indexed by strings.
>
> > stage <- c("1" = 1, "1a" = 1.3, "1b" = 1.5, "1c" = 1.7,
> +            "2" = 2, "2a" = 2.3, "2b" = 2.5, "2c" = 2.7,
> +            "3" = 3, "3a" = 3.3, "3b" = 3.5, "3c" = 3.7)
>
> > testdata <- rep(c("1", "1a", "1b", "1c",
> +                   "2", "2a", "2b", "2c",
> +                   "3", "3a", "3b", "3c"), times=c(1:6,6:1))
>
> > stage[testdata]
>   1  1a  1a  1b  1b  1b  1c  1c  1c  1c   2   2   2   2   2  2a  2a  2a  2a
>  2a
> 1.0 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 1.7 2.0 2.0 2.0 2.0 2.0 2.3 2.3 2.3 2.3
> 2.3
>  2a  2b  2b  2b  2b  2b  2b  2c  2c  2c  2c  2c   3   3   3   3  3a  3a  3a
>  3b
> 2.3 2.5 2.5 2.5 2.5 2.5 2.5 2.7 2.7 2.7 2.7 2.7 3.0 3.0 3.0 3.0 3.3 3.3 3.3
> 3.5
>  3b  3c
> 3.5 3.7
>
> On Sat, 11 Jul 2020 at 05:51, Jean-Louis Abitbol <abitbol at sent.com> wrote:
>
> > Dear All
> >
> > I have a character vector,  representing histology stages, such as for
> > example:
> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> >
> > and this goes on to 3, 3a etc in various order for each patient. I do
> have
> > of course a pre-established  classification available which does change
> > according to the histology criteria under assessment.
> >
> > I would want to convert xc, for plotting reasons, to a numeric vector
> such
> > as
> >
> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> >
> > Unfortunately I have no clue on how to do that.
> >
> > Thanks for any help and apologies if I am missing the obvious way to do
> it.
> >
> > JL
> > --
> > Verif30042020
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Sat Jul 11 08:25:03 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Fri, 10 Jul 2020 23:25:03 -0700
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
 <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>
Message-ID: <CAA99HCx+jvO=4==1fZCR0gyp-+59PfJOMOwZ7mwFwoPHLKyudA@mail.gmail.com>

Hello Jean-Louis,

Noting the subject line of your post I thought the first answer would
have been encoding histology stages as factors, and "unclass-ing" them
to obtain integers that then can be mathematically manipulated. You
can get a lot of work done with all the commands listed on the
"factor" help page:

?factor
samples <- 1:36
values <- runif(length(samples), min=1, max=length(samples))
hist <- rep(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), times=1:8)
data1 <- data.frame("samples" = samples, "values" = values, "hist" = hist )
(data1$hist <- factor(data1$hist, levels=c("1", "1a", "1b", "1c", "2",
"2a", "2b", "2c")) )
unclass(data1$hist)

library(RColorBrewer); pal_1 <- brewer.pal(8, "Pastel2")
barplot(data1$value, beside=T, col=pal_1[data1$hist])
plot(data1$hist, data1$value, col=pal_1)
pal_2 <- brewer.pal(8, "Dark2")
plot(unclass(data1$hist)/4, data1$value, pch=19, col=pal_2[data1$hist] )
group <- c(rep(0,10),rep(1,26)); data1$group <- group
library(lattice); dotplot(hist ~ values | group, data=data1, xlim=c(0,36) )

HTH, Bill.

W. Michels, Ph.D.




On Fri, Jul 10, 2020 at 1:41 PM Jean-Louis Abitbol <abitbol at sent.com> wrote:
>
> Many thanks to all. This help-list is wonderful.
>
> I have used Rich Heiberger solution using match and found something to learn in each answer.
>
> off topic, I also enjoyed very much his 2008 paper on the graphical presentation of safety data....
>
> Best wishes.
>
>
> On Fri, Jul 10, 2020, at 10:02 PM, Fox, John wrote:
> > Hi,
> >
> > We've had several solutions, and I was curious about their relative
> > efficiency. Here's a test with a moderately large data vector:
> >
> > > library("microbenchmark")
> > > set.seed(123) # for reproducibility
> > > x <- sample(xc, 1e4, replace=TRUE) # "data"
> > > microbenchmark(John = John <- xn[x],
> > +                Rich = Rich <- xn[match(x, xc)],
> > +                Jeff = Jeff <- {
> > +                 n <- as.integer( sub( "[a-i]$", "", x ) )
> > +                 d <- match( sub( "^\\d+", "", x ), letters[1:9] )
> > +                 d[ is.na( d ) ] <- 0
> > +                 n + d / 10
> > +                 },
> > +                David = David <- as.numeric(gsub("a", ".3",
> > +                                      gsub("b", ".5",
> > +                                           gsub("c", ".7", x)))),
> > +                times=1000L
> > +                )
> > Unit: microseconds
> >   expr       min        lq       mean     median         uq       max neval cld
> >   John   228.816   345.371   513.5614   503.5965   533.0635  10829.08  1000 a
> >   Rich   217.395   343.035   534.2074   489.0075   518.3260  15388.96  1000 a
> >   Jeff 10325.471 13070.737 15387.2545 15397.9790 17204.0115 153486.94  1000  b
> >  David 14256.673 18148.492 20185.7156 20170.3635 22067.6690  34998.95  1000   c
> > > all.equal(John, Rich)
> > [1] TRUE
> > > all.equal(John, David)
> > [1] "names for target but not for current"
> > > all.equal(John, Jeff)
> > [1] "names for target but not for current" "Mean relative difference:
> > 0.1498243"
> >
> > Of course, efficiency isn't the only consideration, and aesthetically
> > (and no doubt subjectively) I prefer Rich Heiberger's solution. OTOH,
> > Jeff's solution is more general in that it generates the correspondence
> > between letters and numbers. The argument for Jeff's solution would,
> > however, be stronger if it gave the desired answer.
> >
> > Best,
> >  John
> >
> > > On Jul 10, 2020, at 3:28 PM, David Carlson <dcarlson at tamu.edu> wrote:
> > >
> > > Here is a different approach:
> > >
> > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> > > xn
> > > # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> > >
> > > David L Carlson
> > > Professor Emeritus of Anthropology
> > > Texas A&M University
> > >
> > > On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> > > Dear Jean-Louis,
> > >
> > > There must be many ways to do this. Here's one simple way (with no claim of optimality!):
> > >
> > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > >
> > > > set.seed(123) # for reproducibility
> > > > x <- sample(xc, 20, replace=TRUE) # "data"
> > > >
> > > > names(xn) <- xc
> > > > z <- xn[x]
> > > >
> > > > data.frame(z, x)
> > >      z  x
> > > 1  2.5 2b
> > > 2  2.5 2b
> > > 3  1.5 1b
> > > 4  2.3 2a
> > > 5  1.5 1b
> > > 6  1.3 1a
> > > 7  1.3 1a
> > > 8  2.3 2a
> > > 9  1.5 1b
> > > 10 2.0  2
> > > 11 1.7 1c
> > > 12 2.3 2a
> > > 13 2.3 2a
> > > 14 1.0  1
> > > 15 1.3 1a
> > > 16 1.5 1b
> > > 17 2.7 2c
> > > 18 2.0  2
> > > 19 1.5 1b
> > > 20 1.5 1b
> > >
> > > I hope this helps,
> > >  John
> > >
> > >   -----------------------------
> > >   John Fox, Professor Emeritus
> > >   McMaster University
> > >   Hamilton, Ontario, Canada
> > >   Web: http::/socserv.mcmaster.ca/jfox
> > >
> > > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com> wrote:
> > > >
> > > > Dear All
> > > >
> > > > I have a character vector,  representing histology stages, such as for example:
> > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > >
> > > > and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
> > > >
> > > > I would want to convert xc, for plotting reasons, to a numeric vector such as
> > > >
> > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > >
> > > > Unfortunately I have no clue on how to do that.
> > > >
> > > > Thanks for any help and apologies if I am missing the obvious way to do it.
> > > >
> > > > JL
> > > > --
> > > > Verif30042020
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
> --
> Verif30042020
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@oknz @end|ng |rom gm@||@com  Sat Jul 11 09:02:11 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 11 Jul 2020 19:02:11 +1200
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CAGgJW74QdODbH0gUcAa2qrKePwk54ugrRgtab64kWXYvhHqjEw@mail.gmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>
 <CAGgJW74QdODbH0gUcAa2qrKePwk54ugrRgtab64kWXYvhHqjEw@mail.gmail.com>
Message-ID: <CABcYAdLjywLozR7hn_JTBnx=WyAxuMHJ5HHtwdOUVtjTjeye8w@mail.gmail.com>

The string index approach works with any mapping from stage names
to stage numbers, not just regular ones.  For example, if we had
"1" -> 1, "1a" -> 1.4, "1b" -> 1.6
"2" -> 2, "2a" -> 2.3, "2b" -> 2.7
the 'sub' version would fail miserably while the string index
version would just work.  The 'sub' version would also not work
terribly well if the mapping were
"1" -> 1, "a1" -> 1.3, "b1" -> 1.5, "c1" -> 1.7
and so on. The thing I like about the indexing approach is that
it uses a fundamental operation of the language very directly.

Anyone using R would do well to *master* what indexing can do
for you.


On Sat, 11 Jul 2020 at 17:16, Eric Berger <ericjberger at gmail.com> wrote:

> xn <- as.numeric(sub("c",".7",sub("b",".5",sub("a",".3",xc))))
>
>
> On Sat, Jul 11, 2020 at 5:09 AM Richard O'Keefe <raoknz at gmail.com> wrote:
>
>> This can be done very simply because vectors in R can have
>> named elements, and can be indexed by strings.
>>
>> > stage <- c("1" = 1, "1a" = 1.3, "1b" = 1.5, "1c" = 1.7,
>> +            "2" = 2, "2a" = 2.3, "2b" = 2.5, "2c" = 2.7,
>> +            "3" = 3, "3a" = 3.3, "3b" = 3.5, "3c" = 3.7)
>>
>> > testdata <- rep(c("1", "1a", "1b", "1c",
>> +                   "2", "2a", "2b", "2c",
>> +                   "3", "3a", "3b", "3c"), times=c(1:6,6:1))
>>
>> > stage[testdata]
>>   1  1a  1a  1b  1b  1b  1c  1c  1c  1c   2   2   2   2   2  2a  2a  2a
>> 2a
>>  2a
>> 1.0 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 1.7 2.0 2.0 2.0 2.0 2.0 2.3 2.3 2.3
>> 2.3
>> 2.3
>>  2a  2b  2b  2b  2b  2b  2b  2c  2c  2c  2c  2c   3   3   3   3  3a  3a
>> 3a
>>  3b
>> 2.3 2.5 2.5 2.5 2.5 2.5 2.5 2.7 2.7 2.7 2.7 2.7 3.0 3.0 3.0 3.0 3.3 3.3
>> 3.3
>> 3.5
>>  3b  3c
>> 3.5 3.7
>>
>> On Sat, 11 Jul 2020 at 05:51, Jean-Louis Abitbol <abitbol at sent.com>
>> wrote:
>>
>> > Dear All
>> >
>> > I have a character vector,  representing histology stages, such as for
>> > example:
>> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>> >
>> > and this goes on to 3, 3a etc in various order for each patient. I do
>> have
>> > of course a pre-established  classification available which does change
>> > according to the histology criteria under assessment.
>> >
>> > I would want to convert xc, for plotting reasons, to a numeric vector
>> such
>> > as
>> >
>> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
>> >
>> > Unfortunately I have no clue on how to do that.
>> >
>> > Thanks for any help and apologies if I am missing the obvious way to do
>> it.
>> >
>> > JL
>> > --
>> > Verif30042020
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @b|tbo| @end|ng |rom @ent@com  Sat Jul 11 09:14:31 2020
From: @b|tbo| @end|ng |rom @ent@com (Jean-Louis Abitbol)
Date: Sat, 11 Jul 2020 09:14:31 +0200
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CAA99HCx+jvO=4==1fZCR0gyp-+59PfJOMOwZ7mwFwoPHLKyudA@mail.gmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
 <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>
 <CAA99HCx+jvO=4==1fZCR0gyp-+59PfJOMOwZ7mwFwoPHLKyudA@mail.gmail.com>
Message-ID: <ec3b35eb-a5b8-425c-8222-fa868068ce6c@www.fastmail.com>

Hello Bill,

Thanks.

That has indeed the advantage of keeping the histology classification on the  plot instead of some arbitrary numeric scale.

Best wishes, JL

On Sat, Jul 11, 2020, at 8:25 AM, William Michels wrote:
> Hello Jean-Louis,
> 
> Noting the subject line of your post I thought the first answer would
> have been encoding histology stages as factors, and "unclass-ing" them
> to obtain integers that then can be mathematically manipulated. You
> can get a lot of work done with all the commands listed on the
> "factor" help page:
> 
> ?factor
> samples <- 1:36
> values <- runif(length(samples), min=1, max=length(samples))
> hist <- rep(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), times=1:8)
> data1 <- data.frame("samples" = samples, "values" = values, "hist" = hist )
> (data1$hist <- factor(data1$hist, levels=c("1", "1a", "1b", "1c", "2",
> "2a", "2b", "2c")) )
> unclass(data1$hist)
> 
> library(RColorBrewer); pal_1 <- brewer.pal(8, "Pastel2")
> barplot(data1$value, beside=T, col=pal_1[data1$hist])
> plot(data1$hist, data1$value, col=pal_1)
> pal_2 <- brewer.pal(8, "Dark2")
> plot(unclass(data1$hist)/4, data1$value, pch=19, col=pal_2[data1$hist] )
> group <- c(rep(0,10),rep(1,26)); data1$group <- group
> library(lattice); dotplot(hist ~ values | group, data=data1, xlim=c(0,36) )
> 
> HTH, Bill.
> 
> W. Michels, Ph.D.
> 
> 
> 
> 
> On Fri, Jul 10, 2020 at 1:41 PM Jean-Louis Abitbol <abitbol at sent.com> wrote:
> >
> > Many thanks to all. This help-list is wonderful.
> >
> > I have used Rich Heiberger solution using match and found something to learn in each answer.
> >
> > off topic, I also enjoyed very much his 2008 paper on the graphical presentation of safety data....
> >
> > Best wishes.
> >
> >
> > On Fri, Jul 10, 2020, at 10:02 PM, Fox, John wrote:
> > > Hi,
> > >
> > > We've had several solutions, and I was curious about their relative
> > > efficiency. Here's a test with a moderately large data vector:
> > >
> > > > library("microbenchmark")
> > > > set.seed(123) # for reproducibility
> > > > x <- sample(xc, 1e4, replace=TRUE) # "data"
> > > > microbenchmark(John = John <- xn[x],
> > > +                Rich = Rich <- xn[match(x, xc)],
> > > +                Jeff = Jeff <- {
> > > +                 n <- as.integer( sub( "[a-i]$", "", x ) )
> > > +                 d <- match( sub( "^\\d+", "", x ), letters[1:9] )
> > > +                 d[ is.na( d ) ] <- 0
> > > +                 n + d / 10
> > > +                 },
> > > +                David = David <- as.numeric(gsub("a", ".3",
> > > +                                      gsub("b", ".5",
> > > +                                           gsub("c", ".7", x)))),
> > > +                times=1000L
> > > +                )
> > > Unit: microseconds
> > >   expr       min        lq       mean     median         uq       max neval cld
> > >   John   228.816   345.371   513.5614   503.5965   533.0635  10829.08  1000 a
> > >   Rich   217.395   343.035   534.2074   489.0075   518.3260  15388.96  1000 a
> > >   Jeff 10325.471 13070.737 15387.2545 15397.9790 17204.0115 153486.94  1000  b
> > >  David 14256.673 18148.492 20185.7156 20170.3635 22067.6690  34998.95  1000   c
> > > > all.equal(John, Rich)
> > > [1] TRUE
> > > > all.equal(John, David)
> > > [1] "names for target but not for current"
> > > > all.equal(John, Jeff)
> > > [1] "names for target but not for current" "Mean relative difference:
> > > 0.1498243"
> > >
> > > Of course, efficiency isn't the only consideration, and aesthetically
> > > (and no doubt subjectively) I prefer Rich Heiberger's solution. OTOH,
> > > Jeff's solution is more general in that it generates the correspondence
> > > between letters and numbers. The argument for Jeff's solution would,
> > > however, be stronger if it gave the desired answer.
> > >
> > > Best,
> > >  John
> > >
> > > > On Jul 10, 2020, at 3:28 PM, David Carlson <dcarlson at tamu.edu> wrote:
> > > >
> > > > Here is a different approach:
> > > >
> > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> > > > xn
> > > > # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> > > >
> > > > David L Carlson
> > > > Professor Emeritus of Anthropology
> > > > Texas A&M University
> > > >
> > > > On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> > > > Dear Jean-Louis,
> > > >
> > > > There must be many ways to do this. Here's one simple way (with no claim of optimality!):
> > > >
> > > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > > >
> > > > > set.seed(123) # for reproducibility
> > > > > x <- sample(xc, 20, replace=TRUE) # "data"
> > > > >
> > > > > names(xn) <- xc
> > > > > z <- xn[x]
> > > > >
> > > > > data.frame(z, x)
> > > >      z  x
> > > > 1  2.5 2b
> > > > 2  2.5 2b
> > > > 3  1.5 1b
> > > > 4  2.3 2a
> > > > 5  1.5 1b
> > > > 6  1.3 1a
> > > > 7  1.3 1a
> > > > 8  2.3 2a
> > > > 9  1.5 1b
> > > > 10 2.0  2
> > > > 11 1.7 1c
> > > > 12 2.3 2a
> > > > 13 2.3 2a
> > > > 14 1.0  1
> > > > 15 1.3 1a
> > > > 16 1.5 1b
> > > > 17 2.7 2c
> > > > 18 2.0  2
> > > > 19 1.5 1b
> > > > 20 1.5 1b
> > > >
> > > > I hope this helps,
> > > >  John
> > > >
> > > >   -----------------------------
> > > >   John Fox, Professor Emeritus
> > > >   McMaster University
> > > >   Hamilton, Ontario, Canada
> > > >   Web: http::/socserv.mcmaster.ca/jfox
> > > >
> > > > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com> wrote:
> > > > >
> > > > > Dear All
> > > > >
> > > > > I have a character vector,  representing histology stages, such as for example:
> > > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > >
> > > > > and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
> > > > >
> > > > > I would want to convert xc, for plotting reasons, to a numeric vector such as
> > > > >
> > > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > > >
> > > > > Unfortunately I have no clue on how to do that.
> > > > >
> > > > > Thanks for any help and apologies if I am missing the obvious way to do it.
> > > > >
> > > > > JL
> > > > > --
> > > > > Verif30042020
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> >
> > --
> > Verif30042020
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

-- 
Verif30042020


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Sat Jul 11 10:52:35 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Sat, 11 Jul 2020 01:52:35 -0700
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <ec3b35eb-a5b8-425c-8222-fa868068ce6c@www.fastmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
 <021bb81d-fc58-4af9-92c3-f5e6ce87a844@www.fastmail.com>
 <CAA99HCx+jvO=4==1fZCR0gyp-+59PfJOMOwZ7mwFwoPHLKyudA@mail.gmail.com>
 <ec3b35eb-a5b8-425c-8222-fa868068ce6c@www.fastmail.com>
Message-ID: <CAA99HCydSj0FmT9=zdVfOaA6Jbk54sOir6G0z7iFw1fBr2pqgw@mail.gmail.com>

Agreed, I meant to add this line (for unclassed factor levels 1-through-8):

> ((1:8 - 1)*(0.25))+1
[1] 1.00 1.25 1.50 1.75 2.00 2.25 2.50 2.75

Depending on the circumstance, you can also consider using dummy
factors or even "NA" as a level; see the "factor" help page for
details.

Best, Bill.

W. Michels, Ph.D.



On Sat, Jul 11, 2020 at 12:16 AM Jean-Louis Abitbol <abitbol at sent.com> wrote:
>
> Hello Bill,
>
> Thanks.
>
> That has indeed the advantage of keeping the histology classification on the  plot instead of some arbitrary numeric scale.
>
> Best wishes, JL
>
> On Sat, Jul 11, 2020, at 8:25 AM, William Michels wrote:
> > Hello Jean-Louis,
> >
> > Noting the subject line of your post I thought the first answer would
> > have been encoding histology stages as factors, and "unclass-ing" them
> > to obtain integers that then can be mathematically manipulated. You
> > can get a lot of work done with all the commands listed on the
> > "factor" help page:
> >
> > ?factor
> > samples <- 1:36
> > values <- runif(length(samples), min=1, max=length(samples))
> > hist <- rep(c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c"), times=1:8)
> > data1 <- data.frame("samples" = samples, "values" = values, "hist" = hist )
> > (data1$hist <- factor(data1$hist, levels=c("1", "1a", "1b", "1c", "2",
> > "2a", "2b", "2c")) )
> > unclass(data1$hist)
> >
> > library(RColorBrewer); pal_1 <- brewer.pal(8, "Pastel2")
> > barplot(data1$value, beside=T, col=pal_1[data1$hist])
> > plot(data1$hist, data1$value, col=pal_1)
> > pal_2 <- brewer.pal(8, "Dark2")
> > plot(unclass(data1$hist)/4, data1$value, pch=19, col=pal_2[data1$hist] )
> > group <- c(rep(0,10),rep(1,26)); data1$group <- group
> > library(lattice); dotplot(hist ~ values | group, data=data1, xlim=c(0,36) )
> >
> > HTH, Bill.
> >
> > W. Michels, Ph.D.
> >
> >
> >
> >
> > On Fri, Jul 10, 2020 at 1:41 PM Jean-Louis Abitbol <abitbol at sent.com> wrote:
> > >
> > > Many thanks to all. This help-list is wonderful.
> > >
> > > I have used Rich Heiberger solution using match and found something to learn in each answer.
> > >
> > > off topic, I also enjoyed very much his 2008 paper on the graphical presentation of safety data....
> > >
> > > Best wishes.
> > >
> > >
> > > On Fri, Jul 10, 2020, at 10:02 PM, Fox, John wrote:
> > > > Hi,
> > > >
> > > > We've had several solutions, and I was curious about their relative
> > > > efficiency. Here's a test with a moderately large data vector:
> > > >
> > > > > library("microbenchmark")
> > > > > set.seed(123) # for reproducibility
> > > > > x <- sample(xc, 1e4, replace=TRUE) # "data"
> > > > > microbenchmark(John = John <- xn[x],
> > > > +                Rich = Rich <- xn[match(x, xc)],
> > > > +                Jeff = Jeff <- {
> > > > +                 n <- as.integer( sub( "[a-i]$", "", x ) )
> > > > +                 d <- match( sub( "^\\d+", "", x ), letters[1:9] )
> > > > +                 d[ is.na( d ) ] <- 0
> > > > +                 n + d / 10
> > > > +                 },
> > > > +                David = David <- as.numeric(gsub("a", ".3",
> > > > +                                      gsub("b", ".5",
> > > > +                                           gsub("c", ".7", x)))),
> > > > +                times=1000L
> > > > +                )
> > > > Unit: microseconds
> > > >   expr       min        lq       mean     median         uq       max neval cld
> > > >   John   228.816   345.371   513.5614   503.5965   533.0635  10829.08  1000 a
> > > >   Rich   217.395   343.035   534.2074   489.0075   518.3260  15388.96  1000 a
> > > >   Jeff 10325.471 13070.737 15387.2545 15397.9790 17204.0115 153486.94  1000  b
> > > >  David 14256.673 18148.492 20185.7156 20170.3635 22067.6690  34998.95  1000   c
> > > > > all.equal(John, Rich)
> > > > [1] TRUE
> > > > > all.equal(John, David)
> > > > [1] "names for target but not for current"
> > > > > all.equal(John, Jeff)
> > > > [1] "names for target but not for current" "Mean relative difference:
> > > > 0.1498243"
> > > >
> > > > Of course, efficiency isn't the only consideration, and aesthetically
> > > > (and no doubt subjectively) I prefer Rich Heiberger's solution. OTOH,
> > > > Jeff's solution is more general in that it generates the correspondence
> > > > between letters and numbers. The argument for Jeff's solution would,
> > > > however, be stronger if it gave the desired answer.
> > > >
> > > > Best,
> > > >  John
> > > >
> > > > > On Jul 10, 2020, at 3:28 PM, David Carlson <dcarlson at tamu.edu> wrote:
> > > > >
> > > > > Here is a different approach:
> > > > >
> > > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > > xn <- as.numeric(gsub("a", ".3", gsub("b", ".5", gsub("c", ".7", xc))))
> > > > > xn
> > > > > # [1] 1.0 1.3 1.5 1.7 2.0 2.3 2.5 2.7
> > > > >
> > > > > David L Carlson
> > > > > Professor Emeritus of Anthropology
> > > > > Texas A&M University
> > > > >
> > > > > On Fri, Jul 10, 2020 at 1:10 PM Fox, John <jfox at mcmaster.ca> wrote:
> > > > > Dear Jean-Louis,
> > > > >
> > > > > There must be many ways to do this. Here's one simple way (with no claim of optimality!):
> > > > >
> > > > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > > > >
> > > > > > set.seed(123) # for reproducibility
> > > > > > x <- sample(xc, 20, replace=TRUE) # "data"
> > > > > >
> > > > > > names(xn) <- xc
> > > > > > z <- xn[x]
> > > > > >
> > > > > > data.frame(z, x)
> > > > >      z  x
> > > > > 1  2.5 2b
> > > > > 2  2.5 2b
> > > > > 3  1.5 1b
> > > > > 4  2.3 2a
> > > > > 5  1.5 1b
> > > > > 6  1.3 1a
> > > > > 7  1.3 1a
> > > > > 8  2.3 2a
> > > > > 9  1.5 1b
> > > > > 10 2.0  2
> > > > > 11 1.7 1c
> > > > > 12 2.3 2a
> > > > > 13 2.3 2a
> > > > > 14 1.0  1
> > > > > 15 1.3 1a
> > > > > 16 1.5 1b
> > > > > 17 2.7 2c
> > > > > 18 2.0  2
> > > > > 19 1.5 1b
> > > > > 20 1.5 1b
> > > > >
> > > > > I hope this helps,
> > > > >  John
> > > > >
> > > > >   -----------------------------
> > > > >   John Fox, Professor Emeritus
> > > > >   McMaster University
> > > > >   Hamilton, Ontario, Canada
> > > > >   Web: http::/socserv.mcmaster.ca/jfox
> > > > >
> > > > > > On Jul 10, 2020, at 1:50 PM, Jean-Louis Abitbol <abitbol at sent.com> wrote:
> > > > > >
> > > > > > Dear All
> > > > > >
> > > > > > I have a character vector,  representing histology stages, such as for example:
> > > > > > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
> > > > > >
> > > > > > and this goes on to 3, 3a etc in various order for each patient. I do have of course a pre-established  classification available which does change according to the histology criteria under assessment.
> > > > > >
> > > > > > I would want to convert xc, for plotting reasons, to a numeric vector such as
> > > > > >
> > > > > > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
> > > > > >
> > > > > > Unfortunately I have no clue on how to do that.
> > > > > >
> > > > > > Thanks for any help and apologies if I am missing the obvious way to do it.
> > > > > >
> > > > > > JL
> > > > > > --
> > > > > > Verif30042020
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > > > > and provide commented, minimal, self-contained, reproducible code.
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcU3rSW6I$
> > > > > PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!V7p9rtNSgBWmF3KJ3U_01fR7vP_I7y-OnWHiTFxwRZ6bVJ3-emOwkBtcg7nzsmk$
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > >
> > >
> > > --
> > > Verif30042020
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Verif30042020


From p@u||n@@@ko| @end|ng |rom hotm@||@com  Sat Jul 11 16:09:00 2020
From: p@u||n@@@ko| @end|ng |rom hotm@||@com (Paulina Skolasinska)
Date: Sat, 11 Jul 2020 14:09:00 +0000
Subject: [R] ODP:  How to differ stats_cor labels by group on a ggplot
In-Reply-To: <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>
References: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>,
 <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>
Message-ID: <SN2PR03MB2190440F30A01F050243549A94620@SN2PR03MB2190.namprd03.prod.outlook.com>

Thanks Tim, here is the link to the data: https://we.tl/t-c4x9Lw7LeR
I'm posting my code again so it better matches the modified data, and because I've added several improvements in the meantime.

for (i in 3:6) {
    p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
        geom_smooth(method="lm") +
        geom_point(size = 4) +
        scale_x_continuous(breaks = seq(20,90, by=10)) +
        scale_y_continuous(breaks = seq(0.1,0.5, by=0.1)) +
        theme_classic() +
        expand_limits(y = 0.5) +
        ylab(names(df)[i]) +
        theme(axis.text.x = element_text(face="bold", size=14),
              axis.text.y = element_text(face="bold", size=14),
              axis.title.x = element_text(size=14, face="bold"),
              axis.title.y = element_text(size=14, face="bold"),
              legend.title = element_text(color="black", size=12),
              legend.text = element_text(colour="black", size = 14, face = "bold")) +
        geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
        scale_colour_discrete(name="Group", labels=c("Young", "Old", "Overall")) +
        stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i])),
                 method = "pearson", label.x.npc = c("center"), label.y.npc="top") +
        stat_cor(aes(x = Age, y = unlist(df[i]),
                 label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~"),
                 group=1, color="black"), method = "pearson",label.y=0.5, label.x.npc = c("center"),
                 position = position_nudge(y = 0.015 * 0.5))

    ggsave(p1, file=paste0("TestAge_", names(df)[i], ".png"), scale=1, width=16, height=10, units="cm")
}


________________________________
Od: Jim Lemon <drjimlemon at gmail.com>
Wys?ane: sobota, 11 lipca 2020 04:09
Do: Paulina Skolasinska <paulina.skol at hotmail.com>
DW: r-help at r-project.org <r-help at r-project.org>
Temat: Re: [R] How to differ stats_cor labels by group on a ggplot

Hi Paulina,
Without data it's hard to work out what you are doing. Even a small
simulated data set would help to get answers.

Jim

On Fri, Jul 10, 2020 at 11:49 PM Paulina Skolasinska
<paulina.skol at hotmail.com> wrote:
>
> 'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.
>
> I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW
>
> > for (i in 18:21) {
>   p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
>     geom_smooth(method="lm") +
>     geom_point(size = 4) +
>     geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
>     scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) +
>     stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
>     stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black",
>                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
>
>   ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
> }
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Jul 11 18:11:26 2020
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 11 Jul 2020 12:11:26 -0400
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CABcYAdLjywLozR7hn_JTBnx=WyAxuMHJ5HHtwdOUVtjTjeye8w@mail.gmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>
 <CAGgJW74QdODbH0gUcAa2qrKePwk54ugrRgtab64kWXYvhHqjEw@mail.gmail.com>
 <CABcYAdLjywLozR7hn_JTBnx=WyAxuMHJ5HHtwdOUVtjTjeye8w@mail.gmail.com>
Message-ID: <00ed01d6579d$ee3549c0$ca9fdd40$@verizon.net>

There are many ways to do what is requested and some are fairly simple and
robust. A simple switch statement will do if you write some code but
consider using a function from some package for simple vectors or factors.

You could use the recode() or recode_factor() functions in package dplyr or
other similar functions elsewhere and type in the conversions like so:

library("dplyr")

xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")

xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)

sample <- rep(xc, each=3)

recode(sample,
       "1" = 1,
       "1a" = 1.3,
       "1b" = 1.5,
       "1c" = 1.7,
       "2" = 2,
       "2a" =2.3,
       "2b" = 2.5,
       "2c" = 2.7)

That returns:

[1] 1.0 1.0 1.0 1.3 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 2.0 2.0 2.0 2.3 2.3 2.3
2.5 2.5 2.5 2.7 2.7 2.7

To use the original vectors would be a tad harder but doable perhaps using
some indirection.

As has been noted, you need to be careful in matching things to use the
entire item from beginning to end as matching  a substring can produce odd
results. If you add this code to the above, in a silly way, it works for a
more general case:

library(glue)

converted <- sample
for (i in 1:length(xc)) {
  converted <- sub(glue("^{xc[i]}$"), xn[i], converted)
}

result <- as.numeric(converted)

Returns:

> result
 [1] 1.0 1.0 1.0 1.3 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 2.0 2.0 2.0 2.3 2.3 2.3
2.5 2.5 2.5 2.7 2.7 2.7

Not necessarily efficient but it works. You could use something like
glue::glue() to create the arguments you want to use for something like
recode() in more complex cases and so on.

I think we have had enough solutions and methods posted but there are likely
many more as there is rarely only one way to do things in R.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
Sent: Saturday, July 11, 2020 3:02 AM
To: Eric Berger <ericjberger at gmail.com>
Cc: Jean-Louis Abitbol <abitbol at sent.com>; R Project Help
<r-help at r-project.org>
Subject: Re: [R] Character (1a, 1b) to numeric

The string index approach works with any mapping from stage names to stage
numbers, not just regular ones.  For example, if we had "1" -> 1, "1a" ->
1.4, "1b" -> 1.6 "2" -> 2, "2a" -> 2.3, "2b" -> 2.7 the 'sub' version would
fail miserably while the string index version would just work.  The 'sub'
version would also not work terribly well if the mapping were "1" -> 1, "a1"
-> 1.3, "b1" -> 1.5, "c1" -> 1.7 and so on. The thing I like about the
indexing approach is that it uses a fundamental operation of the language
very directly.

Anyone using R would do well to *master* what indexing can do for you.


On Sat, 11 Jul 2020 at 17:16, Eric Berger <ericjberger at gmail.com> wrote:

> xn <- as.numeric(sub("c",".7",sub("b",".5",sub("a",".3",xc))))
>
>
> On Sat, Jul 11, 2020 at 5:09 AM Richard O'Keefe <raoknz at gmail.com> wrote:
>
>> This can be done very simply because vectors in R can have named 
>> elements, and can be indexed by strings.
>>
>> > stage <- c("1" = 1, "1a" = 1.3, "1b" = 1.5, "1c" = 1.7,
>> +            "2" = 2, "2a" = 2.3, "2b" = 2.5, "2c" = 2.7,
>> +            "3" = 3, "3a" = 3.3, "3b" = 3.5, "3c" = 3.7)
>>
>> > testdata <- rep(c("1", "1a", "1b", "1c",
>> +                   "2", "2a", "2b", "2c",
>> +                   "3", "3a", "3b", "3c"), times=c(1:6,6:1))
>>
>> > stage[testdata]
>>   1  1a  1a  1b  1b  1b  1c  1c  1c  1c   2   2   2   2   2  2a  2a  2a
>> 2a
>>  2a
>> 1.0 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 1.7 2.0 2.0 2.0 2.0 2.0 2.3 2.3 
>> 2.3
>> 2.3
>> 2.3
>>  2a  2b  2b  2b  2b  2b  2b  2c  2c  2c  2c  2c   3   3   3   3  3a  3a
>> 3a
>>  3b
>> 2.3 2.5 2.5 2.5 2.5 2.5 2.5 2.7 2.7 2.7 2.7 2.7 3.0 3.0 3.0 3.0 3.3 
>> 3.3
>> 3.3
>> 3.5
>>  3b  3c
>> 3.5 3.7
>>
>> On Sat, 11 Jul 2020 at 05:51, Jean-Louis Abitbol <abitbol at sent.com>
>> wrote:
>>
>> > Dear All
>> >
>> > I have a character vector,  representing histology stages, such as 
>> > for
>> > example:
>> > xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>> >
>> > and this goes on to 3, 3a etc in various order for each patient. I 
>> > do
>> have
>> > of course a pre-established  classification available which does 
>> > change according to the histology criteria under assessment.
>> >
>> > I would want to convert xc, for plotting reasons, to a numeric 
>> > vector
>> such
>> > as
>> >
>> > xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
>> >
>> > Unfortunately I have no clue on how to do that.
>> >
>> > Thanks for any help and apologies if I am missing the obvious way 
>> > to do
>> it.
>> >
>> > JL
>> > --
>> > Verif30042020
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @@ch|n@p@t|| @end|ng |rom vergoc||n|c@|@@|n  Sat Jul 11 11:45:33 2020
From: @@ch|n@p@t|| @end|ng |rom vergoc||n|c@|@@|n (Sachin Patil)
Date: Sat, 11 Jul 2020 15:15:33 +0530
Subject: [R] Inquiry for R software Licensing.
Message-ID: <000a01d65768$063ee9d0$12bcbd70$@vergoclinicals.in>

Dear R Software Team,

 

We want to know about R software Licensing to procure it. Do you have R
software License version or any professional version?

 

Regards,

Sachin Patil

IT Executive

Vergo Pharma Research Pvt Ltd.

(Division - Vergo Clinicals)
Plot 24/1 D-1 Mologa de Orora, Corlim,

Tiswadi, Goa-403110 India,

Tel: +91 8326640555

 


	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Jul 11 19:50:05 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 11 Jul 2020 13:50:05 -0400
Subject: [R] Inquiry for R software Licensing.
In-Reply-To: <000a01d65768$063ee9d0$12bcbd70$@vergoclinicals.in>
References: <000a01d65768$063ee9d0$12bcbd70$@vergoclinicals.in>
Message-ID: <CAJc=yOEqjY7vbHH=wRHAsXf6mfbZaM25ixC8wOzU+VL9PPWDWA@mail.gmail.com>

There's only one version and it's free.

On Sat, Jul 11, 2020 at 1:46 PM Sachin Patil
<sachin.patil at vergoclinicals.in> wrote:
>
> Dear R Software Team,
>
>
>
> We want to know about R software Licensing to procure it. Do you have R
> software License version or any professional version?
>
>
>
> Regards,
>
> Sachin Patil
>
> IT Executive
>
> Vergo Pharma Research Pvt Ltd.
>
> (Division - Vergo Clinicals)
> Plot 24/1 D-1 Mologa de Orora, Corlim,
>
> Tiswadi, Goa-403110 India,
>
> Tel: +91 8326640555
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Jul 11 20:01:28 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 11 Jul 2020 11:01:28 -0700
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>
References: <aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <CABcYAdLfdoHUS6BhhPGvSx0epopBAzoR4H-sChShy6rh_mosgw@mail.gmail.com>
Message-ID: <85dd888f-4b0e-c8fc-d6a2-dd22b8040516@comcast.net>

It might be easier to simply assign names to the numeric vector if you 
already have numeric and character vectors of the right lengths. Using 
Heibergers's vectors:


xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)

names(xn) <- xc

testdata <- rep(c("1", "1a", "1b", "1c",
                     "2", "2a", "2b", "2c",
                    "3", "3a", "3b", "3c"), times=c(1:6,6:1))

xn[ testdata ]  #  NA's when there's no match is a feature.

-- 
David.

On 7/10/20 7:08 PM, Richard O'Keefe wrote:
> This can be done very simply because vectors in R can have
> named elements, and can be indexed by strings.
>
>> stage <- c("1" = 1, "1a" = 1.3, "1b" = 1.5, "1c" = 1.7,
> +            "2" = 2, "2a" = 2.3, "2b" = 2.5, "2c" = 2.7,
> +            "3" = 3, "3a" = 3.3, "3b" = 3.5, "3c" = 3.7)
>
>> testdata <- rep(c("1", "1a", "1b", "1c",
> +                   "2", "2a", "2b", "2c",
> +                   "3", "3a", "3b", "3c"), times=c(1:6,6:1))
>
>> stage[testdata]
>    1  1a  1a  1b  1b  1b  1c  1c  1c  1c   2   2   2   2   2  2a  2a  2a  2a
>   2a
> 1.0 1.3 1.3 1.5 1.5 1.5 1.7 1.7 1.7 1.7 2.0 2.0 2.0 2.0 2.0 2.3 2.3 2.3 2.3
> 2.3
>   2a  2b  2b  2b  2b  2b  2b  2c  2c  2c  2c  2c   3   3   3   3  3a  3a  3a
>   3b
> 2.3 2.5 2.5 2.5 2.5 2.5 2.5 2.7 2.7 2.7 2.7 2.7 3.0 3.0 3.0 3.0 3.3 3.3 3.3
> 3.5
>   3b  3c
> 3.5 3.7
>
> On Sat, 11 Jul 2020 at 05:51, Jean-Louis Abitbol <abitbol at sent.com> wrote:
>
>> Dear All
>>
>> I have a character vector,  representing histology stages, such as for
>> example:
>> xc <-  c("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>>
>> and this goes on to 3, 3a etc in various order for each patient. I do have
>> of course a pre-established  classification available which does change
>> according to the histology criteria under assessment.
>>
>> I would want to convert xc, for plotting reasons, to a numeric vector such
>> as
>>
>> xn <- c(1, 1.3, 1.5, 1.7, 2, 2.3, 2.5, 2.7)
>>
>> Unfortunately I have no clue on how to do that.
>>
>> Thanks for any help and apologies if I am missing the obvious way to do it.
>>
>> JL
>> --
>> Verif30042020
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jul 11 20:01:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 11 Jul 2020 11:01:54 -0700
Subject: [R] Inquiry for R software Licensing.
In-Reply-To: <CAJc=yOEqjY7vbHH=wRHAsXf6mfbZaM25ixC8wOzU+VL9PPWDWA@mail.gmail.com>
References: <000a01d65768$063ee9d0$12bcbd70$@vergoclinicals.in>
 <CAJc=yOEqjY7vbHH=wRHAsXf6mfbZaM25ixC8wOzU+VL9PPWDWA@mail.gmail.com>
Message-ID: <CAGxFJbQY0gmQqpiK1v4_NXXAWLPRC7QmqhzpVeU+Nv1sMwZNDA@mail.gmail.com>

... and details for downloading including worldwide repositories (i.e.
*mirrors*) can be found here:
https://cran.r-project.org/

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jul 11, 2020 at 10:56 AM Patrick (Malone Quantitative) <
malone at malonequantitative.com> wrote:

> There's only one version and it's free.
>
> On Sat, Jul 11, 2020 at 1:46 PM Sachin Patil
> <sachin.patil at vergoclinicals.in> wrote:
> >
> > Dear R Software Team,
> >
> >
> >
> > We want to know about R software Licensing to procure it. Do you have R
> > software License version or any professional version?
> >
> >
> >
> > Regards,
> >
> > Sachin Patil
> >
> > IT Executive
> >
> > Vergo Pharma Research Pvt Ltd.
> >
> > (Division - Vergo Clinicals)
> > Plot 24/1 D-1 Mologa de Orora, Corlim,
> >
> > Tiswadi, Goa-403110 India,
> >
> > Tel: +91 8326640555
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S@E|||@on @end|ng |rom LGCGroup@com  Sun Jul 12 00:19:48 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Sat, 11 Jul 2020 22:19:48 +0000
Subject: [R] Inquiry for R software Licensing.
In-Reply-To: <CAJc=yOEqjY7vbHH=wRHAsXf6mfbZaM25ixC8wOzU+VL9PPWDWA@mail.gmail.com>
References: <000a01d65768$063ee9d0$12bcbd70$@vergoclinicals.in>
 <CAJc=yOEqjY7vbHH=wRHAsXf6mfbZaM25ixC8wOzU+VL9PPWDWA@mail.gmail.com>
Message-ID: <f6e5e39e5ad7424fa7eae7bbbaff48c5@GBDCVPEXC08.corp.lgc-group.com>

> Patrick (Malone Quantitative)
> There's only one version and it's free.

You're forgetting Microsoft R, formerly Revolution R (https://mran.revolutionanalytics.com/download), which comes in open and enterprise flavours, both with multithreading and the latter with beefed up database access services (from the marketing fluff). I should say I've tried neither; the standard R download at R-project.org is fine for what I do.

S Ellison

On Sat, Jul 11, 2020 at 1:46 PM Sachin Patil <sachin.patil at vergoclinicals.in> wrote:
>
> Dear R Software Team,
>
>
>
> We want to know about R software Licensing to procure it. Do you have 
> R software License version or any professional version?
>
>
>
> Regards,
>
> Sachin Patil



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From |@t@z@hn @end|ng |rom gm@||@com  Sun Jul 12 00:52:13 2020
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Sat, 11 Jul 2020 18:52:13 -0400
Subject: [R] Inquiry for R software Licensing.
In-Reply-To: <f6e5e39e5ad7424fa7eae7bbbaff48c5@GBDCVPEXC08.corp.lgc-group.com>
References: <000a01d65768$063ee9d0$12bcbd70$@vergoclinicals.in>
 <CAJc=yOEqjY7vbHH=wRHAsXf6mfbZaM25ixC8wOzU+VL9PPWDWA@mail.gmail.com>
 <f6e5e39e5ad7424fa7eae7bbbaff48c5@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <CA+vqiLGsf4v3rK4hVqJLs5G7Ry-vc8S3HMPmRMnWZwXojg9=Ng@mail.gmail.com>

On Sat, Jul 11, 2020 at 6:20 PM Stephen Ellison <S.Ellison at lgcgroup.com> wrote:
>
> > Patrick (Malone Quantitative)
> > There's only one version and it's free.
>
> You're forgetting Microsoft R, formerly Revolution R (https://mran.revolutionanalytics.com/download), which comes in open and enterprise flavours, both with multithreading and the latter with beefed up database access services (from the marketing fluff).

Is there actually an enterprise version? All I've ever seen is MRO,
which hasn't been updated from R 3.5.3.

--Ista

>
> S Ellison
>
> On Sat, Jul 11, 2020 at 1:46 PM Sachin Patil <sachin.patil at vergoclinicals.in> wrote:
> >
> > Dear R Software Team,
> >
> >
> >
> > We want to know about R software Licensing to procure it. Do you have
> > R software License version or any professional version?
> >
> >
> >
> > Regards,
> >
> > Sachin Patil
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:8}}


From @purd|e@@ @end|ng |rom gm@||@com  Sun Jul 12 01:06:19 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 12 Jul 2020 11:06:19 +1200
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
Message-ID: <CAB8pepw=ReMgFAUPJyO3M5NQz5F=h73C-5Kp41VoOC-KMnSLLA@mail.gmail.com>

On Sat, Jul 11, 2020 at 8:04 AM Fox, John <jfox at mcmaster.ca> wrote:
> We've had several solutions, and I was curious about their relative efficiency. Here's a test

Am I the only person on this mailing list who learnt to program with ASCII...?

In theory, the most ***efficient*** solution, is to get the
ASCII/UTF8/etc values.
Then use a simple (math) formula.
No matching, no searching, required ...

Here's one possibility:

    xc <-  c ("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")

    I <- (nchar (xc) == 2)
    xn <- as.integer (substring (xc, 1, 1) )
    xn [I] <- xn [I] + (utf8ToInt (paste (substring (xc [I], 2, 2),
collapse="") ) - 96) / 4
    xn

Unfortunately, this makes R look bad.
The corresponding C implementation is simpler and presumably the
performance winner.


From drj|m|emon @end|ng |rom gm@||@com  Sun Jul 12 01:32:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 12 Jul 2020 09:32:13 +1000
Subject: [R] How to differ stats_cor labels by group on a ggplot
In-Reply-To: <SN2PR03MB2190440F30A01F050243549A94620@SN2PR03MB2190.namprd03.prod.outlook.com>
References: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>
 <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>
 <SN2PR03MB2190440F30A01F050243549A94620@SN2PR03MB2190.namprd03.prod.outlook.com>
Message-ID: <CA+8X3fUPkawtQa4Fvj-L3ODgB5Ot=QnSWJeVw_Jrda0XYRQPMg@mail.gmail.com>

Hi Paulina,
Thanks for the data. Even after downloading a ton of packages along
with the "ggpubr" package, I get a namespace error when I try to load
it. After a bit of wrangling, I did get the code to run without the
"stat_cor" function, producing the four PNG images. My best guess is
to try the geom_label function with stat="cor", but I can't see any
argument to format the actual label. I think this is about as far as
I'm going to get.

Jim

On Sun, Jul 12, 2020 at 12:09 AM Paulina Skolasinska
<paulina.skol at hotmail.com> wrote:
>
> Thanks Tim, here is the link to the data: https://we.tl/t-c4x9Lw7LeR
> I'm posting my code again so it better matches the modified data, and because I've added several improvements in the meantime.
>
> for (i in 3:6) {
>     p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
>         geom_smooth(method="lm") +
>         geom_point(size = 4) +
>         scale_x_continuous(breaks = seq(20,90, by=10)) +
>         scale_y_continuous(breaks = seq(0.1,0.5, by=0.1)) +
>         theme_classic() +
>         expand_limits(y = 0.5) +
>         ylab(names(df)[i]) +
>         theme(axis.text.x = element_text(face="bold", size=14),
>               axis.text.y = element_text(face="bold", size=14),
>               axis.title.x = element_text(size=14, face="bold"),
>               axis.title.y = element_text(size=14, face="bold"),
>               legend.title = element_text(color="black", size=12),
>               legend.text = element_text(colour="black", size = 14, face = "bold")) +
>         geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
>         scale_colour_discrete(name="Group", labels=c("Young", "Old", "Overall")) +
>         stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i])),
>                  method = "pearson", label.x.npc = c("center"), label.y.npc="top") +
>         stat_cor(aes(x = Age, y = unlist(df[i]),
>                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~"),
>                  group=1, color="black"), method = "pearson",label.y=0.5, label.x.npc = c("center"),
>                  position = position_nudge(y = 0.015 * 0.5))
>
>     ggsave(p1, file=paste0("TestAge_", names(df)[i], ".png"), scale=1, width=16, height=10, units="cm")
> }
>
>
> ________________________________
> Od: Jim Lemon <drjimlemon at gmail.com>
> Wys?ane: sobota, 11 lipca 2020 04:09
> Do: Paulina Skolasinska <paulina.skol at hotmail.com>
> DW: r-help at r-project.org <r-help at r-project.org>
> Temat: Re: [R] How to differ stats_cor labels by group on a ggplot
>
> Hi Paulina,
> Without data it's hard to work out what you are doing. Even a small
> simulated data set would help to get answers.
>
> Jim
>
> On Fri, Jul 10, 2020 at 11:49 PM Paulina Skolasinska
> <paulina.skol at hotmail.com> wrote:
> >
> > 'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.
> >
> > I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW
> >
> > > for (i in 18:21) {
> >   p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
> >     geom_smooth(method="lm") +
> >     geom_point(size = 4) +
> >     geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
> >     scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) +
> >     stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
> >     stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black",
> >                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
> >
> >   ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
> > }
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sun Jul 12 02:04:39 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 12 Jul 2020 10:04:39 +1000
Subject: [R] Character (1a, 1b) to numeric
In-Reply-To: <CAB8pepw=ReMgFAUPJyO3M5NQz5F=h73C-5Kp41VoOC-KMnSLLA@mail.gmail.com>
References: <15064_1594403475_06AHpF6f005082_aad65cc9-be22-45df-adbb-50eeab509397@www.fastmail.com>
 <5281CE73-01D2-4D1D-92D6-4A7C70122BF9@mcmaster.ca>
 <CAE-dL2pRo_maEtvk75dOKhrsxQ8HxDFF807Hj-B4vFxQ=OYrRw@mail.gmail.com>
 <4713362B-418E-41EB-A560-1CABC5CB04EB@mcmaster.ca>
 <CAB8pepw=ReMgFAUPJyO3M5NQz5F=h73C-5Kp41VoOC-KMnSLLA@mail.gmail.com>
Message-ID: <CA+8X3fUFD1qRJC1rJBPFFu9e5ECOz8yKfUB-vgB1pjKKcCchHA@mail.gmail.com>

I'll admit that I cut my teeth on ASCII, but I worried about your
reliance on that ancient typographic ordering. I wrote a little
function:

al2num_sub<-function(x) {
 xspl<-unlist(strsplit(x,""))
 if(length(xspl) > 1)
  xspl<-paste(xspl[1],which(letters==xspl[2]),sep=".")
 return(xspl)
}
unlist(sapply(xc,al2num_sub(xc)))

that does the trick with ASCII, but there was a nagging worry that it
wouldn't work for any ordering apart from the Roman alphabet.
Unfortunately I couldn't find any way to substitute something for
"letters" that would allow me to plug in a more general solution like:

alpha.set<-c("letters","greek",...)

Maybe someone else can crack that one.

Jim

On Sun, Jul 12, 2020 at 9:07 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> On Sat, Jul 11, 2020 at 8:04 AM Fox, John <jfox at mcmaster.ca> wrote:
> > We've had several solutions, and I was curious about their relative efficiency. Here's a test
>
> Am I the only person on this mailing list who learnt to program with ASCII...?
>
> In theory, the most ***efficient*** solution, is to get the
> ASCII/UTF8/etc values.
> Then use a simple (math) formula.
> No matching, no searching, required ...
>
> Here's one possibility:
>
>     xc <-  c ("1", "1a", "1b", "1c", "2", "2a", "2b", "2c")
>
>     I <- (nchar (xc) == 2)
>     xn <- as.integer (substring (xc, 1, 1) )
>     xn [I] <- xn [I] + (utf8ToInt (paste (substring (xc [I], 2, 2),
> collapse="") ) - 96) / 4
>     xn
>
> Unfortunately, this makes R look bad.
> The corresponding C implementation is simpler and presumably the
> performance winner.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u||n@@@ko| @end|ng |rom hotm@||@com  Sun Jul 12 03:20:02 2020
From: p@u||n@@@ko| @end|ng |rom hotm@||@com (Paulina Skolasinska)
Date: Sun, 12 Jul 2020 01:20:02 +0000
Subject: [R] How to differ stats_cor labels by group on a ggplot
In-Reply-To: <CA+8X3fUPkawtQa4Fvj-L3ODgB5Ot=QnSWJeVw_Jrda0XYRQPMg@mail.gmail.com>
References: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>
 <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>
 <SN2PR03MB2190440F30A01F050243549A94620@SN2PR03MB2190.namprd03.prod.outlook.com>,
 <CA+8X3fUPkawtQa4Fvj-L3ODgB5Ot=QnSWJeVw_Jrda0XYRQPMg@mail.gmail.com>
Message-ID: <SN2PR03MB219071241A3258FEE35C46CC94630@SN2PR03MB2190.namprd03.prod.outlook.com>

Sorry for misspelling your name, Jim. Well, it seems this is not worth the effort then. If my advisor decides this is absolutely essential, I?ll add it in gimp or something. Thanks for giving it a go, Jim.

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: Saturday, July 11, 2020 6:32:13 PM
To: Paulina Skolasinska <paulina.skol at hotmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] How to differ stats_cor labels by group on a ggplot

Hi Paulina,
Thanks for the data. Even after downloading a ton of packages along
with the "ggpubr" package, I get a namespace error when I try to load
it. After a bit of wrangling, I did get the code to run without the
"stat_cor" function, producing the four PNG images. My best guess is
to try the geom_label function with stat="cor", but I can't see any
argument to format the actual label. I think this is about as far as
I'm going to get.

Jim

On Sun, Jul 12, 2020 at 12:09 AM Paulina Skolasinska
<paulina.skol at hotmail.com> wrote:
>
> Thanks Tim, here is the link to the data: https://we.tl/t-c4x9Lw7LeR
> I'm posting my code again so it better matches the modified data, and because I've added several improvements in the meantime.
>
> for (i in 3:6) {
>     p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
>         geom_smooth(method="lm") +
>         geom_point(size = 4) +
>         scale_x_continuous(breaks = seq(20,90, by=10)) +
>         scale_y_continuous(breaks = seq(0.1,0.5, by=0.1)) +
>         theme_classic() +
>         expand_limits(y = 0.5) +
>         ylab(names(df)[i]) +
>         theme(axis.text.x = element_text(face="bold", size=14),
>               axis.text.y = element_text(face="bold", size=14),
>               axis.title.x = element_text(size=14, face="bold"),
>               axis.title.y = element_text(size=14, face="bold"),
>               legend.title = element_text(color="black", size=12),
>               legend.text = element_text(colour="black", size = 14, face = "bold")) +
>         geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
>         scale_colour_discrete(name="Group", labels=c("Young", "Old", "Overall")) +
>         stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i])),
>                  method = "pearson", label.x.npc = c("center"), label.y.npc="top") +
>         stat_cor(aes(x = Age, y = unlist(df[i]),
>                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~"),
>                  group=1, color="black"), method = "pearson",label.y=0.5, label.x.npc = c("center"),
>                  position = position_nudge(y = 0.015 * 0.5))
>
>     ggsave(p1, file=paste0("TestAge_", names(df)[i], ".png"), scale=1, width=16, height=10, units="cm")
> }
>
>
> ________________________________
> Od: Jim Lemon <drjimlemon at gmail.com>
> Wys?ane: sobota, 11 lipca 2020 04:09
> Do: Paulina Skolasinska <paulina.skol at hotmail.com>
> DW: r-help at r-project.org <r-help at r-project.org>
> Temat: Re: [R] How to differ stats_cor labels by group on a ggplot
>
> Hi Paulina,
> Without data it's hard to work out what you are doing. Even a small
> simulated data set would help to get answers.
>
> Jim
>
> On Fri, Jul 10, 2020 at 11:49 PM Paulina Skolasinska
> <paulina.skol at hotmail.com> wrote:
> >
> > 'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.
> >
> > I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW
> >
> > > for (i in 18:21) {
> >   p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
> >     geom_smooth(method="lm") +
> >     geom_point(size = 4) +
> >     geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
> >     scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) +
> >     stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
> >     stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black",
> >                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
> >
> >   ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
> > }
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Jul 12 08:08:03 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 12 Jul 2020 16:08:03 +1000
Subject: [R] How to differ stats_cor labels by group on a ggplot
In-Reply-To: <SN2PR03MB219071241A3258FEE35C46CC94630@SN2PR03MB2190.namprd03.prod.outlook.com>
References: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>
 <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>
 <SN2PR03MB2190440F30A01F050243549A94620@SN2PR03MB2190.namprd03.prod.outlook.com>
 <CA+8X3fUPkawtQa4Fvj-L3ODgB5Ot=QnSWJeVw_Jrda0XYRQPMg@mail.gmail.com>
 <SN2PR03MB219071241A3258FEE35C46CC94630@SN2PR03MB2190.namprd03.prod.outlook.com>
Message-ID: <CA+8X3fWdBdopJgTmn5Wb3_=D5fmTD9sWWf-=zhkXp4R54d=Tzw@mail.gmail.com>

Okay. If you get stuck, you can always roll your own:

psdf<-read.table("sim_data.txt",header=TRUE,stringsAsFactors=FALSE)
library(plotrix)
source("supsubtext.R")
par(cex.axis=1.5)
for(i in 3:6) {
 png(paste0("TestAge_",names(psdf[i]),".png"),width=600)
 plot(psdf$Age,psdf[,i],xlim=c(20,85),ylim=c(-0.1,0.5),
  xlab="Age",ylab=names(psdf)[i],
  axes=FALSE,pch=19,col=c("green","orange")[psdf$AgeGroup+1],
  cex=2)
 fullaxis(1,col="black",lwd=1.5)
 fullaxis(2,col="black",lwd=1.5)
 # fit the entire column
 lmfit<-lm(psdf[,i]~psdf$Age)
 lmpf<-predict(lmfit,se.fit=TRUE)
 uniqage<-sort(unique(psdf$Age))
 cis<-supsmu(psdf$Age,lmpf$se.fit)$y
 lmline<-lmfit$coefficients[1]+uniqage*lmfit$coefficients[2]
 # display the overall confidence band
 polygon(c(uniqage,rev(uniqage)),c(lmline+cis,rev(lmline-cis)),
  border=NA,col="lightgray")
 # now the "young" group
 young<-psdf$AgeGroup == 0
 lmfit<-lm(psdf[young,i]~psdf[young,"Age"])
 lmpf<-predict(lmfit,se.fit=TRUE)
 uniqage<-sort(unique(psdf$Age[young]))
 cis<-supsmu(psdf$Age[young],lmpf$se.fit)$y
 lmline<-lmfit$coefficients[1]+uniqage*lmfit$coefficients[2]
 polygon(c(uniqage,rev(uniqage)),c(lmline+cis,rev(lmline-cis)),
  border=NA,col="#88ff8880")
 # now the "old" group
 old<-psdf$AgeGroup == 1
 lmfit<-lm(psdf[old,i]~psdf[old,"Age"])
 lmpf<-predict(lmfit,se.fit=TRUE)
 uniqage<-sort(unique(psdf$Age[old]))
 cis<-supsmu(psdf$Age[old],lmpf$se.fit)$y
 lmline<-lmfit$coefficients[1]+uniqage*lmfit$coefficients[2]
 polygon(c(uniqage,rev(uniqage)),c(lmline+cis,rev(lmline-cis)),
  border=NA,col="#ffaa8880")
 points(psdf$Age,psdf[,i],pch=19,
  col=c("green","orange")[psdf$AgeGroup+1],cex=2)
 # overall correlation
 corval<-cor.test(psdf$Age,psdf[,i])
 corstr<-paste0("R(overall) = ",round(corval$estimate,2),", p = ",
  round(corval$p.value,2))
 supsubtext(20,0.05,corstr,sub=2:10,col="blue")
 # young correlation
 corval<-cor.test(psdf[young,"Age"],psdf[young,i])
 corstr<-paste0("R(young) = ",round(corval$estimate,2),", p = ",
  round(corval$p.value,2))
 supsubtext(20,0,corstr,sub=2:8,col="green")
 # old correlation
 corval<-cor.test(psdf[old,"Age"],psdf[old,i])
 corstr<-paste0("R(old) = ",round(corval$estimate,2),", p = ",
  round(corval$p.value,2))
 supsubtext(20,-0.05,corstr,sub=2:6,col="orange")
 legend(40,0.5,c("Overall","Young","Old"),pch=19,
  col=c("lightgray","green","orange"))
 dev.off()
}

I've been meaning to finish off the "supsubtext" function for a while.

Jim

On Sun, Jul 12, 2020 at 11:20 AM Paulina Skolasinska
<paulina.skol at hotmail.com> wrote:
>
> Sorry for misspelling your name, Jim. Well, it seems this is not worth the effort then. If my advisor decides this is absolutely essential, I?ll add it in gimp or something. Thanks for giving it a go, Jim.
>
> Get Outlook for iOS
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Saturday, July 11, 2020 6:32:13 PM
> To: Paulina Skolasinska <paulina.skol at hotmail.com>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] How to differ stats_cor labels by group on a ggplot
>
> Hi Paulina,
> Thanks for the data. Even after downloading a ton of packages along
> with the "ggpubr" package, I get a namespace error when I try to load
> it. After a bit of wrangling, I did get the code to run without the
> "stat_cor" function, producing the four PNG images. My best guess is
> to try the geom_label function with stat="cor", but I can't see any
> argument to format the actual label. I think this is about as far as
> I'm going to get.
>
> Jim
>
> On Sun, Jul 12, 2020 at 12:09 AM Paulina Skolasinska
> <paulina.skol at hotmail.com> wrote:
> >
> > Thanks Tim, here is the link to the data: https://we.tl/t-c4x9Lw7LeR
> > I'm posting my code again so it better matches the modified data, and because I've added several improvements in the meantime.
> >
> > for (i in 3:6) {
> >     p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
> >         geom_smooth(method="lm") +
> >         geom_point(size = 4) +
> >         scale_x_continuous(breaks = seq(20,90, by=10)) +
> >         scale_y_continuous(breaks = seq(0.1,0.5, by=0.1)) +
> >         theme_classic() +
> >         expand_limits(y = 0.5) +
> >         ylab(names(df)[i]) +
> >         theme(axis.text.x = element_text(face="bold", size=14),
> >               axis.text.y = element_text(face="bold", size=14),
> >               axis.title.x = element_text(size=14, face="bold"),
> >               axis.title.y = element_text(size=14, face="bold"),
> >               legend.title = element_text(color="black", size=12),
> >               legend.text = element_text(colour="black", size = 14, face = "bold")) +
> >         geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
> >         scale_colour_discrete(name="Group", labels=c("Young", "Old", "Overall")) +
> >         stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i])),
> >                  method = "pearson", label.x.npc = c("center"), label.y.npc="top") +
> >         stat_cor(aes(x = Age, y = unlist(df[i]),
> >                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~"),
> >                  group=1, color="black"), method = "pearson",label.y=0.5, label.x.npc = c("center"),
> >                  position = position_nudge(y = 0.015 * 0.5))
> >
> >     ggsave(p1, file=paste0("TestAge_", names(df)[i], ".png"), scale=1, width=16, height=10, units="cm")
> > }
> >
> >
> > ________________________________
> > Od: Jim Lemon <drjimlemon at gmail.com>
> > Wys?ane: sobota, 11 lipca 2020 04:09
> > Do: Paulina Skolasinska <paulina.skol at hotmail.com>
> > DW: r-help at r-project.org <r-help at r-project.org>
> > Temat: Re: [R] How to differ stats_cor labels by group on a ggplot
> >
> > Hi Paulina,
> > Without data it's hard to work out what you are doing. Even a small
> > simulated data set would help to get answers.
> >
> > Jim
> >
> > On Fri, Jul 10, 2020 at 11:49 PM Paulina Skolasinska
> > <paulina.skol at hotmail.com> wrote:
> > >
> > > 'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.
> > >
> > > I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW
> > >
> > > > for (i in 18:21) {
> > >   p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
> > >     geom_smooth(method="lm") +
> > >     geom_point(size = 4) +
> > >     geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
> > >     scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) +
> > >     stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
> > >     stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black",
> > >                  label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
> > >
> > >   ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
> > > }
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.

From tri@g m@iii@g oii gvd@et@dk  Sun Jul 12 11:42:33 2020
From: tri@g m@iii@g oii gvd@et@dk (tri@g m@iii@g oii gvd@et@dk)
Date: Sun, 12 Jul 2020 11:42:33 +0200
Subject: [R] Rmpfr correlation
Message-ID: <19f3601d65830$c6231230$52693690$@gvdnet.dk>

Dear friends - I'm calculating buffer capacities by different methods and
need very high precision and package Rmpfr is working beautifully. However,
I have not been able to find out how to keep precision when finding
correlations.

library(Rmpfr)

KA <- mpfr(10^-4.6, 128)

x <- rnorm(100)*KA

y <- rnorm(100)*x

cor(x,y) # "x" must be numeric

cor(as.numeric(x),as.numeric(y))# 0.2918954

 

In my concrete application I get cor = 1 for
cor(as.numeric(dff$BB),as.numeric(BBVS)) even though I have 

 

str(summary((dff$BB)-(BBVS)))
Class 'summaryMpfr' [package "Rmpfr"] of length 6 and precision 128
 4.61351010833e-8 7.33418976521e-7 1.31009046563e-5 3.76407022709e-5
5.72386764888e-5 ...

 

I am on windows 10

R version 3.6.1
 
Best wishes
Troels Ring,
Aalborg, Denmark

 

 


This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com
<http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
p&url=/> 

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jul 12 12:59:11 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 12 Jul 2020 11:59:11 +0100
Subject: [R] Rmpfr correlation
In-Reply-To: <19f3601d65830$c6231230$52693690$@gvdnet.dk>
References: <19f3601d65830$c6231230$52693690$@gvdnet.dk>
Message-ID: <08edf449-9de1-3e82-9a17-d799289b3895@sapo.pt>

Hello,

Why not write a function COR? Not one as general purpose as stats::cor 
but a simple one, to compute the sample Pearson correlation only.


library(Rmpfr)

COR <- function(x, y){
   precBits <- getPrec(x)[1]
   n <- mpfr(length(x), precBits = precBits)
   x.bar <- mean(x)
   y.bar <- mean(y)
   numer <- sum(x*y) - n*x.bar*y.bar
   denom <- sqrt(sum(x*x) - n*x.bar*x.bar) * sqrt(sum(y*y) - n*y.bar*y.bar)
   numer/denom
}

set.seed(2020)
KA <- mpfr(10^-4.6, 128)
x <- rnorm(100)*KA
y <- rnorm(100)*x

cor(as.numeric(x), as.numeric(y)) # -0.1874986
#[1] -0.1874986

COR(x, y)
#1 'mpfr' number of precision  128   bits
#[1] -0.1874985950531874160800643775644747505073


Hope this helps,

Rui Barradas

?s 10:42 de 12/07/20, tring at gvdnet.dk escreveu:
> Dear friends - I'm calculating buffer capacities by different methods and
> need very high precision and package Rmpfr is working beautifully. However,
> I have not been able to find out how to keep precision when finding
> correlations.
> 
> library(Rmpfr)
> 
> KA <- mpfr(10^-4.6, 128)
> 
> x <- rnorm(100)*KA
> 
> y <- rnorm(100)*x
> 
> cor(x,y) # "x" must be numeric
> 
> cor(as.numeric(x),as.numeric(y))# 0.2918954
> 
>   
> 
> In my concrete application I get cor = 1 for
> cor(as.numeric(dff$BB),as.numeric(BBVS)) even though I have
> 
>   
> 
> str(summary((dff$BB)-(BBVS)))
> Class 'summaryMpfr' [package "Rmpfr"] of length 6 and precision 128
>   4.61351010833e-8 7.33418976521e-7 1.31009046563e-5 3.76407022709e-5
> 5.72386764888e-5 ...
> 
>   
> 
> I am on windows 10
> 
> R version 3.6.1
>   
> Best wishes
> Troels Ring,
> Aalborg, Denmark
> 
>   
> 
>   
> 
> 
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
> p&url=/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tri@g m@iii@g oii gvd@et@dk  Sun Jul 12 14:57:05 2020
From: tri@g m@iii@g oii gvd@et@dk (tri@g m@iii@g oii gvd@et@dk)
Date: Sun, 12 Jul 2020 14:57:05 +0200
Subject: [R] Rmpfr correlation
In-Reply-To: uZhWjmUb9myVguZhYjv5hU
References: <19f3601d65830$c6231230$52693690$@gvdnet.dk> uZhWjmUb9myVguZhYjv5hU
Message-ID: <3130301d6584b$f23c7c10$d6b57430$@gvdnet.dk>

Thanks a lot - solved the issue!

BW
Troels

-----Oprindelig meddelelse-----
Fra: Rui Barradas <ruipbarradas at sapo.pt> 
Sendt: 12. juli 2020 12:59
Til: tring at gvdnet.dk; r-help mailing list <r-help at r-project.org>
Emne: Re: [R] Rmpfr correlation

Hello,

Why not write a function COR? Not one as general purpose as stats::cor but a simple one, to compute the sample Pearson correlation only.


library(Rmpfr)

COR <- function(x, y){
   precBits <- getPrec(x)[1]
   n <- mpfr(length(x), precBits = precBits)
   x.bar <- mean(x)
   y.bar <- mean(y)
   numer <- sum(x*y) - n*x.bar*y.bar
   denom <- sqrt(sum(x*x) - n*x.bar*x.bar) * sqrt(sum(y*y) - n*y.bar*y.bar)
   numer/denom
}

set.seed(2020)
KA <- mpfr(10^-4.6, 128)
x <- rnorm(100)*KA
y <- rnorm(100)*x

cor(as.numeric(x), as.numeric(y)) # -0.1874986
#[1] -0.1874986

COR(x, y)
#1 'mpfr' number of precision  128   bits
#[1] -0.1874985950531874160800643775644747505073


Hope this helps,

Rui Barradas

?s 10:42 de 12/07/20, tring at gvdnet.dk escreveu:
> Dear friends - I'm calculating buffer capacities by different methods and
> need very high precision and package Rmpfr is working beautifully. However,
> I have not been able to find out how to keep precision when finding
> correlations.
> 
> library(Rmpfr)
> 
> KA <- mpfr(10^-4.6, 128)
> 
> x <- rnorm(100)*KA
> 
> y <- rnorm(100)*x
> 
> cor(x,y) # "x" must be numeric
> 
> cor(as.numeric(x),as.numeric(y))# 0.2918954
> 
>   
> 
> In my concrete application I get cor = 1 for
> cor(as.numeric(dff$BB),as.numeric(BBVS)) even though I have
> 
>   
> 
> str(summary((dff$BB)-(BBVS)))
> Class 'summaryMpfr' [package "Rmpfr"] of length 6 and precision 128
>   4.61351010833e-8 7.33418976521e-7 1.31009046563e-5 3.76407022709e-5
> 5.72386764888e-5 ...
> 
>   
> 
> I am on windows 10
> 
> R version 3.6.1
>   
> Best wishes
> Troels Ring,
> Aalborg, Denmark
> 
>   
> 
>   
> 
> 
> This email has been scanned by BullGuard antivirus protection.
> For more info visit www.bullguard.com
> <http://www.bullguard.com/tracking.aspx?affiliate=bullguard&buyaffiliate=smt
> p&url=/>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


This email has been scanned by BullGuard antivirus protection.
For more info visit www.bullguard.com


From ph@t@ch@u @end|ng |rom m@||@utoronto@c@  Sun Jul 12 15:52:18 2020
From: ph@t@ch@u @end|ng |rom m@||@utoronto@c@ (Phat Chau)
Date: Sun, 12 Jul 2020 13:52:18 +0000
Subject: [R] 
 Multi-level (nested) correlation structures via geepack package
Message-ID: <88023D7E-3BCB-4360-9899-8BF1583955E9@mail.utoronto.ca>

Hello,

I have a multi-level, cohort dataset with three levels: repeat measures of a response (level 1), that are collected from individual participants (level 2) who are students within a school (level 3). I would like to do a generalized estimating equation (GEE) analysis of this clustered data, but to do so I need to specify ?nested? correlation structures (e.g. exchangeable, compound symmetric, Toeplitz) to account for the within-individual and within-cluster correlations.

Here is a reference paper that describes a nested exchangeable correlation structure and nested compound symmetry: doi:10.1111/j.1541-0420.2009.01374.x.

The geepack is available in R to do GEE analyses, but it seems to me that it only allows the user to specify a correlation structure via the geepack(??corstr = ?) option which only accounts for the within-individual correlations (that arise from repeated measures). Would it be possible to specify the nested correlation structures that I refer to here to also account for the within-cluster correlations using this package?

Thank you,

Edward


	[[alternative HTML version deleted]]


From t|||@ny@deko|@ @end|ng |rom gm@||@com  Sun Jul 12 19:42:30 2020
From: t|||@ny@deko|@ @end|ng |rom gm@||@com (Tiffany Adekola)
Date: Sun, 12 Jul 2020 18:42:30 +0100
Subject: [R] Using Rvest to scrape pages
Message-ID: <CAFThPKw+b_QiB38gDz3DjNR4s7NxT5FePV86S0AKDF9v53PAAA@mail.gmail.com>

Dear All,

I am just learning how to use R programming. I want to extract reviews
from a page and loop till I extract for all pages:

#specify the first page URL
fpURL <- 'https://wordpress.org/support/plugin/easyrecipe/reviews/'

#read the HTML contents in the first page URL
contentfpURL <- read_html(fpURL)

#identify the anchor tags in the first page URL
fpAnchors <- html_nodes(contentfpURL, css='a.bbp-topic-permalink')

#extract the HREF attribute value of each anchor tag
fpHREF <- html_attr(fpAnchors, 'href')

#create empty lists to store titles & contents found in the HREF
attribute value of each anchor tag
titles = c()
contents = c()

#loop the following actions for each HREF found firstpage
for (u in fpHREF) {

   #read the HTML content of the review page
   fpURL = read_html(u)

  #identify the title anchor and read the title text
  fpreviewT = html_text(html_nodes(fpURL, css='h1.page-title'))

  #identify the content anchor and read the content text
  fpreviewC = html_text(html_nodes(fpURL, css='div.bbp-topic-content'))

  #store the review titles and contents in the previous lists
  titles = c(titles, fpreviewT)
  contents = c(contents, fpreviewC)
}
#identify the anchor tag pointing to the next summary page
npAnchor <- html_text(html_node(contentfpURL, css='a.next page-numbers'))

#extract the HREF attribute value of the anchor tag pointing to the
next summary page
npHREF <- html_attr(npAnchor, 'href')

#loop the following actions for every next summary page HREF attribute
for (u in npHREF) {

  #specify the URL of the summary page
  spURL <- read_html('npHREF')

  #identify all the anchor tags on that summary page
  spAnchors <- html_nodes(spURL, css='a.bbp-topic-permalink')

  #extract the HREF attribute value of each anchor tag
  spHREF <- html_attr(spAnchors, 'href')

  #loop the following actions for each HREF found on that summarypage

   for (u in fpHREF) {
     #read the HTML contents of the review page
     spURL = read_html(u)

      #identify the title anchor and read the title text
      spreviewT = html_text(html_nodes(spURL, css='h1.page-title'))

      #identify the content anchor and read the content text
      spreviewC = html_text(html_nodes(spURL, css='div.bbp-topic-content'))

      #store the review titles and contents in the previous lists
      titles = c(titles, spreviewT)
      contents = c(contents, spreviewC)
      }
}

I got stuck at the step to extract the HREF attribute value of the
anchor tag pointing to the next summary page with the error: Error in
UseMethod("xml_attr") :
  no applicable method for 'xml_attr' applied to an object of class "character"

 I will appreciate any help with this task.
Thanks in advance.

---Tiffany


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jul 12 21:09:10 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 12 Jul 2020 20:09:10 +0100
Subject: [R] How to differ stats_cor labels by group on a ggplot
In-Reply-To: <SN2PR03MB219071241A3258FEE35C46CC94630@SN2PR03MB2190.namprd03.prod.outlook.com>
References: <SN2PR03MB2190BDE30A1C31CDE2518B4494650@SN2PR03MB2190.namprd03.prod.outlook.com>
 <CA+8X3fXPPR6Y_+CaVAEwPc00SyGqK4rSQqVRZg9Rtsw6RuRNew@mail.gmail.com>
 <SN2PR03MB2190440F30A01F050243549A94620@SN2PR03MB2190.namprd03.prod.outlook.com>
 <CA+8X3fUPkawtQa4Fvj-L3ODgB5Ot=QnSWJeVw_Jrda0XYRQPMg@mail.gmail.com>
 <SN2PR03MB219071241A3258FEE35C46CC94630@SN2PR03MB2190.namprd03.prod.outlook.com>
Message-ID: <2981e1ad-7ea3-b686-aa78-d69a8b1d1607@sapo.pt>

Hello,

The code below puts the group names as subscripts to 'R'.
The trick is to create each of the labels with those names before 
pasting the ..p.label..
This is done by Map, calling a function f defined outside the for loop.

I have also changed your code a bit, simplifying parts of it.

1. I have named the data set df1, since df already is a base R function.
2. Instead of redefining theme() elements in the loop, I have created a 
custom one.
3. The for loop runs directly through the names of the data set df1, not 
through indices into them.
4. df1[[i]] is the same as unlist(df1[i]). And simpler.
5. After testing the code with df1[[i]], there were warnings, telling to 
use the pronoun .data, which I do.
6. The code repeated itself a lot, if you define aesthetics in the 
initial call to ggplot, there is no need to redefine them in the layers 
calls unless you are changing them. For instance, after

ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup)))


you don't have to define the same y and color again:

stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))


7. Some arguments (method = "pearson" and others) didn't change their 
default values and were removed.


Now the code.
Note that before writing to file, the filename is output to stdin, 
remove it, it's not part of your original code.



theme_custom_ps <- function(){

   theme_classic() %+replace%    # replace elements we want to change

     theme(axis.text.x = element_text(face = "bold", size = 14),
           axis.text.y = element_text(face = "bold", size = 14),
           axis.title.x = element_text(face = "bold", size = 14),
           axis.title.y = element_text(face = "bold", size = 14),
           legend.text = element_text(face = "bold", size = 14, colour = 
"black"),
           legend.title = element_text(size = 12, colour = "black")
     )
}


library(ggplot2)
library(ggpubr)

df1 <- read.table("sim_data.txt", header = TRUE)

group_name <- c("old", "young")
f <- function(grp, rlab) sub("R", paste0("R[", grp, "]"), rlab)

for (i in names(df1)[3:6]) {
   p1 <- ggplot(df1, mapping = aes(x = Age, y = .data[[i]], color = 
factor(AgeGroup))) +
     geom_point(size = 4) +
     geom_smooth(method = "lm", formula = y ~ x) +
     geom_smooth(mapping = aes(group = 1), method = "lm", formula = y ~ x) +
     stat_cor(aes(label = paste(Map(f, group_name, ..r.label..), 
..p.label.., sep = "~`,`~")),
              label.x.npc = "center",
              show.legend = FALSE) +
     stat_cor(aes(label = paste(sub("R", expression("R"[overall]), 
..r.label..), ..p.label.., sep = "~`,`~"),
                  group = 1, color = "black"),
              label.y = 0.5,
              label.x.npc = "center",
              position = position_nudge(y = 0.015 * 0.5),
              show.legend = FALSE) +
     scale_colour_discrete(name = "Group", labels = c("Young", "Old", 
"Overall")) +
     scale_x_continuous(breaks = seq(20, 90, by = 10)) +
     scale_y_continuous(breaks = seq(0.1, 0.5, by = 0.1)) +
     expand_limits(y = 0.5) +
     ylab(i) +
     theme_custom_ps()

   pngfile <- paste0("TestAge_", i, ".png")
   cat("filename:", pngfile, "\n")
   ggsave(p1, file = pngfile, scale = 1, width = 16, height = 10, units 
= "cm")
}


So it seems this is worth the effort after all.
Just trickier than expected.


Hope this helps,

Rui Barradas

?s 02:20 de 12/07/20, Paulina Skolasinska escreveu:
> Sorry for misspelling your name, Jim. Well, it seems this is not worth the effort then. If my advisor decides this is absolutely essential, I?ll add it in gimp or something. Thanks for giving it a go, Jim.
> 
> Get Outlook for iOS<https://aka.ms/o0ukef>
> ________________________________
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Saturday, July 11, 2020 6:32:13 PM
> To: Paulina Skolasinska <paulina.skol at hotmail.com>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] How to differ stats_cor labels by group on a ggplot
> 
> Hi Paulina,
> Thanks for the data. Even after downloading a ton of packages along
> with the "ggpubr" package, I get a namespace error when I try to load
> it. After a bit of wrangling, I did get the code to run without the
> "stat_cor" function, producing the four PNG images. My best guess is
> to try the geom_label function with stat="cor", but I can't see any
> argument to format the actual label. I think this is about as far as
> I'm going to get.
> 
> Jim
> 
> On Sun, Jul 12, 2020 at 12:09 AM Paulina Skolasinska
> <paulina.skol at hotmail.com> wrote:
>>
>> Thanks Tim, here is the link to the data: https://we.tl/t-c4x9Lw7LeR
>> I'm posting my code again so it better matches the modified data, and because I've added several improvements in the meantime.
>>
>> for (i in 3:6) {
>>      p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
>>          geom_smooth(method="lm") +
>>          geom_point(size = 4) +
>>          scale_x_continuous(breaks = seq(20,90, by=10)) +
>>          scale_y_continuous(breaks = seq(0.1,0.5, by=0.1)) +
>>          theme_classic() +
>>          expand_limits(y = 0.5) +
>>          ylab(names(df)[i]) +
>>          theme(axis.text.x = element_text(face="bold", size=14),
>>                axis.text.y = element_text(face="bold", size=14),
>>                axis.title.x = element_text(size=14, face="bold"),
>>                axis.title.y = element_text(size=14, face="bold"),
>>                legend.title = element_text(color="black", size=12),
>>                legend.text = element_text(colour="black", size = 14, face = "bold")) +
>>          geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
>>          scale_colour_discrete(name="Group", labels=c("Young", "Old", "Overall")) +
>>          stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i])),
>>                   method = "pearson", label.x.npc = c("center"), label.y.npc="top") +
>>          stat_cor(aes(x = Age, y = unlist(df[i]),
>>                   label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~"),
>>                   group=1, color="black"), method = "pearson",label.y=0.5, label.x.npc = c("center"),
>>                   position = position_nudge(y = 0.015 * 0.5))
>>
>>      ggsave(p1, file=paste0("TestAge_", names(df)[i], ".png"), scale=1, width=16, height=10, units="cm")
>> }
>>
>>
>> ________________________________
>> Od: Jim Lemon <drjimlemon at gmail.com>
>> Wys?ane: sobota, 11 lipca 2020 04:09
>> Do: Paulina Skolasinska <paulina.skol at hotmail.com>
>> DW: r-help at r-project.org <r-help at r-project.org>
>> Temat: Re: [R] How to differ stats_cor labels by group on a ggplot
>>
>> Hi Paulina,
>> Without data it's hard to work out what you are doing. Even a small
>> simulated data set would help to get answers.
>>
>> Jim
>>
>> On Fri, Jul 10, 2020 at 11:49 PM Paulina Skolasinska
>> <paulina.skol at hotmail.com> wrote:
>>>
>>> 'm using ggplot2 to plot two variables at a time. I'm plotting two age groups and overall data on the same graph. I'm also using stat_cor form the ggpubr package to report correlations for the two groups and overall data.
>>>
>>> I want each stat_cor label to have a custom subscript - the group name ("old", "young"). I have managed to do this for the overall data, but I don't know how to add custom labels for each group separately. I'd like the labels to look like this: https://imgur.com/a/naF7uNW
>>>
>>>> for (i in 18:21) {
>>>    p1 <- ggplot(df, mapping=aes(x = Age, y = unlist(df[i]), color=factor(AgeGroup))) +
>>>      geom_smooth(method="lm") +
>>>      geom_point(size = 4) +
>>>      geom_smooth(data=df, mapping = aes(x = Age, y = unlist(df[i]), group=1, color="black"), method = "lm") +
>>>      scale_colour_discrete(name="Group", labels=c("young", "old", "overall")) +
>>>      stat_cor(aes(color = factor(AgeGroup), y = unlist(df[i]))) +
>>>      stat_cor(aes(x = Age, y = unlist(df[i]), group=1, color="black",
>>>                   label = paste(sub("R",expression("R"[overall]),..r.label..), ..p.label.., sep = "~`,`~")))
>>>
>>>    ggsave(p1, file=paste0("Age_", names(df)[i], ".png"), scale=1)
>>> }
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jul 12 22:18:37 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 12 Jul 2020 13:18:37 -0700
Subject: [R] 
 Multi-level (nested) correlation structures via geepack package
In-Reply-To: <88023D7E-3BCB-4360-9899-8BF1583955E9@mail.utoronto.ca>
References: <88023D7E-3BCB-4360-9899-8BF1583955E9@mail.utoronto.ca>
Message-ID: <CAGxFJbThBKgLczG5w7VJ=U9-aETKPoD+AN2uP1fLy=pA8qhzAw@mail.gmail.com>

You may get lucky, but generally such package-specific questions don't get
responses here. There are about 20000 packages after all. You might do
better posting on the r-sig-mixed-models list or by asking the package
maintainer (?maintainer) whether there is some sort of support list for the
package.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jul 12, 2020 at 9:59 AM Phat Chau <phat.chau at mail.utoronto.ca>
wrote:

> Hello,
>
> I have a multi-level, cohort dataset with three levels: repeat measures of
> a response (level 1), that are collected from individual participants
> (level 2) who are students within a school (level 3). I would like to do a
> generalized estimating equation (GEE) analysis of this clustered data, but
> to do so I need to specify ?nested? correlation structures (e.g.
> exchangeable, compound symmetric, Toeplitz) to account for the
> within-individual and within-cluster correlations.
>
> Here is a reference paper that describes a nested exchangeable correlation
> structure and nested compound symmetry:
> doi:10.1111/j.1541-0420.2009.01374.x.
>
> The geepack is available in R to do GEE analyses, but it seems to me that
> it only allows the user to specify a correlation structure via the
> geepack(??corstr = ?) option which only accounts for the within-individual
> correlations (that arise from repeated measures). Would it be possible to
> specify the nested correlation structures that I refer to here to also
> account for the within-cluster correlations using this package?
>
> Thank you,
>
> Edward
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jul 13 01:28:50 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 12 Jul 2020 16:28:50 -0700
Subject: [R] Using Rvest to scrape pages
In-Reply-To: <CAFThPKw+b_QiB38gDz3DjNR4s7NxT5FePV86S0AKDF9v53PAAA@mail.gmail.com>
References: <CAFThPKw+b_QiB38gDz3DjNR4s7NxT5FePV86S0AKDF9v53PAAA@mail.gmail.com>
Message-ID: <b7e06018-7626-96dd-235a-a236b12e5c99@comcast.net>


On 7/12/20 10:42 AM, Tiffany Adekola wrote:
> Dear All,
>
> I am just learning how to use R programming. I want to extract reviews
> from a page and loop till I extract for all pages:
>
> #specify the first page URL
> fpURL <- 'https://wordpress.org/support/plugin/easyrecipe/reviews/'
>
> #read the HTML contents in the first page URL
> contentfpURL <- read_html(fpURL)
>
> #identify the anchor tags in the first page URL
> fpAnchors <- html_nodes(contentfpURL, css='a.bbp-topic-permalink')
>
> #extract the HREF attribute value of each anchor tag
> fpHREF <- html_attr(fpAnchors, 'href')
>
> #create empty lists to store titles & contents found in the HREF
> attribute value of each anchor tag
> titles = c()
> contents = c()
>
> #loop the following actions for each HREF found firstpage
> for (u in fpHREF) {
>
>     #read the HTML content of the review page
>     fpURL = read_html(u)
>
>    #identify the title anchor and read the title text
>    fpreviewT = html_text(html_nodes(fpURL, css='h1.page-title'))
>
>    #identify the content anchor and read the content text
>    fpreviewC = html_text(html_nodes(fpURL, css='div.bbp-topic-content'))
>
>    #store the review titles and contents in the previous lists
>    titles = c(titles, fpreviewT)
>    contents = c(contents, fpreviewC)
> }
> #identify the anchor tag pointing to the next summary page
> npAnchor <- html_text(html_node(contentfpURL, css='a.next page-numbers'))
>
> #extract the HREF attribute value of the anchor tag pointing to the
> next summary page
> npHREF <- html_attr(npAnchor, 'href')


The error occurs with the line above, but if you look at the argument to 
`html_attr` you see that the problem is higher up

str(npAnchor)
# chr NA

Perhaps the problem occurs here:


html_node(contentfpURL, css='a.next page-numbers')
#{xml_missing}
#<NA>

-- 

David.

>
> #loop the following actions for every next summary page HREF attribute
> for (u in npHREF) {
>
>    #specify the URL of the summary page
>    spURL <- read_html('npHREF')
>
>    #identify all the anchor tags on that summary page
>    spAnchors <- html_nodes(spURL, css='a.bbp-topic-permalink')
>
>    #extract the HREF attribute value of each anchor tag
>    spHREF <- html_attr(spAnchors, 'href')
>
>    #loop the following actions for each HREF found on that summarypage
>
>     for (u in fpHREF) {
>       #read the HTML contents of the review page
>       spURL = read_html(u)
>
>        #identify the title anchor and read the title text
>        spreviewT = html_text(html_nodes(spURL, css='h1.page-title'))
>
>        #identify the content anchor and read the content text
>        spreviewC = html_text(html_nodes(spURL, css='div.bbp-topic-content'))
>
>        #store the review titles and contents in the previous lists
>        titles = c(titles, spreviewT)
>        contents = c(contents, spreviewC)
>        }
> }
>
> I got stuck at the step to extract the HREF attribute value of the
> anchor tag pointing to the next summary page with the error: Error in
> UseMethod("xml_attr") :
>    no applicable method for 'xml_attr' applied to an object of class "character"
>
>   I will appreciate any help with this task.
> Thanks in advance.
>
> ---Tiffany
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From du|c@|m@ @end|ng |rom b|gpond@com  Mon Jul 13 05:06:32 2020
From: du|c@|m@ @end|ng |rom b|gpond@com (dulcalma dulcalma)
Date: Mon, 13 Jul 2020 13:06:32 +1000 (AEST)
Subject: [R] 
 Multi-level (nested) correlation structures via geepack package
In-Reply-To: <88023D7E-3BCB-4360-9899-8BF1583955E9@mail.utoronto.ca>
References: <88023D7E-3BCB-4360-9899-8BF1583955E9@mail.utoronto.ca>
Message-ID: <6ede047e.abb46.17346236796.Webtop.96@bigpond.com>

Hi

Your choice of package should partly depend on the type of dependent 
variable or Y that you are going to be dealing with
categorical/ordinal data may involve different packages than continuous 
or binary data see multgee for one.
The number of samples can also make a difference GEE with the "correct 
model" should normally have no problems with numbers 30-40; 25 or less 
would normally require corrections and a diffence package.

The doi for multgee  paper is 10.1111/biom.12054 and Touloumis paper in 
Journal of Statistical Software

For longitudinal data there is the following doi:
10.2307/2531248
and
10.1097/EDE.0b013e3181caeb90
10.1093/biomet/90.1.29
10.1007/s00362-017-0881-0
10.1002/sim.2368

a search for gee in the list of available packages should show you the 
alternatives.

As a check of the result do the statistics on another package. I 
remember doing a simple gee with an example
from a book using 4 different packages 2 of which gave poor or 
unreasonable answers

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
ARMIDALE NSW 2351



------ Original Message ------
From: "Phat Chau" <phat.chau at mail.utoronto.ca>
To: "r-help at R-project.org" <r-help at R-project.org>; "sorenh at math.aau.dk" 
<sorenh at math.aau.dk>
Sent: Sunday, 12 Jul, 2020 At 11:52 PM
Subject: Re: [R]  Multi-level (nested) correlation structures via 
geepack package

Hello,

I have a multi-level, cohort dataset with three levels: repeat measures 
of a response (level 1), that are collected from individual participants 
(level 2) who are students within a school (level 3). I would like to do 
a generalized estimating equation (GEE) analysis of this clustered data, 
but to do so I need to specify ?nested? correlation structures (e.g. 
exchangeable, compound symmetric, Toeplitz) to account for the 
within-individual and within-cluster correlations.

Here is a reference paper that describes a nested exchangeable 
correlation structure and nested compound symmetry: 
doi:10.1111/j.1541-0420.2009.01374.x.

The geepack is available in R to do GEE analyses, but it seems to me 
that it only allows the user to specify a correlation structure via the 
geepack(??corstr = ?) option which only accounts for the 
within-individual correlations (that arise from repeated measures). 
Would it be possible to specify the nested correlation structures that I 
refer to here to also account for the within-cluster correlations using 
this package?

Thank you,

Edward


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wewo|@k| @end|ng |rom gm@||@com  Mon Jul 13 15:41:45 2020
From: wewo|@k| @end|ng |rom gm@||@com (Witold E Wolski)
Date: Mon, 13 Jul 2020 15:41:45 +0200
Subject: [R] brms does not work with R4.0.2
Message-ID: <CAAjnpdiimUb+pC=joU3QfVvrrS9W7sXOcOyvDxkAEdSOhu+tAQ@mail.gmail.com>

Hello,

I upgraded today to R4.0.2 from 3.6.3 on my Windows machine (actually
2 of them - first desktop and then laptop just to verify the problem)
and on both of them I am getting the following error when running the
brms::brm function example code.

```
> bprior1 <- prior(student_t(5,0,10), class = b) +
+     prior(cauchy(0,2), class = sd)
> fit1 <- brm(count ~ zAge + zBase * Trt + (1|patient),
+             data = epilepsy, family = poisson(), prior = bprior1)
Compiling the C++ model
>
> fit1
Error: object 'fit1' not found
```

I tried to get some more information by setting `silent = FALSE` but
nothing is being printed.
All I see is:

```
> brm(count ~ zAge + zBase * Trt + (1|patient),
+     data = epilepsy, family = poisson(), prior = bprior1, silent=FALSE)
Compiling the C++ model
>
```

R tools is installed and I did test that they work properly.
Also:

```
system.file(package = "StanHeaders")
[1] "C:/Users/wewol/OneDrive/Documents/R/win-library/4.0/StanHeaders"
```

Help highly appreciated.

Witek
--
Witold Eryk Wolski


From @xe|@urb|z @end|ng |rom gm@||@com  Mon Jul 13 15:54:03 2020
From: @xe|@urb|z @end|ng |rom gm@||@com (Axel Urbiz)
Date: Mon, 13 Jul 2020 09:54:03 -0400
Subject: [R] lme4 - Mixed Model question
Message-ID: <E45A3535-F886-44AB-95EB-AF2F7EFC95EB@gmail.com>

Dear List, 

I?d appreciate any guidance on the following. 

I?m using a mixed effects logistic regression model, to allow coefficients to vary by a group variable. However, my case is not typical in the sense that I need to specify a different set of covariates for each level of the group variable. Say I have 3 covariates {x1, x2, x3} and 2 groups {g1, g2}. I want to specify a model for g1 that only depends on x1 and x2, and a model for g2 that only depends on x2 and x3. 

Is this possible with lme4?

Thanks,
Axel. 


From wewo|@k| @end|ng |rom gm@||@com  Mon Jul 13 15:55:35 2020
From: wewo|@k| @end|ng |rom gm@||@com (Witold E Wolski)
Date: Mon, 13 Jul 2020 15:55:35 +0200
Subject: [R] brms does not work with R4.0.2
In-Reply-To: <CAAjnpdiimUb+pC=joU3QfVvrrS9W7sXOcOyvDxkAEdSOhu+tAQ@mail.gmail.com>
References: <CAAjnpdiimUb+pC=joU3QfVvrrS9W7sXOcOyvDxkAEdSOhu+tAQ@mail.gmail.com>
Message-ID: <CAAjnpdgcFu5upjG9ozNSS8Foh1JD9hJKbdiZkJ2Lh1JHqhYe4w@mail.gmail.com>

Hello,

Got the following info from the brms package Maintainer.

"This is a caused by a problem in the current rstan CRAN version on
Windows and is not related to brms. You can find various threads that
deal with that topic on https://discourse.mc-stan.org/. For now, it
may be easiest to revert to rstan 2.19.3."

Thanks
Witek



On Mon, 13 Jul 2020 at 15:41, Witold E Wolski <wewolski at gmail.com> wrote:
>
> Hello,
>
> I upgraded today to R4.0.2 from 3.6.3 on my Windows machine (actually
> 2 of them - first desktop and then laptop just to verify the problem)
> and on both of them I am getting the following error when running the
> brms::brm function example code.
>
> ```
> > bprior1 <- prior(student_t(5,0,10), class = b) +
> +     prior(cauchy(0,2), class = sd)
> > fit1 <- brm(count ~ zAge + zBase * Trt + (1|patient),
> +             data = epilepsy, family = poisson(), prior = bprior1)
> Compiling the C++ model
> >
> > fit1
> Error: object 'fit1' not found
> ```
>
> I tried to get some more information by setting `silent = FALSE` but
> nothing is being printed.
> All I see is:
>
> ```
> > brm(count ~ zAge + zBase * Trt + (1|patient),
> +     data = epilepsy, family = poisson(), prior = bprior1, silent=FALSE)
> Compiling the C++ model
> >
> ```
>
> R tools is installed and I did test that they work properly.
> Also:
>
> ```
> system.file(package = "StanHeaders")
> [1] "C:/Users/wewol/OneDrive/Documents/R/win-library/4.0/StanHeaders"
> ```
>
> Help highly appreciated.
>
> Witek
> --
> Witold Eryk Wolski



-- 
Witold Eryk Wolski


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jul 13 16:15:36 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 13 Jul 2020 16:15:36 +0200
Subject: [R] lme4 - Mixed Model question
In-Reply-To: <E45A3535-F886-44AB-95EB-AF2F7EFC95EB@gmail.com>
References: <E45A3535-F886-44AB-95EB-AF2F7EFC95EB@gmail.com>
Message-ID: <CAJuCY5yC0bpisBfQ9qKC=JKBcUqxSzA3s_HMJwJ1HZP0uPXWuw@mail.gmail.com>

Dear Axel,

A few quick remarks.

1) This question is more suitable for r-sig-mixed-models.
2) A mixed model needs much more than two groups. If you have only a few
groups, consider a glm with group interactions.
3) Setting the value of a covariate to zero for a set of observations has
the same effect as setting its coefficient to zero for that set of
observations.

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 13 jul. 2020 om 16:00 schreef Axel Urbiz <axel.urbiz at gmail.com>:

> Dear List,
>
> I?d appreciate any guidance on the following.
>
> I?m using a mixed effects logistic regression model, to allow coefficients
> to vary by a group variable. However, my case is not typical in the sense
> that I need to specify a different set of covariates for each level of the
> group variable. Say I have 3 covariates {x1, x2, x3} and 2 groups {g1, g2}.
> I want to specify a model for g1 that only depends on x1 and x2, and a
> model for g2 that only depends on x2 and x3.
>
> Is this possible with lme4?
>
> Thanks,
> Axel.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jul 13 20:40:37 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 13 Jul 2020 13:40:37 -0500
Subject: [R] Issues whenWorking with Daily Time Series and Generating
 Forecasts
Message-ID: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>

Dear friends, hope you are doing great,

I am working with a daily time series, the series starts on march,10, 2020
until july 9th, 2020.

I would like to know if there is a way to make it a ts object, specifying
the year, month and day with the ts function.

First, I tried setting the ts object as follows:

trainingts <- ts(Dataset2$PANCASES, frequency=7)

but when I plot trainingts, the x-axis (time axis) shows values like 5, 10,
15 and not the dates.

Secondly, I tried doing the following

trainingts2 <- ts(Dataset2$PANCASES, start=c(2020,3,10), end=c(2020,7,9),
frequency=365.25)

but with this setup, now the x-axis has extrange values like 2020.006,
2020.008, etc.

Now, when generating forecasts with auto.arima function I get extremely
large values for the y-axis, which makes the forecasts look like a flat
line:

trainingts <- ts(Dataset2$PANCASES, frequency=7)

ModelArima2 <- auto.arima(trainingts, lambda=0)
ModelArima2For <- forecast(ModelArima2, h=30)
plot(ModelArima2For)

I am providing the dput() for my dataset below.

Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

 > dput(Dataset2)
structure(list(DATE = structure(c(18331, 18332, 18333, 18334,
18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343,
18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352,
18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361,
18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370,
18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388,
18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397,
18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406,
18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415,
18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424,
18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433,
18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442,
18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
18452), class = "Date"), PANCASES = c(1, 8, 11, 27, 36, 43, 55,
69, 86, 109, 137, 200, 313, 345, 345, 443, 558, 674, 786, 901,
989, 1181, 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210, 4273, 4467,
4658, 4821, 5166, 5338, 5538, 5779, 6021, 6021, 6378, 6532, 6720,
7090, 7090, 7197, 7523, 7731, 7868, 8070, 8282, 8448, 8616, 8783,
8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267,
10577, 10926, 11183, 11447, 11728, 12131, 12531, 13018, 13463,
13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854, 17233,
17889, 18586, 19211, 20059, 21418, 21422, 21962, 22597, 23351,
24274, 25222, 26030, 26752, 27314, 28030, 29037, 29905, 30658,
31686, 32785, 33550, 34463, 35237, 35995, 36983, 38149, 39334,
40291, 41251, 42216)), row.names = c(NA, -122L), class = "data.frame")

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Jul 13 20:44:27 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 13 Jul 2020 12:44:27 -0600
Subject: [R] Issues whenWorking with Daily Time Series and Generating
 Forecasts
In-Reply-To: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
References: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
Message-ID: <CACxE24=O=ZFfF3x=Ui50avGwSyTCGxKz0yJJnmFqeA2MBbqi3g@mail.gmail.com>

Hi Paul

Have you looked at the xts or zoo packages, please?

They work very well on daily series.

Thanks,
Erin

On Mon, Jul 13, 2020 at 12:41 PM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends, hope you are doing great,
>
> I am working with a daily time series, the series starts on march,10, 2020
> until july 9th, 2020.
>
> I would like to know if there is a way to make it a ts object, specifying
> the year, month and day with the ts function.
>
> First, I tried setting the ts object as follows:
>
> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>
> but when I plot trainingts, the x-axis (time axis) shows values like 5, 10,
> 15 and not the dates.
>
> Secondly, I tried doing the following
>
> trainingts2 <- ts(Dataset2$PANCASES, start=c(2020,3,10), end=c(2020,7,9),
> frequency=365.25)
>
> but with this setup, now the x-axis has extrange values like 2020.006,
> 2020.008, etc.
>
> Now, when generating forecasts with auto.arima function I get extremely
> large values for the y-axis, which makes the forecasts look like a flat
> line:
>
> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>
> ModelArima2 <- auto.arima(trainingts, lambda=0)
> ModelArima2For <- forecast(ModelArima2, h=30)
> plot(ModelArima2For)
>
> I am providing the dput() for my dataset below.
>
> Any help and/or guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>  > dput(Dataset2)
> structure(list(DATE = structure(c(18331, 18332, 18333, 18334,
> 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343,
> 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352,
> 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361,
> 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370,
> 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388,
> 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397,
> 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406,
> 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415,
> 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424,
> 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433,
> 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442,
> 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
> 18452), class = "Date"), PANCASES = c(1, 8, 11, 27, 36, 43, 55,
> 69, 86, 109, 137, 200, 313, 345, 345, 443, 558, 674, 786, 901,
> 989, 1181, 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210, 4273, 4467,
> 4658, 4821, 5166, 5338, 5538, 5779, 6021, 6021, 6378, 6532, 6720,
> 7090, 7090, 7197, 7523, 7731, 7868, 8070, 8282, 8448, 8616, 8783,
> 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267,
> 10577, 10926, 11183, 11447, 11728, 12131, 12531, 13018, 13463,
> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854, 17233,
> 17889, 18586, 19211, 20059, 21418, 21422, 21962, 22597, 23351,
> 24274, 25222, 26030, 26752, 27314, 28030, 29037, 29905, 30658,
> 31686, 32785, 33550, 34463, 35237, 35995, 36983, 38149, 39334,
> 40291, 41251, 42216)), row.names = c(NA, -122L), class = "data.frame")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jul 13 22:35:41 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 13 Jul 2020 22:35:41 +0200
Subject: [R] How to install libisl.so.19 on chromebook?
Message-ID: <CAMk+s2S8M9L3tZ5wu_g4yhjD2ejXmBViEhcFiyVe+PDORAmUZg@mail.gmail.com>

I am trying to install minpack.lm on R 3.3.3 on a Chromebook. But I
get this error:
```
> install.packages("minpack.lm")
Installing package into ?/home/marongiuluigi/R/x86_64-pc-linux-gnu-library/3.3?
(as ?lib? is unspecified)
trying URL 'https://cran.rstudio.com/src/contrib/minpack.lm_1.2-1.tar.gz'
Content type 'application/x-gzip' length 43029 bytes (42 KB)
==================================================
downloaded 42 KB

* installing *source* package ?minpack.lm? ...
** package ?minpack.lm? successfully unpacked and MD5 sums checked
** libs
gfortran   -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-3.3.3=.
-fstack-protector-strong  -c chkder.f -o chkder.o
/usr/local/libexec/gcc/x86_64-cros-linux-gnu/8.3.0/f951: error while
loading shared libraries: libisl.so.19: cannot open shared object
file: No such file or directory
/usr/lib/R/etc/Makeconf:155: recipe for target 'chkder.o' failed
make: *** [chkder.o] Error 1
ERROR: compilation failed for package ?minpack.lm?
* removing ?/home/marongiuluigi/R/x86_64-pc-linux-gnu-library/3.3/minpack.lm?
Warning in install.packages :
  installation of package ?minpack.lm? had non-zero exit status
```
I tried to install  libisl.so.19 but:
```
$ sudo apt-get install libisl19
Reading package lists... Done
Building dependency tree
Reading state information... Done
E: Unable to locate package libisl19
```
I downloaded libisl.so.19 for debian, but where shall I place it?
Is there an easier way to install this library?
Thank you


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jul 14 00:11:08 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 13 Jul 2020 15:11:08 -0700
Subject: [R] How to install libisl.so.19 on chromebook?
In-Reply-To: <CAMk+s2S8M9L3tZ5wu_g4yhjD2ejXmBViEhcFiyVe+PDORAmUZg@mail.gmail.com>
References: <CAMk+s2S8M9L3tZ5wu_g4yhjD2ejXmBViEhcFiyVe+PDORAmUZg@mail.gmail.com>
Message-ID: <9EFA7F96-6B3F-40B9-9104-C9D5F67C8914@dcn.davis.ca.us>

This question is off topic here (it is not about R... read the Posting Guide... contributed packages are not R), but... it is not AFAIK possible to install R on ChromeOS though you can install it within the "Linux (Beta)" container, which comes by default with the Debian distribution.

Assuming you have not altered this (your confusion about which operating system you are interacting with suggests not?) then go ask this question on R-sig-debian.

FWIW I think the description for this package is deficient... it should mention this system dependency. [1]

[1] https://cran.r-project.org/web/packages/minpack.lm/index.html

On July 13, 2020 1:35:41 PM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>I am trying to install minpack.lm on R 3.3.3 on a Chromebook. But I
>get this error:
>```
>> install.packages("minpack.lm")
>Installing package into
>?/home/marongiuluigi/R/x86_64-pc-linux-gnu-library/3.3?
>(as ?lib? is unspecified)
>trying URL
>'https://cran.rstudio.com/src/contrib/minpack.lm_1.2-1.tar.gz'
>Content type 'application/x-gzip' length 43029 bytes (42 KB)
>==================================================
>downloaded 42 KB
>
>* installing *source* package ?minpack.lm? ...
>** package ?minpack.lm? successfully unpacked and MD5 sums checked
>** libs
>gfortran   -fpic  -g -O2 -fdebug-prefix-map=/build/r-base-3.3.3=.
>-fstack-protector-strong  -c chkder.f -o chkder.o
>/usr/local/libexec/gcc/x86_64-cros-linux-gnu/8.3.0/f951: error while
>loading shared libraries: libisl.so.19: cannot open shared object
>file: No such file or directory
>/usr/lib/R/etc/Makeconf:155: recipe for target 'chkder.o' failed
>make: *** [chkder.o] Error 1
>ERROR: compilation failed for package ?minpack.lm?
>* removing
>?/home/marongiuluigi/R/x86_64-pc-linux-gnu-library/3.3/minpack.lm?
>Warning in install.packages :
>  installation of package ?minpack.lm? had non-zero exit status
>```
>I tried to install  libisl.so.19 but:
>```
>$ sudo apt-get install libisl19
>Reading package lists... Done
>Building dependency tree
>Reading state information... Done
>E: Unable to locate package libisl19
>```
>I downloaded libisl.so.19 for debian, but where shall I place it?
>Is there an easier way to install this library?
>Thank you
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Jul 14 00:35:51 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 13 Jul 2020 17:35:51 -0500
Subject: [R] Issues whenWorking with Daily Time Series and Generating
 Forecasts
In-Reply-To: <CACxE24=O=ZFfF3x=Ui50avGwSyTCGxKz0yJJnmFqeA2MBbqi3g@mail.gmail.com>
References: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
 <CACxE24=O=ZFfF3x=Ui50avGwSyTCGxKz0yJJnmFqeA2MBbqi3g@mail.gmail.com>
Message-ID: <CAMOcQfOJ-DwC7uRupO7SuTDaD1Nm6aadkZkNDnkYQ5N+9LBsGg@mail.gmail.com>

Dear friend Erin,

Thank you so much for your kind reply. I have not tried xts nor zoo, but I
will give it a shot and let you know how it goes.

Best regards,

Paul

El lun., 13 jul. 2020 a las 13:44, Erin Hodgess (<erinm.hodgess at gmail.com>)
escribi?:

> Hi Paul
>
> Have you looked at the xts or zoo packages, please?
>
> They work very well on daily series.
>
> Thanks,
> Erin
>
> On Mon, Jul 13, 2020 at 12:41 PM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear friends, hope you are doing great,
>>
>> I am working with a daily time series, the series starts on march,10, 2020
>> until july 9th, 2020.
>>
>> I would like to know if there is a way to make it a ts object, specifying
>> the year, month and day with the ts function.
>>
>> First, I tried setting the ts object as follows:
>>
>> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>>
>> but when I plot trainingts, the x-axis (time axis) shows values like 5,
>> 10,
>> 15 and not the dates.
>>
>> Secondly, I tried doing the following
>>
>> trainingts2 <- ts(Dataset2$PANCASES, start=c(2020,3,10), end=c(2020,7,9),
>> frequency=365.25)
>>
>> but with this setup, now the x-axis has extrange values like 2020.006,
>> 2020.008, etc.
>>
>> Now, when generating forecasts with auto.arima function I get extremely
>> large values for the y-axis, which makes the forecasts look like a flat
>> line:
>>
>> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>>
>> ModelArima2 <- auto.arima(trainingts, lambda=0)
>> ModelArima2For <- forecast(ModelArima2, h=30)
>> plot(ModelArima2For)
>>
>> I am providing the dput() for my dataset below.
>>
>> Any help and/or guidance will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>  > dput(Dataset2)
>> structure(list(DATE = structure(c(18331, 18332, 18333, 18334,
>> 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343,
>> 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352,
>> 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361,
>> 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370,
>> 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388,
>> 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397,
>> 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406,
>> 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415,
>> 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424,
>> 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433,
>> 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442,
>> 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>> 18452), class = "Date"), PANCASES = c(1, 8, 11, 27, 36, 43, 55,
>> 69, 86, 109, 137, 200, 313, 345, 345, 443, 558, 674, 786, 901,
>> 989, 1181, 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210, 4273, 4467,
>> 4658, 4821, 5166, 5338, 5538, 5779, 6021, 6021, 6378, 6532, 6720,
>> 7090, 7090, 7197, 7523, 7731, 7868, 8070, 8282, 8448, 8616, 8783,
>> 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267,
>> 10577, 10926, 11183, 11447, 11728, 12131, 12531, 13018, 13463,
>> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854, 17233,
>> 17889, 18586, 19211, 20059, 21418, 21422, 21962, 22597, 23351,
>> 24274, 25222, 26030, 26752, 27314, 28030, 29037, 29905, 30658,
>> 31686, 32785, 33550, 34463, 35237, 35995, 36983, 38149, 39334,
>> 40291, 41251, 42216)), row.names = c(NA, -122L), class = "data.frame")
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Tue Jul 14 02:10:32 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 13 Jul 2020 18:10:32 -0600
Subject: [R] Issues whenWorking with Daily Time Series and Generating
 Forecasts
In-Reply-To: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
References: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
Message-ID: <CACxE24nuLXBqhdq-FSDL=H-rwkaN4_uUH+CQbMPp1=+roRt9cA@mail.gmail.com>

Hi again, Paul!

When you are plotting the final product, do you want both the original
series, the fitted values, and the forecast, please?

I am messing around with your data.

Thanks,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Mon, Jul 13, 2020 at 12:41 PM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends, hope you are doing great,
>
> I am working with a daily time series, the series starts on march,10, 2020
> until july 9th, 2020.
>
> I would like to know if there is a way to make it a ts object, specifying
> the year, month and day with the ts function.
>
> First, I tried setting the ts object as follows:
>
> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>
> but when I plot trainingts, the x-axis (time axis) shows values like 5, 10,
> 15 and not the dates.
>
> Secondly, I tried doing the following
>
> trainingts2 <- ts(Dataset2$PANCASES, start=c(2020,3,10), end=c(2020,7,9),
> frequency=365.25)
>
> but with this setup, now the x-axis has extrange values like 2020.006,
> 2020.008, etc.
>
> Now, when generating forecasts with auto.arima function I get extremely
> large values for the y-axis, which makes the forecasts look like a flat
> line:
>
> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>
> ModelArima2 <- auto.arima(trainingts, lambda=0)
> ModelArima2For <- forecast(ModelArima2, h=30)
> plot(ModelArima2For)
>
> I am providing the dput() for my dataset below.
>
> Any help and/or guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>  > dput(Dataset2)
> structure(list(DATE = structure(c(18331, 18332, 18333, 18334,
> 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343,
> 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352,
> 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361,
> 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370,
> 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388,
> 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397,
> 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406,
> 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415,
> 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424,
> 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433,
> 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442,
> 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
> 18452), class = "Date"), PANCASES = c(1, 8, 11, 27, 36, 43, 55,
> 69, 86, 109, 137, 200, 313, 345, 345, 443, 558, 674, 786, 901,
> 989, 1181, 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210, 4273, 4467,
> 4658, 4821, 5166, 5338, 5538, 5779, 6021, 6021, 6378, 6532, 6720,
> 7090, 7090, 7197, 7523, 7731, 7868, 8070, 8282, 8448, 8616, 8783,
> 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267,
> 10577, 10926, 11183, 11447, 11728, 12131, 12531, 13018, 13463,
> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854, 17233,
> 17889, 18586, 19211, 20059, 21418, 21422, 21962, 22597, 23351,
> 24274, 25222, 26030, 26752, 27314, 28030, 29037, 29905, 30658,
> 31686, 32785, 33550, 34463, 35237, 35995, 36983, 38149, 39334,
> 40291, 41251, 42216)), row.names = c(NA, -122L), class = "data.frame")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Jul 14 02:58:33 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 13 Jul 2020 19:58:33 -0500
Subject: [R] Issues whenWorking with Daily Time Series and Generating
 Forecasts
In-Reply-To: <CACxE24nuLXBqhdq-FSDL=H-rwkaN4_uUH+CQbMPp1=+roRt9cA@mail.gmail.com>
References: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
 <CACxE24nuLXBqhdq-FSDL=H-rwkaN4_uUH+CQbMPp1=+roRt9cA@mail.gmail.com>
Message-ID: <CAMOcQfPi99aeq=w+-hES5_xqh9+siJdQYJCDOvuuVT8hje7UHw@mail.gmail.com>

Dear friend, yes,

When I generate the forecasts i want the output to include the original
series, the fitted vaules and the forecast and I want the x-axis to show
all dates (both the dates of the historical series plus the future dares in
YYYY-mm-dd format).

Thank you so much for your kind and valuable help.

Cheers,

Paul


El lun., 13 de julio de 2020 7:10 p. m., Erin Hodgess <
erinm.hodgess at gmail.com> escribi?:

> Hi again, Paul!
>
> When you are plotting the final product, do you want both the original
> series, the fitted values, and the forecast, please?
>
> I am messing around with your data.
>
> Thanks,
> Erin
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>
> On Mon, Jul 13, 2020 at 12:41 PM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear friends, hope you are doing great,
>>
>> I am working with a daily time series, the series starts on march,10, 2020
>> until july 9th, 2020.
>>
>> I would like to know if there is a way to make it a ts object, specifying
>> the year, month and day with the ts function.
>>
>> First, I tried setting the ts object as follows:
>>
>> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>>
>> but when I plot trainingts, the x-axis (time axis) shows values like 5,
>> 10,
>> 15 and not the dates.
>>
>> Secondly, I tried doing the following
>>
>> trainingts2 <- ts(Dataset2$PANCASES, start=c(2020,3,10), end=c(2020,7,9),
>> frequency=365.25)
>>
>> but with this setup, now the x-axis has extrange values like 2020.006,
>> 2020.008, etc.
>>
>> Now, when generating forecasts with auto.arima function I get extremely
>> large values for the y-axis, which makes the forecasts look like a flat
>> line:
>>
>> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>>
>> ModelArima2 <- auto.arima(trainingts, lambda=0)
>> ModelArima2For <- forecast(ModelArima2, h=30)
>> plot(ModelArima2For)
>>
>> I am providing the dput() for my dataset below.
>>
>> Any help and/or guidance will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>  > dput(Dataset2)
>> structure(list(DATE = structure(c(18331, 18332, 18333, 18334,
>> 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343,
>> 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352,
>> 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361,
>> 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370,
>> 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388,
>> 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397,
>> 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406,
>> 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415,
>> 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424,
>> 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433,
>> 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442,
>> 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>> 18452), class = "Date"), PANCASES = c(1, 8, 11, 27, 36, 43, 55,
>> 69, 86, 109, 137, 200, 313, 345, 345, 443, 558, 674, 786, 901,
>> 989, 1181, 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210, 4273, 4467,
>> 4658, 4821, 5166, 5338, 5538, 5779, 6021, 6021, 6378, 6532, 6720,
>> 7090, 7090, 7197, 7523, 7731, 7868, 8070, 8282, 8448, 8616, 8783,
>> 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267,
>> 10577, 10926, 11183, 11447, 11728, 12131, 12531, 13018, 13463,
>> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854, 17233,
>> 17889, 18586, 19211, 20059, 21418, 21422, 21962, 22597, 23351,
>> 24274, 25222, 26030, 26752, 27314, 28030, 29037, 29905, 30658,
>> 31686, 32785, 33550, 34463, 35237, 35995, 36983, 38149, 39334,
>> 40291, 41251, 42216)), row.names = c(NA, -122L), class = "data.frame")
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Tue Jul 14 03:00:43 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Mon, 13 Jul 2020 19:00:43 -0600
Subject: [R] Issues whenWorking with Daily Time Series and Generating
 Forecasts
In-Reply-To: <CAMOcQfPi99aeq=w+-hES5_xqh9+siJdQYJCDOvuuVT8hje7UHw@mail.gmail.com>
References: <CAMOcQfOfkSL8oD2mU78KY9GnB0nTMkbpd-uhN=CLyi0P8GGfOA@mail.gmail.com>
 <CACxE24nuLXBqhdq-FSDL=H-rwkaN4_uUH+CQbMPp1=+roRt9cA@mail.gmail.com>
 <CAMOcQfPi99aeq=w+-hES5_xqh9+siJdQYJCDOvuuVT8hje7UHw@mail.gmail.com>
Message-ID: <CACxE24krcodyEDr9N+spKQH4ZjmLz+50s3Hakg6s53wRUGt2Zw@mail.gmail.com>

I?m not entirely sure if we can do the Y-m-d format, but I will give it a
try!

Thanks

On Mon, Jul 13, 2020 at 6:58 PM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friend, yes,
>
> When I generate the forecasts i want the output to include the original
> series, the fitted vaules and the forecast and I want the x-axis to show
> all dates (both the dates of the historical series plus the future dares in
> YYYY-mm-dd format).
>
> Thank you so much for your kind and valuable help.
>
> Cheers,
>
> Paul
>
>
> El lun., 13 de julio de 2020 7:10 p. m., Erin Hodgess <
> erinm.hodgess at gmail.com> escribi?:
>
>> Hi again, Paul!
>>
>> When you are plotting the final product, do you want both the original
>> series, the fitted values, and the forecast, please?
>>
>> I am messing around with your data.
>>
>> Thanks,
>> Erin
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com
>>
>>
>> On Mon, Jul 13, 2020 at 12:41 PM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Dear friends, hope you are doing great,
>>>
>>> I am working with a daily time series, the series starts on march,10,
>>> 2020
>>> until july 9th, 2020.
>>>
>>> I would like to know if there is a way to make it a ts object, specifying
>>> the year, month and day with the ts function.
>>>
>>> First, I tried setting the ts object as follows:
>>>
>>> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>>>
>>> but when I plot trainingts, the x-axis (time axis) shows values like 5,
>>> 10,
>>> 15 and not the dates.
>>>
>>> Secondly, I tried doing the following
>>>
>>> trainingts2 <- ts(Dataset2$PANCASES, start=c(2020,3,10), end=c(2020,7,9),
>>> frequency=365.25)
>>>
>>> but with this setup, now the x-axis has extrange values like 2020.006,
>>> 2020.008, etc.
>>>
>>> Now, when generating forecasts with auto.arima function I get extremely
>>> large values for the y-axis, which makes the forecasts look like a flat
>>> line:
>>>
>>> trainingts <- ts(Dataset2$PANCASES, frequency=7)
>>>
>>> ModelArima2 <- auto.arima(trainingts, lambda=0)
>>> ModelArima2For <- forecast(ModelArima2, h=30)
>>> plot(ModelArima2For)
>>>
>>> I am providing the dput() for my dataset below.
>>>
>>> Any help and/or guidance will be greatly appreciated,
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>>  > dput(Dataset2)
>>> structure(list(DATE = structure(c(18331, 18332, 18333, 18334,
>>> 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342, 18343,
>>> 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351, 18352,
>>> 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360, 18361,
>>> 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369, 18370,
>>> 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>>> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387, 18388,
>>> 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396, 18397,
>>> 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405, 18406,
>>> 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414, 18415,
>>> 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423, 18424,
>>> 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432, 18433,
>>> 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441, 18442,
>>> 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>>> 18452), class = "Date"), PANCASES = c(1, 8, 11, 27, 36, 43, 55,
>>> 69, 86, 109, 137, 200, 313, 345, 345, 443, 558, 674, 786, 901,
>>> 989, 1181, 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>>> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210, 4273, 4467,
>>> 4658, 4821, 5166, 5338, 5538, 5779, 6021, 6021, 6378, 6532, 6720,
>>> 7090, 7090, 7197, 7523, 7731, 7868, 8070, 8282, 8448, 8616, 8783,
>>> 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267,
>>> 10577, 10926, 11183, 11447, 11728, 12131, 12531, 13018, 13463,
>>> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854, 17233,
>>> 17889, 18586, 19211, 20059, 21418, 21422, 21962, 22597, 23351,
>>> 24274, 25222, 26030, 26752, 27314, 28030, 29037, 29905, 30658,
>>> 31686, 32785, 33550, 34463, 35237, 35995, 36983, 38149, 39334,
>>> 40291, 41251, 42216)), row.names = c(NA, -122L), class = "data.frame")
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> --
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


